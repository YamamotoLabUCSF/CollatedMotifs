{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## CollatedMotifs.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background:\n",
    "https://github.com/YamamotoLabUCSF/CollatedMotifs  \n",
    "v1.1/Committed 07-01-2021\n",
    " \n",
    "DNA sequence-selective transcription factors (TFs) mediate gene regulation; their interactions with DNA contribute to the formation of nucleoprotein structures that modulate transcription at target genes.  These functional units -- **response elements** (*e.g.*, enhancers/*cis*-regulatory modules) -- integrate cellular signals to regulate the types of gene transcripts produce by a cell, and when and how much of each transcript type is made.  Genomic editing by programmable nucleases (*e.g.*, CRISPR-Cas9) routinely yields mixed allelic mutation at target loci (*e.g.*, variable insertion *vs.* deletion, indel length across edited cells).  For editing efforts targeted to putative response elements, widely available pattern-matching tools enable prediction of transcription factor binding sites (TFBS) at altered loci, based on matches to position frequency matrices of known TFs.  Awareness of altered TFBSs in genomically edited alleles can aid prediction and/or interpretation of functional consequences associated with mutations.\n",
    "\n",
    "<img src=\"CollatedMotifs_img/CollatedMotifs_thumbnail.png\" align=\"right\" width=\"650\"> \n",
    "\n",
    "**This script automates allele prediction and TFBS collation for deeply sequenced amplicons, and reports TFBS 'lost' and 'new' relative to user-supplied reference sequence(s).**\n",
    "\n",
    "### Potential uses:  \n",
    "This script was developed to enable rapid assessment of TFBS differences at target loci in mutant clones, following Cas9-editing (CRISPR-Cas9 mutagenesis) and clonal isolation.\n",
    "\n",
    "### Synopsis:  \n",
    "**This script returns allele definitions annotated with lost and/or gained TFBS (relative to a reference sequence), for samples from a demultiplexed NGS fastq dataset** \n",
    ">(see 'Output notes' for file output details).  \n",
    "\n",
    "**Users are asked for paths to specific directories (*e.g.*, output and input directories), locally installed executables (BLASTN & MAKEBLASTDB (NCBI), FIMO & FASTA-GET-MARKOV (MEME)), and files (fasta file containing reference sequence(s) for TFBS comparison, fasta file containing reference sequence(s) for alignment, text file containing position frequency matrices for TFBS)**  \n",
    ">(see 'Input notes' for details).\n",
    "    \n",
    "Python3, BLASTN (NCBI), MAKEBLASTDB (NCBI), FIMO (MEME), and FASTA-GET-MARKOV (MEME) are required for operation.  \n",
    "\n",
    "BLASTN & its associated executable MAKEBLASTDB can be downloaded and locally installed at https://www.ncbi.nlm.nih.gov/guide/howto/run-blast-local/.  \n",
    "\n",
    "FIMO, its associated executable FASTA-GET-MARKOV, and positional frequency matrix files can be downloaded and locally installed at http://meme-suite.org/doc/fimo.html.\n",
    "\n",
    "For usage details, please refer to README file at GitHub and to the following manuscript:  \n",
    ">*Ehmsen, Knuesel, Martinez, Asahina, Aridomi, Yamamoto (2021)*\n",
    "    \n",
    "Please cite usage as:  \n",
    ">CollatedMotifs.py  \n",
    ">*Ehmsen, Knuesel, Martinez, Asahina, Aridomi, Yamamoto (2021)*\n",
    " \n",
    "--------\n",
    "\n",
    "### Operation notes:  \n",
    "*What does this script do?*\n",
    " 1. **classify & count reads:** merges R1 and R2 sequences into a single read, counts unique read types per well (*i.e.*, sample); fastq file name provides the sample name  \n",
    " \n",
    " \n",
    " 2. **identify top 5 reads** per well (in terms of read abundance); calculates representation among reads within the well at four levels:  \n",
    " \n",
    "   (a) raw frequency (% read type in question, relative to total reads)  \n",
    "   (b) percentile (% of other read types that fall below the frequency of the read type in question)  \n",
    "   (c) adjusted frequency @ 1% (% read type in question, relative to reads that occur at >1% frequency)  \n",
    "   (d) adjusted frequency @ 10% (% read type in question, relative to reads that occur at >10% frequency)  \n",
    " \n",
    " \n",
    " 3. **align to reference database:** aligns top 5 reads to reference sequence(s) using BLASTN  \n",
    " *(National Center for Biotechnology Information;\n",
    "    Altschul S.F. et al. (1990) \"Basic local alignment search tool\", J Mol Biol. 15(3):403-10)*  \n",
    "      * Alignment database is created within the script by MAKEBLASTDB, from user-provided, fasta-formatted reference sequence(s)  \n",
    "    <img src=\"CollatedMotifs_img/MAKEBLASTDB_and_BLASTN_reference_database_thumbnail.png\" align=\"left\" width=\"300\">\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    " 4. **identify TFBSs in reference and allele sequences:** for user-provided reference sequences, uses FIMO and user-provided positional frequency matrix file to find matches to TFBS motifs  \n",
    "     * Background Markov file for TFBS match statistics is created within the script by FASTA-GET-MARKOV, from user-provided, fasta-formatted reference sequence(s)  \n",
    "    *(FIMO: Grant C.E. et al. (2011) \"FIMO: Scanning for occurrences of a given motif\", Bioinformatics 27(7):1017–1018)*  \n",
    "    *(MEME Suite; Bailey T.L. et al. (2015) \"The MEME Suite\", Nucleic Acids Res 43(Web Server issue):W39–W49)*\n",
    "<img src=\"CollatedMotifs_img/FASTAGETMARKOV_and_Markov_background_thumbnail.png\" align=\"left\" width=\"350\">\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    " 5. **return collation of novel *vs.* lost TFBSs:** compares TFBS in reads to TFBS in specific reference sequence, outputting 'new' and 'lost' TFBSs relative to the reference sequence.\n",
    " \n",
    "\n",
    " \n",
    "--------\n",
    "### Input notes:\n",
    "You will be prompted for the following user-specific information (up to 11 items):\n",
    "\n",
    "**Required** (10 strings: 9 strings specifying directory, executable, or file locations, + 1 string specifying prefix to be assigned to BLASTN database files) \n",
    "\n",
    "  * paths to directories (2)\n",
    "    <ul>\n",
    "    <li>where should output files go?</li>  \n",
    "    <i>path to <strong>output directory</strong> for output files</i>\n",
    "    <li>where are input files found?</li>\n",
    "    <i>path to single directory containing <strong>demultiplexed fastq files</strong></i> \n",
    "    </ul>\n",
    "<br clear=\"all\" />\n",
    "  * paths to executables (4)  \n",
    "     <ul>\n",
    "     <li>where is BLASTN executable found?</li>\n",
    "         <i>path to <strong>BLASTN</strong> installation</i>\n",
    "     <li>where is MAKEBLASTDB executable found?</li>\n",
    "         <i>path to <strong>MAKEBLASTDB</strong> installation</i>\n",
    "     <li>where is FIMO executable found?</li>\n",
    "         <i>path to <strong>FIMO</strong> installation</i>\n",
    "     <li>where is FASTA-GET-MARKOV executable found?</li>\n",
    "         <i>path to <strong>FASTA-GET-MARKOV</strong> installation</i>\n",
    "     </ul>\n",
    "<br clear=\"all\" />      \n",
    "  * paths to files (3)\n",
    "     <ul>\n",
    "     <li>what are your reference sequence(s), to which you will (a) align sequenced reads, and (b) compare sequenced reads for TFBS occurrence?</li>\n",
    "        <i>path to single <strong>fasta file</strong>, containing <strong>reference sequence(s)</strong> for processing by (a) MAKEBLASTDB, to generate a database reference for BLASTN, and (b) FIMO, to establish TFBS occurrence(s) to be evaluated relative to sequenced reads</i>\n",
    "     <li>what are the TFBS motif(s) for which you will search, and for which you will draw comparisons for presence/absence between sequences?</li>\n",
    "        <i>path to single <strong>text file</strong>, containing <strong>position frequency matrix(ces)</strong> for TFs</i>\n",
    "     <li>what DNA sequence(s) will you use as a basis for markov background estimation, to be used by FIMO?</li>\n",
    "        <i>path to single <strong>text/fasta file</strong>, containing DNA sequence(s) from which a <strong>markov background file</strong> will be generated for use by FIMO</i>    \n",
    "     </ul>\n",
    "<br clear=\"all\" />\n",
    "  * label for database files created in 'alignment_directory' by MAKEBLASTDB (1)\n",
    "     <ul>\n",
    "     <li>what common prefix (*) will you assign to the six files (*.nin, *.nhr, *.nog, *.nsd, *.nsg, *.nsi) created by MAKEBLASTDB, as the alignment database for BLASTN?</li>\n",
    "    </ul>  \n",
    "   \n",
    "**Optional** (1 string specifying transcription factor (TF) of interest) \n",
    "  * transcription factor (TF) of interest (1)\n",
    "     <ul>\n",
    "\n",
    "------\n",
    "\n",
    "### Output notes:\n",
    "This script produces 6 output files in the user-specified output directory, plus 3 sub-directories:  \n",
    "\n",
    "  - 3 **sub-directories** comprise outputs of MAKEBLASTDB and FIMO:  \n",
    "  \n",
    "    - two directories contain FIMO output files (fimo_out and fimo_out_ref); each of these sub-directories contains 5 subsidiary files created by FIMO (cisml.xml, fimo.gff, fimo.html, fimo.tsv, fimo.xml)  \n",
    "    - one directory comprises BLASTN alignment database (alignment_database); this directory contains 6 subsidiary files created by MAKEBLASTDB operation on user-supplied fasta file containing reference sequence(s) (\\*.nin, \\*.nhr, \\*.nog, \\*.nsd, \\*.nsg, \\*.nsi)  \n",
    " <br clear=\"all\" />\n",
    "  - 6 **output files** in the user-specified output directory; these include:\n",
    "     \n",
    "  \n",
    "    1. fasta.fa  \n",
    "        (collection of fasta entries representing top 5 most abundant sequences assigned to a single sample ID)  \n",
    "\n",
    "\t2. blastn_alignments.txt  \n",
    "        (output of BLASTN operation on fasta.fa)  \n",
    "        \n",
    "    3. markov_background.txt  \n",
    "        (output of FASTA-GET-MARKOV operation on user-supplied fasta reference file)  \n",
    "        \n",
    "    4. collated_TFBS.txt  \n",
    "        (output of script operation on FIMO-generated .tsv files in fimo_out and fimo_out_ref)\n",
    "        \n",
    "    5. collated_TFBS.xlsx\n",
    "        (output of script interpretation of lost and gained TFBS, detailed for inferred alleles in spreadsheet)\n",
    "     \n",
    "    6. script_metrics.txt  \n",
    "        (summary/analysis of script operation metrics (metadata))\n",
    "\n",
    "           Directory structure under an output directory specified as 'CollatedMotifs', for example,\n",
    "           would contain the following subdirectories and files following CollatedMotifs.py operations:\n",
    "\n",
    "           /CollatedMotifs \n",
    "                          `-----/alignment_database\n",
    "                                        `----------*.nin\n",
    "                                        `----------*.nhr\n",
    "                                        `----------*.nog\n",
    "                                        `----------*.nsd\n",
    "                                        `----------*.nsg\n",
    "                                        `----------*.nsi\n",
    "                          `-----blastn_alignments.txt\n",
    "                          `-----collated_TFBS.txt\n",
    "                          `-----collated_TFBS.xlsx\n",
    "                          `-----fasta.fa\n",
    "                          `-----/fimo_out\n",
    "                                        `----------cisml.xml\n",
    "                                        `----------fimo.gff\n",
    "                                        `----------fimo.html\n",
    "                                        `----------fimo.tsv\n",
    "                                        `----------fimo.xml\n",
    "                          `-----/fimo_out_ref\n",
    "                                        `----------cisml.xml\n",
    "                                        `----------fimo.gff\n",
    "                                        `----------fimo.html\n",
    "                                        `----------fimo.tsv\n",
    "                                        `----------fimo.xml\n",
    "                          `-----markov_background.txt  \n",
    "                          `-----script_metrics.txt\n",
    "--------\n",
    "### Visual summary of key script operations:  \n",
    "In short, sequencing data in a sample-specific **fastq file** (*e.g.,* below), are converted to user-interpretable allele definitions (alignments to a reference sequence) annotated with **TFBS motif(s) lost and/or gained relative to a reference sequence** (**key output files**, below), for 100s to 1000s of samples.  \n",
    "##### example of input fastq file  \n",
    "<img src=\"CollatedMotifs_img/fastq_example.png\" align=\"left\" width=\"700\">\n",
    "<br clear=\"all\" />  \n",
    "\n",
    "#### Key output files:  \n",
    "##### collated_TFBS.txt\n",
    "<img src=\"CollatedMotifs_img/Example_CollatedMotifs_output.png\" align=\"left\" width=\"900\">\n",
    "<br clear=\"all\" />\n",
    "\n",
    "##### collated_TFBS.xlsx  \n",
    "*up to **8 worksheets** occur in this Excel spreadsheet file (example with NR3C1 as TF of interest):*  \n",
    "<img src=\"CollatedMotifs_img/Example_CollatedMotifs_output_xlsx_tab_names.png\" align=\"left\" width=\"700\">\n",
    "<br clear=\"all\" />  \n",
    "*these worksheets are:*   \n",
    "<img src=\"CollatedMotifs_img/CollatedMotifs_output_xlsx_synopsis.png\" align=\"left\" width=\"700\">\n",
    "<br clear=\"all\" />  \n",
    "*example below is for one of the 8 worksheets (\"2 TBFS, lost-regained pairs\"), which interprets TFBSs lost in an allele (relative to reference) that positionally coincide with a FIMO-identified new TFBS for the same TF (therefore designated as 'lost-regained' pairs):*    \n",
    "<img src=\"CollatedMotifs_img/Example_CollatedMotifs_output_xlsx.png\" align=\"left\" width=\"1000\">\n",
    "<br clear=\"all\" />  \n",
    "\n",
    "-------------------------------------------------------------------------------\n",
    "**Welcome.**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code display can be toggled on/off here\n",
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### I. Setup  \n",
    "Import libraries, modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for availability of Python dependencies in path\n",
    "missing_dependencies_list = []\n",
    "\n",
    "try:\n",
    "    import psutil\n",
    "except ImportError:\n",
    "    missing_dependencies_list.append('psutil')\n",
    "    \n",
    "try:\n",
    "    import numpy\n",
    "except ImportError:\n",
    "    missing_dependencies_list.append('numpy')\n",
    "\n",
    "try:\n",
    "    import scipy\n",
    "except ImportError:\n",
    "    missing_dependencies_list.append('scipy')\n",
    "    \n",
    "try:\n",
    "    import pandas\n",
    "except ImportError:\n",
    "    missing_dependencies_list.append('pandas')\n",
    "    \n",
    "if len(missing_dependencies_list) > 0:\n",
    "    print('ModuleNotFoundError\\n')\n",
    "    print('Please note, the following required Python module(s) are not found in your Python system path:')\n",
    "    for i in missing_dependencies_list:\n",
    "        print('   '+i)\n",
    "    print('\\nPlease exit the script and install these Python dependencies in your system path.')\n",
    "    print(\"\"\"\\nGuidelines for installation of Python dependencies can be found in the README file for CollatedMotifs.py ('System Setup')\"\"\")\n",
    "    print(\"\"\"    (Creation of a Python virtual environment is recommended)\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Operating system interfaces\n",
    "import os\n",
    "\n",
    "# Time access and conversions, Basic data and time types\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# System-specific parameters and functions\n",
    "import sys\n",
    "\n",
    "# Process and system utilities\n",
    "import psutil\n",
    "from psutil import virtual_memory\n",
    "\n",
    "# Gzip to read GNU zipped files\n",
    "import gzip\n",
    "\n",
    "# Low-level networking interface\n",
    "import socket\n",
    "\n",
    "# System version information\n",
    "import platform\n",
    "\n",
    "# Unix-style pathname pattern expansion\n",
    "import glob\n",
    "\n",
    "# NumPy (numeric operations)\n",
    "import numpy\n",
    "\n",
    "# SciPy (for percentile) \n",
    "from scipy import stats\n",
    "\n",
    "# Container datatypes (for Counter operation)\n",
    "from collections import Counter\n",
    "\n",
    "# Decimal fixed point and floating point arithmetic\n",
    "from decimal import Decimal\n",
    "\n",
    "# Regular expression operations\n",
    "import re\n",
    "\n",
    "# Object-oriented filesystem paths\n",
    "from pathlib import Path\n",
    "\n",
    "# Internationalization services (for use of thousands separator in numbers where appropriate)\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "\n",
    "# start time\n",
    "initialTime = datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions  \n",
    "*User inputs can be entered either in rapid succession ('List' format), or in response to individually coached prompts. 'Prompts' defines a series of 11 coached entries that provide a user with instructive detail regarding the nature of required input.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 'prompts' function for coached user input\n",
    "def prompts():\n",
    "    \"\"\"Coached prompts to collect user input\"\"\"\n",
    "    # Make variables assigned in prompts() function globally available\n",
    "    global output_directory\n",
    "    global fastq_directory\n",
    "    global fasta_ref\n",
    "    global blastn_path\n",
    "    global makeblastdb_path\n",
    "    global db_prefix\n",
    "    global fimo_path\n",
    "    global fimo_motifs_path\n",
    "    global fasta_get_markov_path\n",
    "    global markov_background_file\n",
    "    global TF_of_interest\n",
    "    # 1-Specify output directory.\n",
    "    print(r\"\"\"\n",
    "---------------------------------------------\n",
    "Location of OUTPUT DIRECTORY for output files\n",
    "---------------------------------------------\n",
    "    \n",
    "This script produces 6 output files in the user-specified output directory, plus three directories:\n",
    "two directories and subsidiary files created by FIMO (fimo_out and fimo_out_ref) and one directory\n",
    "and subsidiary files created by MAKEBLASTDB (alignment_database).\n",
    "    \n",
    "CollatedMotifs.py output files include:\n",
    "    \n",
    "    1. fasta.fa\n",
    "\n",
    "    2. blastn_alignments.txt\n",
    "        (output of BLASTN operation on fasta.fa)\n",
    "\n",
    "    3. markov_background.txt\n",
    "        (output of FASTA-GET-MARKOV operation on user-supplied fasta reference file)\n",
    "\n",
    "    4. collated_TFBS.txt\n",
    "        (output of script operation on FIMO-generated .tsv files in fimo_out and fimo_out_ref)\n",
    "        \n",
    "    5. collated_TFBS.xlsx\n",
    "        (output of script interpretation of lost and gained TFBS, detailed for inferred alleles in spreadsheet)\n",
    "         \n",
    "    6. script_metrics.txt (summary/analysis of script operation metrics [metadata])\n",
    "    \n",
    "        Note: \n",
    "        * These files do not exist before the script is run. The files are made by the script.\n",
    "        * The primary data outputs for TFBS comparisons are found in collated_TFBS.txt\n",
    "        \n",
    "At this prompt, indicate an absolute path to a ** directory ** that will be created by the script as the location\n",
    "for output files.  This directory should not exist yet -- it will be created as an output of this script, and will\n",
    "be populated with the file outputs of this specific instance of the script operation.\n",
    "\n",
    "Use only forward slashes ('/') as directory separators, regardless of operating system (Mac or Windows).\n",
    "\n",
    "Example: if you'd like to create a directory ('CollatedMotifs') in an existing directory ('Illumina'), accessed\n",
    "with absolute path of '/Users/myname/Illumina/CollatedMotifs' (Mac) or 'C:\\Users\\myname\\Illumina\\CollatedMotifs'\n",
    "(Windows), enter '/Users/myname/Illumina/CollatedMotifs' at the command line prompt. Replace 'myname' with the\n",
    "appropriate intervening directory identifiers. Do *not* flank your entry with quotation marks (') at the\n",
    "command-line.\n",
    "    \n",
    "Alternatively, simply enter a desired directory name (e.g., 'CollatedMotifs') and run this script from\n",
    "within a directory where you'd like to create this new directory.\"\"\"+'\\n')\n",
    "    output_directory = input(r\"\"\"    -----> Output directory name and path:  \"\"\")\n",
    "    # 2-Specify the fastq files to be used for input, by indicating directory location of the file list.\n",
    "    print(r\"\"\"\n",
    "------------------------------------------------------------------------------\n",
    "Location of INPUT FILES (single directory containing demutiplexed fastq files)\n",
    "------------------------------------------------------------------------------\n",
    "\n",
    "You will now be asked to enter the path to the directory containing the fastq files\n",
    "to be processed as CollatedMotifs.py input.\n",
    "\n",
    "Use only forward slashes ('/') as directory separators.\n",
    "\n",
    "Example: if your fastq input files are named file1.fastq, file2.fastq, etc. and are found in a directory\n",
    "named 'Sequences' with absolute path of '/Users/myname/Sequences' (Mac) or 'C:\\Users\\myname\\Sequences' (PC),\n",
    "enter '/Users/myname/Sequences' at the command line prompt.\n",
    "\n",
    "When you're done entering the fastq file location, press 'Enter' again to proceed in the script.\"\"\"+'\\n')\n",
    "    fastq_directory = input(r\"\"\"    -----> Directory name and path:  \"\"\")\n",
    "    # 3-Specify fasta file containing reference sequences as basis for TFBS motif comparisons/contrasts.\n",
    "    print(r\"\"\"\n",
    "-----------------------------------------\n",
    "Location of FIMO REFERENCE SEQUENCES FILE\n",
    "-----------------------------------------\n",
    "\n",
    "This script aligns and compares your top sample read sequence(s) to a defined reference sequence,\n",
    "as its basis for determining distinct vs. common TFBS motifs. Please indicate the absolute path to a\n",
    "fasta file containing reference sequence(s).\n",
    "\n",
    "Use only forward slashes ('/') as directory separators.\n",
    "\n",
    "**Important**: Each fasta entry definition line (defline) should be named such that the defline name\n",
    "matches a unique descriptor (character string) that occurs in the fastq file names for samples that\n",
    "will be aligned and compared to the corresponding fasta entry. For all ranked alleles for a given sample,\n",
    "the fastq file name is incorporated into the allele names; the script then relies on a character string\n",
    "to match between the allele name and an entry in the fasta reference file, to understand which reference\n",
    "sequence to use for alignment and comparison of TFBSs that occur between the allele and the reference.\n",
    "\n",
    "Example: if you have samples screened by PCR amplification across three distinct loci (Locus1, Locus2,\n",
    "and Locus3), the fastq file names might be named Locus1_A01.fastq, Locus1_A02.fastq, etc.; Locus2_A01.fastq,\n",
    "Locus2_A02.fastq, etc.; Locus3_A01.fastq, Locus3_A02.fastq, etc.\n",
    "\n",
    "For the fasta reference sequences, you would designate deflines for the three different reference sequences such\n",
    "that the deflines are character strings with diagnostic matches to character strings that occur in the \n",
    "corresponding sample fastq file names (such as 'Locus1', 'Locus2', 'Locus3' for the example sample sets above.\n",
    "Prepare the reference sequences in fasta format, saved in a single text file.\n",
    "    \n",
    "    >Locus1\n",
    "    GATCGACTAGAGCGAGCATTCATCATATCACGAGTAGCATCGACGTGCACGATCGATCGTAGCTAGCTAGTCATGCATGCATGCTAGATTCGAGCATGCATGCTAC\n",
    "    >Locus2\n",
    "    AGTAGCTGTGATGCTAGTCATCTAGCTAGCAGCGTAGCTAGCGATCGATCTAGAGCCGATCGATCGAGCATCTAGCTATCAGCGGCGGGATCATCTATCTACGGG\n",
    "    >Locus3\n",
    "    CGATGCAGCGCGATCGAGCGCGATCGATATTAGCATGCGCAGCTAGCTAGCTGGCGATCGATGCATGCTAGCTGTGTCAGTCGACGATCACACGATCACACTGTGTG\n",
    "\n",
    "When you're done entering the path to the reference sequence file, press 'Enter' again to proceed in the script.\"\"\"+'\\n')\n",
    "    fasta_ref = input(r\"\"\"    -----> Path to fasta file containing reference sequences:  \"\"\")\n",
    "    # 4-Collect path to blastn executable.\n",
    "    print(r\"\"\"\n",
    "-----------------------------\n",
    "Location of BLASTN EXECUTABLE\n",
    "-----------------------------\n",
    "\n",
    "This script uses BLASTN (NCBI) to align reads from your fastq files to a reference sequence database.\n",
    "Please indicate the absolute path to the BLASTN executable.\n",
    "\n",
    "Use only forward slashes ('/') as directory separators.\n",
    "\n",
    "Example: if your BLASTN executable is found at absolute path /Users/myname/blastn, type '/Users/myname/blastn'\n",
    "and press Enter.\"\"\"+'\\n')\n",
    "    blastn_path = input(r\"\"\"    -----> Path to BLASTN executable:  \"\"\")\n",
    "    # 5-Collect path to makeblastdb executable.\n",
    "    print(r\"\"\"\n",
    "----------------------------------\n",
    "Location of MAKEBLASTDB EXECUTABLE\n",
    "----------------------------------\n",
    "\n",
    "Because this script uses BLASTN (NCBI) to align reads from your fastq files to a reference sequence database,\n",
    "a compatible reference sequence database is required. This script uses MAKEBLASTDB (NCBI) to generate\n",
    "a reference sequence database from the reference sequences in the fasta file you provided earlier.\n",
    "    \n",
    "Please indicate the absolute path to the MAKEBLASTDB executable.\n",
    "\n",
    "Use only forward slashes ('/') as directory separators.\n",
    "\n",
    "Example: if your MAKEBLASTDB executable is found at absolute path /Users/myname/makeblastdb,\n",
    "type '/Users/myname/makeblastdb' and press Enter.\"\"\"+'\\n')\n",
    "    makeblastdb_path = input(r\"\"\"    -----> Path to MAKEBLASTDB executable:  \"\"\")\n",
    "    # 6-Specify prefix to files in database\n",
    "    print(r\"\"\"\n",
    "---------------------------------------------\n",
    "Prefix for files in BLASTN ALIGNMENT DATABASE\n",
    "---------------------------------------------\n",
    "\n",
    "Because this script uses BLASTN (NCBI) and an alignment reference database, a common prefix identifier for the six\n",
    "database files generated by MAKEBLASTDB is needed.\n",
    "\n",
    "Please indicate a prefix to assign to each of the database files.\n",
    "\n",
    "Example: if your alignment reference was generated by MAKEBLASTDB from a fasta file called GRCh38.fa,\n",
    "the alignment database files will have been assigned the prefix 'GRCh38'; you would type 'GRCh38'\n",
    "and press Enter.\"\"\"+'\\n')\n",
    "    db_prefix = input(r\"\"\"    -----> Prefix for alignment reference sequence database files:  \"\"\")\n",
    "    # 7-Specify path to FIMO installation\n",
    "    print(r\"\"\"\n",
    "---------------------------\n",
    "Location of FIMO EXECUTABLE\n",
    "---------------------------\n",
    "\n",
    "This script uses FIMO from the MEME suite of sequence analysis tools as its basis for determining distinct vs.\n",
    "common TFBSs.\n",
    "\n",
    "Please indicate the absolute path to the FIMO installation.\n",
    "\n",
    "Use only forward slashes ('/') as directory separators.\n",
    "\n",
    "Example: if your FIMO executable is found at absolute path /Users/myname/fimo, type '/Users/myname/fimo'\n",
    "and press Enter.\"\"\"+'\\n')\n",
    "    fimo_path = input(r\"\"\"    -----> Path to FIMO executable:  \"\"\")\n",
    "    # 8-Specify path to FIMO motif file.\n",
    "    print(r\"\"\"\n",
    "----------------------------\n",
    "Location of FIMO MOTIFS FILE\n",
    "----------------------------\n",
    "\n",
    "This script uses FIMO from the meme suite of sequence analysis tools as its basis for determining distinct vs.\n",
    "common TFBS motifs.\n",
    "\n",
    "Please indicate the absolute path to the FIMO motifs file (containing position frequency matrix/matrices).\n",
    "\n",
    "Use only forward slashes ('/') as directory separators.\n",
    "\n",
    "When you're done entering the location of the motifs file, press Enter.\"\"\"+'\\n')\n",
    "    fimo_motifs_path = input(r\"\"\"    -----> Path to FIMO motifs file:  \"\"\")\n",
    "    # 9-Specify path to FIMO fasta-get-markov installation.\n",
    "    print(r\"\"\"\n",
    "---------------------------------------------\n",
    "Location of FIMO FASTA-GET-MARKOV EXECUTABLE\n",
    "---------------------------------------------\n",
    "\n",
    "This script uses FIMO from the MEME suite of sequence analysis tools as its basis for determining distinct vs.\n",
    "common TFBSs.\n",
    "\n",
    "Please indicate an absolute path to the location of the FASTA-GET-MARKOV executable.\n",
    "\n",
    "Use only forward slashes ('/') as directory separators.\n",
    "\n",
    "When you're done entering the location of the executable, press Enter.\"\"\"+'\\n')\n",
    "    fasta_get_markov_path = input(r\"\"\"    -----> Path to FASTA-GET-MARKOV executable:  \"\"\")\n",
    "    # 10-Specify path to markov background file.\n",
    "    print(r\"\"\"\n",
    "------------------------------------------------------------\n",
    "Location of FIMO FASTA-GET-MARKOV BACKGROUND REFERENCE FILE\n",
    "------------------------------------------------------------\n",
    "\n",
    "This script uses FIMO from the MEME suite of sequence analysis tools as its basis for determining distinct vs.\n",
    "common TFBSs.\n",
    "\n",
    "Please indicate an absolute path to the location of the fasta file you will use as your background reference\n",
    "(on which FASTA-GET-MARKOV will operate to generate a markov background file).\n",
    "\n",
    "Use only forward slashes ('/') as directory separators.\n",
    "    \n",
    "When you're done entering the location of the reference sequence, press Enter.\"\"\"+'\\n')\n",
    "    markov_background_file = input(r\"\"\"    -----> Path to background reference file:  \"\"\")\n",
    "    # 11-Specify transcription factor (TF) of interest, for which to search for lost TFBS occurrences in alleles.\n",
    "    print(r\"\"\"\n",
    "------------------------------------------------\n",
    "TRANSCRIPTION FACTOR (TF) of interest (optional)\n",
    "------------------------------------------------\n",
    "\n",
    "This script collates lost and gained TFBS for sample-associated allele(s) relative to a reference sequence;\n",
    "if detailed analysis of alleles that have lost TFBS matches for a specific transcription factor (TF) are desired,\n",
    "the identity of an individual TF of interest can be provided (optional).\n",
    "\n",
    "If you would like the script to further analyze alleles for TFBS matches to a specific TF, please indicate the\n",
    "TF here.  Otherwise, press Enter. \n",
    "\n",
    "Important: Use only the standardized Entrez gene name for the TF of interest (such as NR3C1), rather than the\n",
    "matrix model stable ID (for example, MA0113 for NR3C1) or stable ID with version number (for example, MA0113.3\n",
    "for NR3C1).\n",
    "\n",
    "Example: if you are interested in losses of TFBS for the TF NR3C1, you would type 'NR3C1'\n",
    "and press Enter.\"\"\"+'\\n')\n",
    "    TF_of_interest = input(r\"\"\"    -----> Transcription Factor (TF) of interest:  \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define 'convert_bytes' and 'path_size' functions to be used in data collection for script_metrics.txt        \n",
    "def convert_bytes(num):\n",
    "    \"\"\"\n",
    "    This function converts bytes to convenient order of magnitude prefixes\n",
    "    \"\"\"\n",
    "    for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if num < 1024.0:\n",
    "            return \"%3.1f %s\" % (num, x)\n",
    "        num /= 1024.0\n",
    "        \n",
    "def path_size(given_path):\n",
    "    \"\"\"\n",
    "    This function returns file or directory size\n",
    "    \"\"\"\n",
    "    if os.path.isfile(given_path):\n",
    "        file_info = os.stat(given_path)\n",
    "        return convert_bytes(file_info.st_size)\n",
    "    elif os.path.isdir(given_path):\n",
    "        dir_info = os.stat(given_path)\n",
    "        return convert_bytes(dir_info.st_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "*'merge' and 'merge1' define functions that merge R1 & R2 (reverse complement), or append if they do not overlap; nt_dict is called upon to reverse complement R2* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Define 'merge' function to merge R1 & R2 reads\n",
    "def merge(s1, s2):\n",
    "    i = 0\n",
    "    while not s2.startswith(s1[i:]):\n",
    "        i += 1\n",
    "    if i < len(s2):\n",
    "        return s1[:i] + s2\n",
    "    else:\n",
    "        return 'no overlap'\n",
    "    \n",
    "# Define 'merge1' function to append two strings that do not overlap\n",
    "def merge1(s1, s2):\n",
    "    i = 0\n",
    "    while not s2.startswith(s1[i:]):\n",
    "        i += 1\n",
    "    return s1[:i] + s2\n",
    "\n",
    "# Define nt complement dictionary      \n",
    "nt_dict = {'A':'T', 'T':'A', 'G':'C', 'C':'G', 'N':'N', '-':'-'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### II. Define user-specified variables\n",
    "\n",
    "A user defines input variables by entering individual lines of text at the Jupyter interface.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------------\n",
      "User-specified input: choice of coached prompts vs. single list entry\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "Values for the user-specified input indicated above can be entered at individually coached command-line prompts\n",
      "(default), or as a single list of variables provided in a single command-line entry without coached prompts.\n",
      "\n",
      "To proceed with input at individual command-line PROMPTS, type 'Prompt' and press Enter;\n",
      "To proceed with input provided as a single LIST in one command-line entry, type 'List' and press Enter:  \n",
      "    \n",
      "    -----> List or Prompt: List\n"
     ]
    }
   ],
   "source": [
    "# Specify whether user input is provided at individual coached prompts or as single-list entry\n",
    "print(r\"\"\"\n",
    "---------------------------------------------------------------------\n",
    "User-specified input: choice of coached prompts vs. single list entry\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "Values for the user-specified input indicated above can be entered at individually coached command-line prompts\n",
    "(default), or as a single list of variables provided in a single command-line entry without coached prompts.\n",
    "\n",
    "To proceed with input at individual command-line PROMPTS, type 'Prompt' and press Enter;\n",
    "To proceed with input provided as a single LIST in one command-line entry, type 'List' and press Enter:  \n",
    "    \"\"\")\n",
    "user_input = input(r\"\"\"    -----> List or Prompt: \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------\n",
      "User-specified input (list format)\n",
      "----------------------------------\n",
      "    \n",
      "Please paste input values directly at the interpreter prompt, specifying the following 10 or 11 values:\n",
      "\n",
      "    1-Location of OUTPUT DIRECTORY for output files\n",
      "    2-Location of INPUT FILES (directory containing fastq files)\n",
      "    3-Location of REFERENCE FASTA FILE\n",
      "    4-Location of BLASTN EXECUTABLE\n",
      "    5-Location of MAKEBLASTDB EXECUTABLE\n",
      "    6-Prefix to assign to BLASTN sequence database files\n",
      "    7-Location of FIMO EXECUTABLE\n",
      "    8-Location of POSITION FREQUENCY MATRIX FILE\n",
      "    9-Location of FASTA-GET-MARKOV EXECUTABLE\n",
      "    10-Location of MARKOV BACKGROUND FILE\n",
      "    11-Identity of TRANSCRIPTION FACTOR (TF) of interest (optional)\n",
      "\n",
      "** Input the values in the specified order in a single line of text\n",
      "** Separate each value by a single semicolon (';')\n",
      "    \n",
      "For example (if specifying TF of interest, 11 values):\n",
      "\n",
      "/Users/myname/CollatedMotifsOutput; /Users/myname/fastq_files; Users/myname/ref_fasta.fa; /Users/myname/bin/blastn;\n",
      "/Users/myname/bin/makeblastdb; ref_name; /Users/myname/Meme/bin/fimo;\n",
      "/Users/myname/JASPAR_CORE_2016_vertebrates.meme; /Users/myname/Meme/bin/fasta-get-markov; /Users/myname/hg38.fa;\n",
      "NR3C1\n",
      "\n",
      "For example (if no specification for TF of interest, 10 values):\n",
      "\n",
      "/Users/myname/CollatedMotifsOutput; /Users/myname/fastq_files; Users/myname/ref_fasta.fa; /Users/myname/bin/blastn;\n",
      "/Users/myname/bin/makeblastdb; ref_name; /Users/myname/Meme/bin/fimo;\n",
      "/Users/myname/JASPAR_CORE_2016_vertebrates.meme; /Users/myname/Meme/bin/fasta-get-markov; /Users/myname/hg38.fa\n",
      "\n",
      "Press 'Enter' to complete.\n",
      "    \n",
      "\n",
      "/Users/kirkehmsen/Documents/CollatedMotifsOutputGit_072721; /Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/CollatedMotifs_testfiles/fastq_files_subset; /Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/CollatedMotifs_testfiles/FKBP5_GOR+86.848kb_KE4.txt; /Users/kirkehmsen/anaconda3/bin/blastn; /Users/kirkehmsen/anaconda3/bin/makeblastdb; FKBP5_GOR+86.848kb; /Users/kirkehmsen/Meme/bin/fimo; /Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/CollatedMotifs_testfiles/JASPAR_CORE_2016_vertebrates.meme; /Users/kirkehmsen/Meme/meme-5.0.1/src/fasta-get-markov; /Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/CollatedMotifs_testfiles/hg38.fa\n"
     ]
    }
   ],
   "source": [
    "if user_input == 'Prompt':\n",
    "    prompts()\n",
    "elif user_input == 'List':\n",
    "    print(\"\"\"\n",
    "----------------------------------\n",
    "User-specified input (list format)\n",
    "----------------------------------\n",
    "    \n",
    "Please paste input values directly at the interpreter prompt, specifying the following 10 or 11 values:\n",
    "\n",
    "    1-Location of OUTPUT DIRECTORY for output files\n",
    "    2-Location of INPUT FILES (directory containing fastq files)\n",
    "    3-Location of REFERENCE FASTA FILE\n",
    "    4-Location of BLASTN EXECUTABLE\n",
    "    5-Location of MAKEBLASTDB EXECUTABLE\n",
    "    6-Prefix to assign to BLASTN sequence database files\n",
    "    7-Location of FIMO EXECUTABLE\n",
    "    8-Location of POSITION FREQUENCY MATRIX FILE\n",
    "    9-Location of FASTA-GET-MARKOV EXECUTABLE\n",
    "    10-Location of MARKOV BACKGROUND FILE\n",
    "    11-Identity of TRANSCRIPTION FACTOR (TF) of interest (optional)\n",
    "\n",
    "** Input the values in the specified order in a single line of text\n",
    "** Separate each value by a single semicolon (';')\n",
    "    \n",
    "For example (if specifying TF of interest, 11 values):\n",
    "\n",
    "/Users/myname/CollatedMotifsOutput; /Users/myname/fastq_files; Users/myname/ref_fasta.fa; /Users/myname/bin/blastn;\n",
    "/Users/myname/bin/makeblastdb; ref_name; /Users/myname/Meme/bin/fimo;\n",
    "/Users/myname/JASPAR_CORE_2016_vertebrates.meme; /Users/myname/Meme/bin/fasta-get-markov; /Users/myname/hg38.fa;\n",
    "NR3C1\n",
    "\n",
    "For example (if no specification for TF of interest, 10 values):\n",
    "\n",
    "/Users/myname/CollatedMotifsOutput; /Users/myname/fastq_files; Users/myname/ref_fasta.fa; /Users/myname/bin/blastn;\n",
    "/Users/myname/bin/makeblastdb; ref_name; /Users/myname/Meme/bin/fimo;\n",
    "/Users/myname/JASPAR_CORE_2016_vertebrates.meme; /Users/myname/Meme/bin/fasta-get-markov; /Users/myname/hg38.fa\n",
    "\n",
    "Press 'Enter' to complete.\n",
    "    \n",
    "\"\"\")\n",
    "    input_list = []\n",
    "    input_str_temp = input()\n",
    "    input_str = input_str_temp.strip()\n",
    "    for x in input_str.split(';'):\n",
    "        input_list.append(x.strip())\n",
    "    output_directory = input_list[0].strip()\n",
    "    fastq_directory = input_list[1].strip()\n",
    "    fasta_ref = input_list[2].strip()\n",
    "    blastn_path = input_list[3].strip()\n",
    "    makeblastdb_path = input_list[4].strip()\n",
    "    db_prefix = input_list[5].strip()\n",
    "    fimo_path = input_list[6].strip()\n",
    "    fimo_motifs_path = input_list[7].strip()\n",
    "    fasta_get_markov_path = input_list[8].strip()\n",
    "    markov_background_file = input_list[9].strip()\n",
    "    if len(input_list) == 11:\n",
    "        TF_of_interest = input_list[10].strip()\n",
    "    else:\n",
    "        TF_of_interest = ''\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Convert directory and executable strings to operating system-appropriate paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Wait to create the directories and files until after input has been reviewed and accepted.\n",
    "# Convert fastq_directory input to operating system-appropriate filepath.\n",
    "output_directory = Path(str(output_directory))\n",
    "# Convert fastq_directory input to operating system-appropriate filepath.\n",
    "fastq_directory = Path(str(fastq_directory))\n",
    "# Convert fasta_ref input to operating system-appropriate filepath.\n",
    "fasta_ref = Path(str(fasta_ref))\n",
    "# Convert blastn_path input to operating system-appropriate filepath.\n",
    "blastn_path = Path(str(blastn_path))\n",
    "# Convert makeblastdb_path input to operating system-appropriate filepath.\n",
    "makeblastdb_path = Path(str(makeblastdb_path))\n",
    "# Convert fimo_path input to operating system-appropriate filepath.\n",
    "fimo_path = Path(str(fimo_path))\n",
    "# Convert fimo_motifs_path input to operating system-appropriate filepath.\n",
    "fimo_motifs_path = Path(str(fimo_motifs_path))\n",
    "# Convert fasta_get_markov_path input to operating system-appropriate filepath.\n",
    "fasta_get_markov_path = Path(str(fasta_get_markov_path))\n",
    "# Convert markov_background_file input to operating system-appropriate filepath.\n",
    "markov_background_file = Path(str(markov_background_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Collect fastq files from directory; sort alphanumerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "myFastqFilenames = [file for file in glob.glob(str(fastq_directory)+'/*') if Path(file).suffix in [\".gz\",\".fastq\"]]\n",
    "\n",
    "#Sort fastq file names\n",
    "myFastqFilenames = sorted(myFastqFilenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Print fastq file names, to double-check file inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/CollatedMotifs_testfiles/fastq_files_subset/KE4-1-C02_S1178_L001_R1_001.fastq\n",
      "/Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/CollatedMotifs_testfiles/fastq_files_subset/KE4-1-C02_S1178_L001_R2_001.fastq\n",
      "/Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/CollatedMotifs_testfiles/fastq_files_subset/KE4-2-A01_S1249_L001_R1_001.fastq\n",
      "/Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/CollatedMotifs_testfiles/fastq_files_subset/KE4-2-A01_S1249_L001_R2_001.fastq\n",
      "/Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/CollatedMotifs_testfiles/fastq_files_subset/KE4-4-G02_S1514_L001_R1_001.fastq\n",
      "/Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/CollatedMotifs_testfiles/fastq_files_subset/KE4-4-G02_S1514_L001_R2_001.fastq\n",
      "/Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/CollatedMotifs_testfiles/fastq_files_subset/KE4-4-G10_S1522_L001_R1_001.fastq\n",
      "/Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/CollatedMotifs_testfiles/fastq_files_subset/KE4-4-G10_S1522_L001_R2_001.fastq\n"
     ]
    }
   ],
   "source": [
    "for file in myFastqFilenames:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Collect overview of fastq file contents:  \n",
    "<ul>\n",
    "  <li>Illumina runID</li>   \n",
    "  <li>read count in each fastq file</li>    \n",
    "  <li>file size</li> \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Collect Illumina run IDs from fastq files, consolidate to unique run IDs\n",
    "runIDlist = []\n",
    "for sourcefile in myFastqFilenames:\n",
    "    if Path(sourcefile).suffix == \".gz\":\n",
    "        with gzip.open(sourcefile, \"rt\") as f:\n",
    "            runID = \":\".join(f.readline().split(\":\",-2)[:2])\n",
    "            if not runID in runIDlist:\n",
    "                runIDlist.append(runID) \n",
    "    elif Path(sourcefile).suffix == \".fastq\":\n",
    "        with open(sourcefile, \"r\") as f:\n",
    "            runID = \":\".join(f.readline().split(\":\",-2)[:2])\n",
    "            if not runID in runIDlist:\n",
    "                runIDlist.append(runID)\n",
    "\n",
    "# Collect total read counts for fastq files\n",
    "readcount = []\n",
    "for sourcefile in myFastqFilenames:\n",
    "    if Path(sourcefile).suffix == \".gz\":\n",
    "        with gzip.open(sourcefile, \"rt\") as f:    \n",
    "            readcount.append(int(len((f).readlines())/4))\n",
    "    elif Path(sourcefile).suffix == \".fastq\":\n",
    "        with open(sourcefile, \"r\") as f:\n",
    "            readcount.append(int(len((f).readlines())/4))\n",
    "        \n",
    "# Collect file sizes for fastq files\n",
    "filesize = []\n",
    "for sourcefile in myFastqFilenames:\n",
    "    if Path(sourcefile).suffix == \".gz\":\n",
    "        with gzip.open(sourcefile, \"rt\") as f:\n",
    "            filesize.append(round((os.path.getsize(sourcefile)/1048576),5))\n",
    "    elif Path(sourcefile).suffix == \".fastq\":\n",
    "        filesize.append(round((os.path.getsize(sourcefile)/1048576),5))\n",
    "\n",
    "# fastq_overview prepares summation of fastq file names, their sizes, and read counts, to be reported in script_metrics.txt    \n",
    "fastq_overview = list(zip(myFastqFilenames, filesize, readcount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Double-check whether user-specified entries look good. If a variable is inaccurately assigned, prompt user to restart kernel to begin again.\n",
    "\n",
    "Retrieve and/or calculate the following properties across the fastq files to be processed (these values will be reported in script_metrics.txt):  \n",
    "<ul>\n",
    "  <li>Illumina sequencing run ID(s)</li>\n",
    "  <li>Total number of fastq files</li>\n",
    "  <li>Total number of sequencing reads</li>\n",
    "  <li>Size distribution of fastq files</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------------------------------\n",
      "Preparation for output:\n",
      "Please double-check that your inputs were recorded as expected.\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Your OUTPUT DIRECTORY was recorded as:\n",
      "\n",
      "/Users/kirkehmsen/Documents/CollatedMotifsOutputGit_072721\n",
      "\n",
      "Your directory containing fastq INPUT FILES was recorded as:\n",
      "\n",
      "/Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/CollatedMotifs_testfiles/fastq_files_subset\n",
      "The following data were collected:  \n",
      "    Illumina sequencing run ID(s): \n",
      "        @M00582:216\n",
      "    # of fastq files to process: 8\n",
      "    size distribution of fastq files to process: \n",
      "      total... 3 MB \n",
      "      range... max: 0.58 MB; min: 0.05928 MB; median: 0.339 MB; mean +/- stdev: 0.329 +/- 0.206 MB\n",
      "    read distribution within fastq files to process: \n",
      "      total... 7,592 reads \n",
      "      range... max: 1667 reads; min: 171 reads; median: 979.0 reads; mean +/- stdev: 949.0 +/- 595.0 reads\n",
      "\n",
      "Your FASTA REFERENCE FILE location was recorded as:\n",
      "\n",
      "/Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/CollatedMotifs_testfiles/FKBP5_GOR+86.848kb_KE4.txt\n",
      "\n",
      "Your BLASTN EXECUTABLE location was recorded as:\n",
      "\n",
      "/Users/kirkehmsen/anaconda3/bin/blastn\n",
      "\n",
      "Your MAKEBLASTDB EXECUTABLE location was recorded as:\n",
      "\n",
      "/Users/kirkehmsen/anaconda3/bin/makeblastdb\n",
      "\n",
      "Your BLASTN DATABASE FILE PREFIX was recorded as:\n",
      "\n",
      "FKBP5_GOR+86.848kb\n",
      "\n",
      "Your FIMO EXECUTABLE location was recorded as:\n",
      "\n",
      "/Users/kirkehmsen/Meme/bin/fimo\n",
      "\n",
      "Your POSITION FREQUENCY FILE location was recorded as:\n",
      "\n",
      "/Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/CollatedMotifs_testfiles/JASPAR_CORE_2016_vertebrates.meme\n",
      "\n",
      "# of TFBS motifs examined: 519\n",
      "Identities of TFBS motifs examined: \n",
      "    ALX3       ARNT::HIF1A      ATF4          ATF7        Ahr::Arnt       Alx1          Alx4           Ar      \n",
      "   Arid3a        Arid3b        Arid5a         Arnt          Arntl          Arx          Ascl2         Atf1     \n",
      "    Atf3          Atoh1        BARHL2         BARX1         BATF3       BATF::JUN       BCL6B        BHLHE22   \n",
      "   BHLHE23       BHLHE40       BHLHE41         BSX       Bach1::Mafk     Barhl1         Bcl6         Bhlha15   \n",
      "    CDX1          CDX2          CEBPA         CEBPB         CEBPD         CEBPE         CEBPG         CENPB    \n",
      "    CLOCK         CREB1         CREB3        CREB3L1        CTCF          CUX1          CUX2         Creb3l2   \n",
      "    Creb5         Crem           Crx           DBP          DLX6          DMRT3         DUX4          DUXA     \n",
      "Ddit3::Cebpa      Dlx1          Dlx2          Dlx3          Dlx4          Dmbx1          Dux          E2F1     \n",
      "    E2F2          E2F3          E2F4          E2F6          E2F7          E2F8          EBF1          EGR1     \n",
      "    EGR2          EGR3          EGR4           EHF          ELF1          ELF3          ELF4          ELF5     \n",
      "    ELK1          ELK3          ELK4          EMX1          EMX2           EN1           EN2          EOMES    \n",
      "     ERF           ERG          ESR1          ESR2          ESRRB         ESX1          ETS1          ETV1     \n",
      "    ETV2          ETV3          ETV4          ETV5          ETV6          EVX1          EVX2       EWSR1-FLI1  \n",
      "    Esrra         Esrrg          FEV          FIGLA         FLI1           FOS        FOS::JUN        FOSL1    \n",
      "    FOSL2         FOXA1         FOXB1         FOXC1         FOXC2         FOXD1         FOXD2         FOXF2    \n",
      "    FOXG1         FOXH1         FOXI1         FOXL1         FOXO3         FOXO4         FOXO6         FOXP1    \n",
      "    FOXP2         FOXP3         Foxa2         Foxd3         Foxj2         Foxj3         Foxk1         Foxo1    \n",
      "    Foxq1      GATA1::TAL1      GATA2         GATA3         GATA5         GBX1          GBX2          GCM1     \n",
      "    GCM2          GLI2          GLIS1         GLIS2         GLIS3         GMEB2         GRHL1          GSC     \n",
      "    GSC2          GSX1          GSX2          Gabpa         Gata1         Gata4         Gfi1          Gfi1b    \n",
      "    Gmeb1         HES5          HES7          HESX1         HEY1          HEY2          HIC2          HINFP    \n",
      "     HLF          HLTF         HMBOX1         HNF1A         HNF1B         HNF4G        HOXA10        HOXA13    \n",
      "    HOXA2         HOXA5        HOXB13         HOXB2         HOXB3        HOXC10        HOXC11        HOXC12    \n",
      "   HOXC13        HOXD11        HOXD12        HOXD13         HSF1          HSF2          HSF4       Hand1::Tcf3 \n",
      "    Hes1          Hes2          Hic1          Hmx1          Hmx2          Hmx3          Hnf4a        Hoxa11    \n",
      "    Hoxa9         Hoxb5         Hoxc9         Hoxd3         Hoxd8         Hoxd9          ID4          INSM1    \n",
      "    IRF1          IRF2          IRF7          IRF8          IRF9          ISL2           ISX           Id2     \n",
      "    JDP2       JDP2(var.2)       JUN       JUN(var.2)       JUNB          JUND       JUND(var.2)      KLF13    \n",
      "    KLF14         KLF16         KLF5          Klf1          Klf12         Klf4          LBX1          LBX2     \n",
      "    LEF1          LHX2          LHX6          LHX9          LIN54         LMX1A         LMX1B         Lhx3     \n",
      "    Lhx4          Lhx8        MAF::NFE2       MAFF          MAFG      MAFG::NFE2L1      MAFK           MAX     \n",
      "  MAX::MYC        MEF2A         MEF2B         MEF2C         MEF2D         MEIS1         MEIS2         MEIS3    \n",
      "    MEOX1         MEOX2          MGA          MIXL1          MLX         MLXIPL          MNT          MNX1     \n",
      "     MSC          MSX1          MSX2          MTF1          MYBL1         MYBL2         MYF6          MZF1     \n",
      " MZF1(var.2)      Mafb          Mecom         Mitf          Mlxip         Msx3           Myb           Myc     \n",
      "    Mycn          Myod1         Myog         NEUROD2       NEUROG2        NFAT5        NFATC1        NFATC2    \n",
      "   NFATC3         NFE2          NFIA          NFIC       NFIC::TLX1       NFIL3         NFIX          NFKB1    \n",
      "    NFKB2         NFYA          NFYB          NHLH1        NKX2-3        NKX2-8        NKX3-2        NKX6-1    \n",
      "   NKX6-2         NOTO       NR1H2::RXRA      NR2C2         NR2F1         NR3C1         NR3C2         NR4A2    \n",
      "    NRF1           NRL         Neurog1       Nfe2l2        Nkx2-5     Nkx2-5(var.2)    Nkx3-1         Nobox    \n",
      "    Npas2      Nr1h3::Rxra      Nr2e1         Nr2e3         Nr2f6     Nr2f6(var.2)      Nr5a2         OLIG1    \n",
      "    OLIG2         OLIG3        ONECUT1       ONECUT2       ONECUT3        OTX1          OTX2          PAX1     \n",
      "    PAX3          PAX4          PAX5          PAX7          PAX9          PBX1          PDX1         PHOX2A    \n",
      "    PITX3        PKNOX1        PKNOX2         PLAG1        POU1F1        POU2F1        POU2F2        POU3F1    \n",
      "   POU3F2        POU3F3        POU3F4        POU4F1        POU4F2        POU4F3        POU5F1B       POU6F1    \n",
      "   POU6F2         PPARG         PRDM1         PROP1         PROX1         PRRX1         Pax2          Pax6     \n",
      "   Phox2b         Pitx1        Pou2f3     Pou5f1::Sox2   Pparg::Rxra      Prrx2         RARA       RARA(var.2) \n",
      " RARA::RXRA        RAX          RAX2           REL          RELA          REST          RFX2          RFX3     \n",
      "    RFX4          RFX5         RHOXF1         RORA       RORA(var.2)      RREB1         RUNX1         RUNX2    \n",
      "    RUNX3       RXRA::VDR       RXRB          RXRG          Rarb       Rarb(var.2)      Rarg       Rarg(var.2) \n",
      "    Rfx1         Rhox11         Rxra          SCRT1         SCRT2         SHOX      SMAD2::SMAD3::SMAD4     SMAD3    \n",
      "    SNAI2         SOX10         SOX21         SOX4          SOX8          SOX9           SP1           SP2     \n",
      "     SP3           SP4           SP8          SPDEF         SPI1          SPIB          SPIC         SREBF1    \n",
      "   SREBF2     SREBF2(var.2)      SRF           SRY          STAT1     STAT1::STAT2      STAT3         Shox2    \n",
      "    Six3          Sox1          Sox11         Sox17         Sox2          Sox3          Sox5          Sox6     \n",
      "    Spz1      Srebf1(var.2)     Stat4     Stat5a::Stat5b     Stat6           T        TAL1::TCF3        TBP     \n",
      "    TBR1          TBX1          TBX15         TBX19         TBX2          TBX20         TBX21         TBX4     \n",
      "    TBX5          TCF3          TCF4         TCF7L2         TEAD1         TEAD3         TEAD4          TEF     \n",
      "   TFAP2A     TFAP2A(var.2) TFAP2A(var.3)    TFAP2B     TFAP2B(var.2) TFAP2B(var.3)    TFAP2C     TFAP2C(var.2)\n",
      "TFAP2C(var.3)     TFAP4         TFCP2         TFE3          TFEB          TFEC          TGIF1         TGIF2    \n",
      "    THAP1         TP53          TP63          TP73          Tcf12         Tcf21         Tcf7          Tcfl5    \n",
      "   Twist2         UNCX          USF1          USF2          VAX1          VAX2          VENTX         VSX1     \n",
      "    VSX2           Vdr          XBP1           YY1           YY2          ZBED1        ZBTB18        ZBTB33    \n",
      "   ZBTB7A        ZBTB7B        ZBTB7C         ZEB1          ZIC1          ZIC3          ZIC4         ZNF143    \n",
      "   ZNF263        ZNF354C       ZNF410        ZNF740          Zfx         Znf423         mix-a    \n",
      "\n",
      "Your FASTA-GET-MARKOV EXECUTABLE location was recorded as:\n",
      "\n",
      "/Users/kirkehmsen/Meme/meme-5.0.1/src/fasta-get-markov\n",
      "\n",
      "Your MARKOV BACKGROUND FILE location was recorded as:\n",
      "\n",
      "/Users/kirkehmsen/Documents/Zenodo/ExampleTestFiles/CollatedMotifs_testfiles/hg38.fa\n",
      "\n",
      "Your TF of interest was recorded as:\n",
      "\n",
      "No TF of interest was provided\n",
      "\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n",
      "* Please check that this list is accurately recorded.                                         *\n",
      "*                                                                                             *\n",
      "* If you have corrections to make, please return to the appropriate cell to reset variables.  *\n",
      "* To continue in the script, move to the next cell.                                           *\n",
      "* To restart the script, click on the menu 'Kernel -> Restart'.                               *\n",
      "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n"
     ]
    }
   ],
   "source": [
    "# Double-check whether entries look good:\n",
    "print(\"\"\"\n",
    "---------------------------------------------------------------\n",
    "Preparation for output:\n",
    "Please double-check that your inputs were recorded as expected.\n",
    "---------------------------------------------------------------\"\"\")\n",
    "\n",
    "print(\"\"\"\n",
    "Your OUTPUT DIRECTORY was recorded as:\n",
    "\"\"\")\n",
    "print(str(output_directory))\n",
    "\n",
    "print(\"\"\"\n",
    "Your directory containing fastq INPUT FILES was recorded as:\n",
    "\"\"\")\n",
    "print(str(fastq_directory))\n",
    "\n",
    "print(\"\"\"The following data were collected:  \"\"\")\n",
    "print(\"    Illumina sequencing run ID(s): \")\n",
    "for i in runIDlist:\n",
    "    print('        '+i)\n",
    "\n",
    "print(\"    # of fastq files to process: {0}\".format(len(myFastqFilenames)))\n",
    "\n",
    "print(\"    size distribution of fastq files to process: \\n      total... \"+str(round((sum(file for file in filesize))))+' MB \\n      range... max: '+str(round((max(file for file in filesize)),2))+' MB; min: '+str(round((min(file for file in filesize)),5))+' MB; median: '+str(round((numpy.median([file for file in filesize])),3))+' MB; mean +/- stdev: '+str(round((numpy.mean([file for file in filesize])),3))+' +/- '+str(round((numpy.std([file for file in filesize])),3))+' MB')\n",
    "\n",
    "print(\"    read distribution within fastq files to process: \\n      total... \"+locale.format_string(\"%d\", sum(readcount), grouping=True)+' reads \\n      range... max: '+str((max(file for file in readcount)))+' reads; min: '+str((min(file for file in readcount)))+' reads; median: '+str((numpy.median([file for file in readcount])))+' reads; mean +/- stdev: '+str(round((numpy.mean([file for file in readcount]))))+' +/- '+str(round((numpy.std([file for file in readcount]))))+' reads')\n",
    "\n",
    "print(\"\"\"\n",
    "Your FASTA REFERENCE FILE location was recorded as:\n",
    "\"\"\")\n",
    "print(str(fasta_ref))\n",
    "\n",
    "print(\"\"\"\n",
    "Your BLASTN EXECUTABLE location was recorded as:\n",
    "\"\"\")\n",
    "print(str(blastn_path))\n",
    "\n",
    "print(\"\"\"\n",
    "Your MAKEBLASTDB EXECUTABLE location was recorded as:\n",
    "\"\"\")\n",
    "print(makeblastdb_path)\n",
    "\n",
    "print(\"\"\"\n",
    "Your BLASTN DATABASE FILE PREFIX was recorded as:\n",
    "\"\"\")\n",
    "print(db_prefix)\n",
    "\n",
    "print(\"\"\"\n",
    "Your FIMO EXECUTABLE location was recorded as:\n",
    "\"\"\")\n",
    "print(fimo_path)\n",
    "\n",
    "print(\"\"\"\n",
    "Your POSITION FREQUENCY FILE location was recorded as:\n",
    "\"\"\")\n",
    "print(fimo_motifs_path)\n",
    "\n",
    "# Examine the reference file and indicate the ID, number of motifs, etc. print out list of factors for query\n",
    "motifcountlist = []\n",
    "with open(fimo_motifs_path, 'r') as file:\n",
    "    for line in file:\n",
    "        if bool(re.search('MOTIF', line)): \n",
    "            motifcountlist.append(line.strip())\n",
    "\n",
    "print(\"\"\"\n",
    "# of TFBS motifs examined: \"\"\"+str(len(motifcountlist)))\n",
    "\n",
    "motifID = [i.split(' ')[2] for i in motifcountlist]\n",
    "motifID = sorted(motifID)\n",
    "chunked_motifID = [motifID[i: i+8] for i in range(0, len(motifID), 8)]\n",
    "\n",
    "print('Identities of TFBS motifs examined: ')\n",
    "\n",
    "for row in chunked_motifID:\n",
    "    itemnumber = (len(row)*'{: ^13} ').rstrip()\n",
    "    print(itemnumber.format(*row))\n",
    "\n",
    "print(\"\"\"\n",
    "Your FASTA-GET-MARKOV EXECUTABLE location was recorded as:\n",
    "\"\"\")\n",
    "print(fasta_get_markov_path)\n",
    "\n",
    "print(\"\"\"\n",
    "Your MARKOV BACKGROUND FILE location was recorded as:\n",
    "\"\"\")\n",
    "print(markov_background_file)\n",
    "\n",
    "print(\"\"\"\n",
    "Your TF of interest was recorded as:\n",
    "\"\"\")\n",
    "if TF_of_interest != '':\n",
    "    print(TF_of_interest)\n",
    "else:\n",
    "    print('No TF of interest was provided')\n",
    "\n",
    "\n",
    "print(\"\"\"\n",
    "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n",
    "* Please check that this list is accurately recorded.                                         *\n",
    "*                                                                                             *\n",
    "* If you have corrections to make, please return to the appropriate cell to reset variables.  *\n",
    "* To continue in the script, move to the next cell.                                           *\n",
    "* To restart the script, click on the menu 'Kernel -> Restart'.                               *\n",
    "* * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\"\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Generate output directory and files, ready for script output  \n",
    "Script generates a single directory, populated with 5 files ready to accept script output (6th file, Excel workbook, is generated during later script operations).  \n",
    "Files are automatically named as in **'Output notes'** above, with current date appended to filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Start the clock on script operation duration\n",
    "startTime = datetime.now()\n",
    "startTimestr = str(startTime).split(' ')[1].split('.')[0]\n",
    "\n",
    "# Proceed to file processing\n",
    "# Generate the directory and its files (to accept content later in script)\n",
    "path = str(output_directory)\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "    \n",
    "output_path = Path(output_directory)\n",
    "\n",
    "# Create output files\n",
    "filename_list = ['fasta.fa', 'blastn_alignments.txt', 'collated_TFBS.txt', 'markov_background.txt', 'script_metrics.txt']\n",
    "\n",
    "# Define current date as prefix to all filenames\n",
    "processdate = datetime.today().strftime(\"%m%d%Y\")\n",
    "\n",
    "for filename in filename_list:\n",
    "    with open(os.path.join(path, processdate+'_'+filename), 'wb') as file:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The file **script_metrics.txt** records script operation metadata (summarizes script input and performance); peform initial log of system information, user-defined variables and fastq file properties to script_metrics.txt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Collect RAM info\n",
    "mem = virtual_memory()\n",
    "ramem = mem.total/1073741824\n",
    "\n",
    "# Use print redirection to write to target file, in append mode (begin script_metrics.txt)\n",
    "with open(fasta_ref, \"r\") as f:\n",
    "    ref_seqs = f.readlines()\n",
    "    \n",
    "filename = Path(str(output_path)+'/'+processdate+'_script_metrics.txt')\n",
    "with open(filename, 'a') as f:\n",
    "    print(\"\"\"CollatedMotifs.py: Script Metrics\n",
    "Date: \"\"\" + (datetime.today().strftime(\"%m/%d/%Y\")) +\n",
    "\"\"\"\\n\\nOperating system information:\n",
    "    name: \"\"\" + socket.gethostname() +\n",
    "'\\n    platform: ' + platform.platform() +\n",
    "'\\n    RAM (GB): ' + str(ramem) +\n",
    "'\\n    physical CPU/effective CPU: ' + str(psutil.cpu_count(logical=False)) +'/'+ str(psutil.cpu_count()) +\n",
    "'\\n    executable: ' + psutil.Process().exe() +\n",
    "\"\"\"\\n\\nUser-entered variables:\n",
    "    output_directory: \"\"\"+ str(output_directory) +\n",
    "\"\\n    fastq_directory: \"+ str(fastq_directory) +\n",
    "\"\\n    fasta_ref: \"+ str(fasta_ref) +\n",
    "\"\\n    blastn_path: \"+ str(blastn_path) +\n",
    "\"\\n    makeblastdb_path: \"+ str(makeblastdb_path) +\n",
    "\"\\n    db_prefix: \"+ str(db_prefix) +\n",
    "\"\\n    fimo_path: \"+ str(fimo_path) +\n",
    "\"\\n    fimo_motifs_path: \"+ str(fimo_motifs_path) +\n",
    "\"\\n    fasta_get_markov_path: \"+ str(fasta_get_markov_path) +\n",
    "\"\\n    markov_background_file: \"+ str(markov_background_file), file = f)\n",
    "    if TF_of_interest == '':\n",
    "        print(\"    TF_of_interest: none specified\", file = f)\n",
    "    else:\n",
    "        print(\"    TF_of_interest: \"+ TF_of_interest, file = f)    \n",
    "    print(\"\"\"\\nfastq file information:\n",
    "    Illumina sequencing run ID(s): \"\"\"+ str(runIDlist).strip('[]').replace(\"'\",\"\") +\n",
    "\"\\n    Number of fastq files processed: \"+ str(len(myFastqFilenames)) +\n",
    "\"\"\"\\n    Size distribution of fastq files processed: \n",
    "        total... \"\"\" +str(round((sum(file for file in filesize))))+' MB \\n        range... max: '+str(round((max(file for file in filesize)),2))+' MB; min: '+str(round((min(file for file in filesize)),5))+' MB; median: '+str(round((numpy.median([file for file in filesize])),3))+' MB; mean +/- stdev: '+str(round((numpy.mean([file for file in filesize])),3))+' +/- '+str(round((numpy.std([file for file in filesize])),3))+' MB' +\n",
    "\"\\n    Read distribution within fastq files to process: \\n        total... \"+locale.format_string(\"%d\", sum(readcount), grouping=True)+' reads \\n        range... max: '+str((max(file for file in readcount)))+' reads; min: '+str((min(file for file in readcount)))+' reads; median: '+str((numpy.median([file for file in readcount])))+' reads; mean +/- stdev: '+str(round((numpy.mean([file for file in readcount]))))+' +/- '+str(round((numpy.std([file for file in readcount]))))+' reads', file = f)\n",
    "    print(\"\\nfastq files processed (name, size (MB), reads): \", file = f)\n",
    "    for i in (sorted(fastq_overview)):\n",
    "        print(\"    \" + str(i).strip(\"()\").replace(\"'\",\"\"), file = f)\n",
    "    print(\"\\nReference sequences provided in fasta_ref file: \", file = f)\n",
    "    for i in ref_seqs:\n",
    "        print(\"    \" + i.strip('\\n'), file = f)     \n",
    "    print(\"\\n# of TFBS motifs examined: \"+str(len(motifcountlist))+\n",
    "\"\\nIdentities of TFBS motifs examined: \", file = f)\n",
    "    for row in chunked_motifID:\n",
    "        itemnumber = (len(row)*'{: ^13} ').rstrip()\n",
    "        print(itemnumber.format(*row), file = f)        \n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Create accessory files for BLASTN and FIMO operations:  \n",
    "- **MAKEBLASTDB** (NCBI) will now be used to prepare a reference sequence database for BLASTN alignments.  \n",
    "*The output of this operation is a set of 6 database files in alignments_directory.*  \n",
    "\n",
    "\n",
    "- **FASTA-GET-MARKOV** (MEME) will then be used to prepare a background markov file for FIMO statistical operations.  \n",
    "*The output of this operation is a single file, markov_background.txt, supplied to FIMO with sample and reference fasta files.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the clock on makeblastdb and fastgetmarkov operations\n",
    "startTime_makeblastdb_fastagetmarkov_operations = datetime.now()\n",
    "\n",
    "# Construct alignment database, in alignment_database directory\n",
    "# Reference sequence input\n",
    "mydb_input = Path(fasta_ref)\n",
    "\n",
    "# Alignment database directory\n",
    "mydb_output = Path(str(output_directory)+'/alignment_database')\n",
    "\n",
    "os.makedirs(mydb_output)\n",
    "\n",
    "# 'Make blastn database' command (usage: makeblastdb -in mydb.fsa -parse_seqids -dbtype nucl -out path)\n",
    "cmd_makeblastndb = str(makeblastdb_path)+' -in '+str(mydb_input)+' -parse_seqids -dbtype nucl -out '+str(mydb_output)+'/'+db_prefix\n",
    "\n",
    "os.system(cmd_makeblastndb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Construct background markov file to be used by FIMO\n",
    "# Markov input file (markov background file)\n",
    "markovbackground_input = Path(markov_background_file)\n",
    "\n",
    "# Markov background output file  \n",
    "markovbackground_output = Path(str(output_directory)+'/'+processdate+'_markov_background.txt')\n",
    "\n",
    "# 'Make markov background file' command (usage: fasta-get-markov [options] [<sequence file> [<background file>]])\n",
    "cmd_fastagetmarkov = str(fasta_get_markov_path)+' -dna '+str(markovbackground_input)+' '+str(markovbackground_output)\n",
    "\n",
    "os.system(cmd_fastagetmarkov)\n",
    "\n",
    "# Log makeblastdb and fastgetmarkov operations time duration\n",
    "makeblastdb_fastagetmarkov_operationsDuration = str(datetime.now()- startTime_makeblastdb_fastagetmarkov_operations).split(':')[0]+' hr|'+str(datetime.now() - startTime_makeblastdb_fastagetmarkov_operations).split(':')[1]+' min|'+str(datetime.now() - startTime_makeblastdb_fastagetmarkov_operations).split(':')[2].split('.')[0]+' sec|'+str(datetime.now()- startTime_makeblastdb_fastagetmarkov_operations).split(':')[2].split('.')[1]+' microsec'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V. Identify candidate alleles: fasta file, BLASTN alignment, and assignment of alleles to samples  \n",
    "Deep sequencing of amplicons can yield hundreds to thousands of reads per sample; read frequencies can be used to gauge relative read abundance and, ultimately, to infer probable genotype (sequence ID(s) of the source template(s)).\n",
    "<img src=\"CollatedMotifs_img/fasta_thumbnail.png\" align=\"left\" width=\"560\">  \n",
    "\n",
    "**Count reads.** This script parses sample-specific fastq files for unique read types, counts the abundance of these read types, and reports the top 5 most abundant read types in the form of fasta entries. For each sample, **each of the 5 ranked sequences is reported with its frequency metrics** in a corresponding fasta definition line (defline).  \n",
    "The output of this step is a fasta file (.fa) that will be created in the user-specified OUTPUT DIRECTORY.  \n",
    "\n",
    "*(rationale for top 5 ranked sequences: 5 ranked reads facilitate user interpretation of genotype, because homozygous or heterozygous genotypes exhibit top-ranked allele(s) (one if homozygous, two if heterozygous) with frequency(ies) substantially higher than the remaining ranked reads (which may then be inferred as PCR and/or sequencing artefacts); alternatively, if sample is multiploid and/or otherwise heterogenous, the 5 ranked sequences sample into the underlying diversity)*   \n",
    "\n",
    "**Align reads to reference.** This fasta file is then presented to **BLASTN** (with the reference sequence database specified during user input) for alignments.\n",
    "\n",
    "**Define candidate alleles.** The script then parses the alignments to organize alignment data for the 'top 5' reads assigned to each sample, in a single dictionary called **'alignmentoutput_dict'**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Start the clock on read count duration      \n",
    "startTime_readcount = datetime.now()\n",
    "\n",
    "# Populate fasta files for fasta.fa, in preparation for fimo analysis      \n",
    "query_input = Path(str(output_directory)+'/'+processdate+'_fasta.fa')\n",
    "\n",
    "# define Nextera adaptor sequence, in preparation to trim read 3' ends if necessary\n",
    "adaptor_str = 'CTGTCTCTTATACACATCT'\n",
    "adaptor_str_rev = 'AGATGTGTATAAGAGACAG'\n",
    "\n",
    "# Merge R1 and R2 reads, if present, as single sequence\n",
    "R1_file_list = [sourcefile for sourcefile in myFastqFilenames if bool(re.split('_',os.path.basename(sourcefile))[3] == 'R1')]\n",
    "R2_file_list = [sourcefile for sourcefile in myFastqFilenames if bool(re.split('_',os.path.basename(sourcefile))[3] == 'R2')]  \n",
    "\n",
    "# R1, R2 cluster mapping\n",
    "processed_files_list = []\n",
    "R1_R2_map_list = []\n",
    "for sourcefile in myFastqFilenames:\n",
    "    if sourcefile in processed_files_list:\n",
    "        pass\n",
    "    else:\n",
    "        testname = ''.join(re.split('_',os.path.basename(sourcefile))[0:3])\n",
    "        for sourcefile1 in R1_file_list:\n",
    "            if testname == ''.join(re.split('_',os.path.basename(sourcefile1))[0:3]):\n",
    "                R1 = sourcefile\n",
    "                if sourcefile not in processed_files_list:\n",
    "                    processed_files_list.append(sourcefile)\n",
    "        for sourcefile2 in R2_file_list:\n",
    "            if testname == ''.join(re.split('_',os.path.basename(sourcefile2))[0:3]):\n",
    "                R2 = sourcefile2\n",
    "                if sourcefile2 not in processed_files_list:\n",
    "                    processed_files_list.append(sourcefile2)\n",
    "        R1_R2_map_list.append((R1, R2))\n",
    "        \n",
    "# Make fasta file of read entries, direct top read count output and annotation to fasta.fa   \n",
    "for file_pair in R1_R2_map_list:\n",
    "    R1_file = file_pair[0]\n",
    "    R2_file = file_pair[1]\n",
    "    fastaname = re.split('_', os.path.basename(R1_file))\n",
    "    cluster_sequence_R1_dict = {}\n",
    "    cluster_sequence_R2_dict = {}\n",
    "    cluster_sequence_R2_revcomp_dict = {}\n",
    "    cluster_merged_R1_R2revcomp_dict = {}\n",
    "    cluster_merged_R1_R2revcomp_dict2 = {}\n",
    "    merged_read_list = []\n",
    "    counter=()\n",
    "    if Path(R1_file).suffix == \".gz\":\n",
    "        with gzip.open(R1_file, \"rt\") as f:\n",
    "            lines_R1 = f.readlines()\n",
    "    elif Path(R1_file).suffix == \".fastq\":\n",
    "        with open(R1_file, 'r') as f:\n",
    "            lines_R1 = f.readlines()    \n",
    "    for x in range(0,len(lines_R1),4):\n",
    "        # trim adaptor sequence and up to 3' end of read from R1 sequence, if adaptor sequence found\n",
    "        cluster_sequence_R1_dict[lines_R1[x].split(':')[5]+':'+lines_R1[x].split(':')[6].split(' ')[0]] = lines_R1[x+1].strip('\\n')[:lines_R1[x+1].strip('\\n').index(adaptor_str)] if adaptor_str in lines_R1[x+1].strip('\\n') else lines_R1[x+1].strip('\\n') \n",
    "    #cluster_IDs_list_R1 = [x.split(':')[5]+':'+x.split(':')[6].split(' ')[0] for x in lines_R1[0::4]]\n",
    "    if Path(R2_file).suffix == \".gz\":\n",
    "        with gzip.open(R2_file, \"rt\") as f:\n",
    "            lines_R2 = f.readlines()\n",
    "    elif Path(R2_file).suffix == \".fastq\":\n",
    "        with open(R2_file, 'r') as f:\n",
    "            lines_R2 = f.readlines()\n",
    "    for x in range(0,len(lines_R2),4):\n",
    "        # trim adaptor sequence and up to 3' end of read from R2 sequence, if adaptor sequence found\n",
    "        cluster_sequence_R2_dict[lines_R2[x].split(':')[5]+':'+lines_R2[x].split(':')[6].split(' ')[0]] = lines_R2[x+1].strip('\\n')[:lines_R2[x+1].strip('\\n').index(adaptor_str)] if adaptor_str in lines_R2[x+1].strip('\\n') else lines_R2[x+1].strip('\\n') \n",
    "    #cluster_IDs_list_R2 = [x.split(':')[5]+':'+x.split(':')[6].split(' ')[0] for x in lines_R2[0::4]]\n",
    "    for cluster in cluster_sequence_R2_dict:\n",
    "        cluster_sequence_R2_revcomp_dict[cluster] = ''.join(reversed(''.join(nt_dict.get(nt) for nt in cluster_sequence_R2_dict.get(cluster))))\n",
    "    for cluster in cluster_sequence_R1_dict:\n",
    "        if cluster in cluster_sequence_R2_revcomp_dict:\n",
    "            if merge(cluster_sequence_R1_dict.get(cluster), cluster_sequence_R2_revcomp_dict.get(cluster)) != 'no overlap':\n",
    "                cluster_merged_R1_R2revcomp_dict[cluster] = merge(cluster_sequence_R1_dict.get(cluster), cluster_sequence_R2_revcomp_dict.get(cluster))\n",
    "            else:\n",
    "                cluster_merged_R1_R2revcomp_dict2[cluster] = merge1(cluster_sequence_R1_dict.get(cluster), cluster_sequence_R2_revcomp_dict.get(cluster))\n",
    "    for cluster in cluster_merged_R1_R2revcomp_dict:\n",
    "        merged_read_list.append(cluster_merged_R1_R2revcomp_dict.get(cluster))\n",
    "    # create dictionary (counter) relating unique read sequence to its # of occurrences\n",
    "    counter=Counter(merged_read_list)\n",
    "    modified_read_list_top5 = []\n",
    "    for index, i in enumerate(counter.most_common(5)):\n",
    "        filtered1 = sum([x for x in counter.values() if x/(sum(counter.values())) > 0.01])\n",
    "        filtered10 = sum([x for x in counter.values() if x/(sum(counter.values())) > 0.1])\n",
    "        raw_freq = round((100*i[1]/sum(counter.values())),2)\n",
    "        modified_read_list_top5.append([i[0], '['+str(i[1])+'/'+str(sum(counter.values()))+']', 'rank'+str(index+1), raw_freq, int(stats.percentileofscore([i for i in counter.values()], i[1], 'rank')), round((100*i[1]/sum([i[1] for i in counter.most_common(5)])),2), round((100*i[1]/filtered1),2) if filtered1 > 0 and raw_freq >= 1 else 'None', round((100*i[1]/filtered10),2) if filtered10 > 0 and raw_freq >= 10 else 'None'])\n",
    "    with open(str(query_input), 'a+') as file:\n",
    "        for i in modified_read_list_top5:\n",
    "              file.write('>'+fastaname[0]+'_'+'R1+R2'+'_'+str(i[1])+'_'+i[2]+'_%totalreads:'+str(i[3])+'_percentile:'+str(i[4])+'_%top5reads:'+str(i[5])+'_%readsfilteredfor1%:'+str(i[6])+'_%readsfilteredfor10%:'+str(i[7])+'\\n'+i[0]+'\\n')\n",
    "                \n",
    "# Log read count time duration      \n",
    "readcountDuration = str(datetime.now()- startTime_readcount).split(':')[0]+' hr|'+str(datetime.now() - startTime_readcount).split(':')[1]+' min|'+str(datetime.now() - startTime_readcount).split(':')[2].split('.')[0]+' sec|'+str(datetime.now() - startTime_readcount).split(':')[2].split('.')[1]+' microsec'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process alignments to reference sequence database, using **BLASTN** (NCBI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Start the clock on blastn alignments duration  \n",
    "startTime_alignments = datetime.now()\n",
    "\n",
    "# Process alignments relative to reference sequence database, using blastn\n",
    "# Reference database\n",
    "db_input = mydb_output / db_prefix\n",
    "\n",
    "# Alignment output\n",
    "query_output = str(output_directory)+'/'+processdate+'_blastn_alignments.txt'\n",
    "\n",
    "# Alignment command\n",
    "cmd_align = str(blastn_path)+' -strand plus -query '+str(query_input)+' -db '+str(db_input)+' -out '+str(query_output)+' -gapopen 1 -gapextend 1 -outfmt \"5\"'\n",
    "\n",
    "os.system(cmd_align)\n",
    "\n",
    "# Log alignment time duration\n",
    "alignmentsDuration = str(datetime.now()- startTime_alignments).split(':')[0]+' hr|'+str(datetime.now()- startTime_alignments).split(':')[1]+' min|'+str(datetime.now()- startTime_alignments).split(':')[2].split('.')[0]+' sec|'+str(datetime.now()- startTime_alignments).split(':')[2].split('.')[1]+' microsec'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Define alleles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Start the clock on allele definitions duration      \n",
    "startTime_alleles = datetime.now()\n",
    " \n",
    "# Import blastn alignments output as a list of strings (each string corresponds to a query alignment)      \n",
    "alignments_list = []\n",
    "with open(str(query_output), 'r') as file:\n",
    "    reader = file.read()\n",
    "    for i,part in enumerate(reader.split('<Iteration_iter-num>')):\n",
    "        alignments_list.append(part)\n",
    "# Remove blastn header line from alignments_list\n",
    "alignments_list = alignments_list[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Convert alignments_list to list of lists (i.e., each query alignment string is encapsulateed into its own sublist within alignments_list2)\n",
    "alignments_list2 = [alignments_list[i:i+1] for i in range(0, len(alignments_list))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Subset sample IDs and/or associated reads for which *(1) no alignment* was found in reference database, or *(2) multiple hits* were identified in reference database. These are ultimately removed from further analysis, but the identities of samples and/or associated reads that were filtered by these criteria are ultimately reported in 'population_summary.txt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Identify & subset queries for which no alignments were found in reference database ('no hits found')\n",
    "no_hits_list = []\n",
    "for i in alignments_list2:\n",
    "    if re.search('No hits found', str(i)):\n",
    "        no_hits_list.append(str(i).split('<Iteration_query-def>')[1].split('</Iteration_query-def>')[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Record sample names having reads with no alignment hits      \n",
    "no_hits_samplename_list = []\n",
    "for i in no_hits_list:\n",
    "    samplename = i.split('_')[0]\n",
    "    if samplename not in no_hits_samplename_list:\n",
    "        no_hits_samplename_list.append(samplename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Within each sublist of alignments_list2, split each line into an individual string, remove beginning and trailing whitespace, and recapture specified subset of alignment information in alignments_list3\n",
    "alignments_list3 = []\n",
    "for i in alignments_list2:\n",
    "    if str(i).split('<Iteration_query-def>')[1].split('</Iteration_query-def>')[0] not in no_hits_list:\n",
    "        alignments_list3.append([y.strip() for x in i for y in x.split('\\n') if y.strip().startswith(('<Iteration_query-ID>', '<Iteration_query-def>', '<Hit_num>', '<Hit_id>', '<Hit_def>', '<Hsp_hit-from>', '<Hsp_hit-to>', '<Hsp_qseq>', '<Hsp_hseq>', '<Hsp_midline>'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify & subset reads with >1 alignment to sequences in reference database\n",
    "# Some reads with >1 alignment will be recovered to 'reconstitute' hypothesized allele (if BLASTN has split the read into multiple 'hits' or 'high-scoring pairs' (hsp's) within the span of the user-provided reference sequence)\n",
    "\n",
    "# There are in principle at least 3 ways a read could potentially align to >1 position in reference database (1 & 2a,b below):\n",
    "# (1) same sequence span aligns to >1 different locus (disparate <Hit_id>'s)\n",
    "# [unlike in Genotypes.py, this scenario is not anticipated in CollatedMotifs.py, unless significant sequence overlap occurs in user-provided fasta file containing reference sequence(s)]\n",
    "# (2) one sequence span may be split into two (ore more) different alignment matches, because of intervening gap(s) or insertion(s) that exceed ~60 bp (an apparent BLASTN gap limit)\n",
    "#    (a) if the two (or more) 'split matches' align to the same <Hit_id>, but to different coordinates of that <Hit_id>, they will be presented by BLASTN as belonging to the same <Hit_num>, but to different <Hsp_num> (Hsp=high scoring pair)\n",
    "#    (b) if the two (or more) 'split matches' span different <Hit_id>'s (essentially different 'chunks' of sequence with unique names, as organized within the alignment database), they will be presented by BLASTN as belonging to different <Hit_num>\n",
    "# These observations suggest that it is important to distinguish a read with alignment to >1 sequence as either one with poor resolution among >1 reference sequences (if >1 reference sequence is provided), vs. one that harbors sizeable deletions or insertions relative to the reference sequence\n",
    "# CollatedMotifs.py assumes continuity of 2 or more hsp's if they are assigned to the same user-provided reference sequence,\n",
    "# and therefore attempts to reconstitute hypothesized alleles that span multiple non-overlapping hsp's (but does not attempt to reconstitute across multiple hits or for ambiguous reconstructions from overlapping hsp's)\n",
    "\n",
    "# Organize reads with multiple hit IDs\n",
    "# These reads are deprecated (not further analyzed)\n",
    "multiple_alignments_hits_list = []\n",
    "for i in alignments_list3:\n",
    "    if len(re.findall('<Hit_num>', str(i))) > 1:\n",
    "        multiple_alignments_hits_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dictionary linking sample names to their reads having >1 alignment to sequences in reference database    \n",
    "multiple_alignments_samplename_list = []\n",
    "for i in multiple_alignments_hits_list:\n",
    "    multiple_alignments_samplename_list.append(i[1].split('>')[1].split('_')[0])\n",
    "    \n",
    "multiple_alignments_dict = {}\n",
    "for i in multiple_alignments_samplename_list:\n",
    "    multiple_alignments_dict [\"{0}\".format(i)] = tuple(x for x in multiple_alignments_hits_list if bool(re.search(i, x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize reads with single hit, but multiple associated hsp IDs\n",
    "# These reads will be processed separately to 'reconstitute' potential alleles, with high-scoring alignment pairs matched to the reference sequence, but split into separate matches due to intervening non-aligning span between the alignment matches\n",
    "multiple_alignments_hsp_list = []\n",
    "for i in alignments_list3:\n",
    "    if len(re.findall('<Hit_num>', str(i))) > 1:\n",
    "        pass\n",
    "    elif len(re.findall('<Hsp_hit-from>', str(i))) > 1:\n",
    "        multiple_alignments_hsp_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for multiple hsp's that can be reasonably reconstructed (i.e., >1 hsp's that do not overlap. Overlapping hsp's cannot readily be reconstructed and alleles with overlapping hsp's will be deprecated from analysis)\n",
    "alleles_with_multiple_hsps_that_can_be_reconstructed_list = []\n",
    "for i in alignments_list3:\n",
    "    count = 0\n",
    "    for x in i:\n",
    "        if re.search('<Hsp_hit-from>', x):\n",
    "            count = count+1\n",
    "    if count > 1:\n",
    "        overlapping_hsp = False\n",
    "        index_split_list = []\n",
    "        hsp_list = []\n",
    "        hsp_to_from_list = []\n",
    "        for index, x in enumerate(i):\n",
    "            if re.search('<Hsp_hit-from>', x):\n",
    "                index_split_list.append(index)\n",
    "        for index, y in enumerate(index_split_list):\n",
    "            hsp_list.append(i[y:y+(index+1)*5])\n",
    "        hsp_to_from_list_chunked = []\n",
    "        for index, w in enumerate(range(0,len(hsp_list))):\n",
    "            hsp_to_from_list_chunked.append(hsp_list[index])\n",
    "        for index, hsp in enumerate(hsp_list):\n",
    "            range_to_check = range(int(hsp[0].split('>')[1].split('<')[0]),int(hsp[1].split('>')[1].split('<')[0]))\n",
    "            # ranges of other hsp's in hsp_list\n",
    "            other_hsps_list = hsp_list.copy()\n",
    "            del other_hsps_list[index]\n",
    "            for other_hsp in other_hsps_list:\n",
    "                other_hsp_range = range(int(other_hsp[0].split('>')[1].split('<')[0]),int(other_hsp[1].split('>')[1].split('<')[0]))\n",
    "                if set(range_to_check).intersection(other_hsp_range):\n",
    "                    overlapping_hsp = True\n",
    "                else:\n",
    "                    pass\n",
    "        if overlapping_hsp is False:\n",
    "            alleles_with_multiple_hsps_that_can_be_reconstructed_list.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify alleles with multiple hsp's that were not able to be reconstructed; note these later in script_metrics.txt\n",
    "alleles_with_multiple_hsps_that_cannot_be_reconstructed_list = []\n",
    "for i in multiple_alignments_hsp_list:\n",
    "    if i not in alleles_with_multiple_hsps_that_can_be_reconstructed_list:\n",
    "        alleles_with_multiple_hsps_that_cannot_be_reconstructed_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt to reconstruct long-ranging alignment for alleles with >1 BLASTN hsp that can be reasonably reconstituted\n",
    "reconstructed_alleles_with_multiple_hsps_list = []\n",
    "\n",
    "with open(mydb_input) as file:\n",
    "    ref_candidates = file.readlines()\n",
    "ref_candidates2 = [i.strip('>\\n') for i in ref_candidates]\n",
    "iterator = iter(ref_candidates2)\n",
    "ref_candidates3 = list(zip(iterator,iterator))\n",
    "\n",
    "for allele in alleles_with_multiple_hsps_that_can_be_reconstructed_list:\n",
    "    # get allele as it appears intact in fasta file\n",
    "    with open(query_input) as file:\n",
    "        for index, line in enumerate(file):\n",
    "            if line.strip('\\n') == '>'+allele[1].split('>')[1].split('<')[0]:\n",
    "                allele_fasta = next(file).strip()\n",
    "    allele_reconstruction_list = [i for i in allele[0:5]]\n",
    "    allele_reconstruction_temp_list = []\n",
    "    allele_ref = allele[3].split('>')[1].split('<')[0]\n",
    "    for ref in ref_candidates3:\n",
    "        if ref[0] == allele_ref:\n",
    "            allele_ref_sequence = ref[1]\n",
    "        else:\n",
    "            pass\n",
    "    # collect info re: hsp match spans and alignments to reference\n",
    "    for hsp in range(0,int(((len(allele)-5)/5))):\n",
    "        hsp_from = int(allele[5+hsp*5].split('>')[1].split('<')[0])\n",
    "        hsp_to = int(allele[6+hsp*5].split('>')[1].split('<')[0])\n",
    "        hsp_qseq = allele[7+hsp*5].split('>')[1].split('<')[0]\n",
    "        hsp_hseq = allele[8+hsp*5].split('>')[1].split('<')[0]\n",
    "        hsp_midline = allele[9+hsp*5].split('>')[1].split('<')[0]\n",
    "        \n",
    "        if hsp_from == 1:\n",
    "            allele_reconstruction_temp_list.append((hsp_from, str(hsp_from)+':'+str(hsp_to), allele_ref_sequence[0:hsp_to], hsp_qseq, hsp_hseq, hsp_midline))\n",
    "        else:\n",
    "            allele_reconstruction_temp_list.append((hsp_from, str(hsp_from)+':'+str(hsp_to), allele_ref_sequence[hsp_from-1:hsp_to], hsp_qseq, hsp_hseq, hsp_midline))\n",
    "\n",
    "    allele_span_list = []\n",
    "    reference_span_list = []\n",
    "    alignment_midline_list = []\n",
    "    # prepare to account for bp spans from allele read as represented in fasta file, which are represented in hsps\n",
    "    allele_fasta_span_bp_accounting_set = set()\n",
    "    allele_fasta_span_bp = range(1,len(allele_fasta)+1)\n",
    "    allele_fasta_spans_in_hsps = set()\n",
    "    # prepare to account for bp spans from reference as represented in reference file, which are represented in hsps\n",
    "    reference_span_bp_accounting_set = set()\n",
    "    reference_span_bp = range(1,len(allele_ref_sequence)+1)\n",
    "    reference_spans_in_hsps = set()\n",
    "    # assess hsp match positions relative to ref span, and re-order if needed based on relative order of start and stop positions of hsp alignment\n",
    "    for subregion in sorted(allele_reconstruction_temp_list):\n",
    "        reference_spans_in_hsps.update(set(range(int(subregion[1].split(':')[0]),int(subregion[1].split(':')[1]))))\n",
    "        match = re.search(subregion[3].replace('-',''), allele_fasta)\n",
    "        allele_fasta_spans_in_hsps.update(range(match.span()[0],match.span()[1]))\n",
    "        \n",
    "    for index, subregion in enumerate(sorted(allele_reconstruction_temp_list)):\n",
    "        # subregion[0] is start position of hsp alignment match in reference; subregion[1] is string form of hsp coordinate span (start:end) relative to reference\n",
    "        # subregion[2] is direct sequence span from reference sequence; subregion[3] is query from allele; subregion[4] is hit from reference; subregion[5] is midline\n",
    "        if index == 0:\n",
    "            if subregion[0] == 1:\n",
    "                allele_span_list.append(subregion[3])\n",
    "                reference_span_list.append(subregion[4])\n",
    "                alignment_midline_list.append(subregion[5])\n",
    "                reference_span_bp_accounting_set.update(range(1,int(subregion[1].split(':')[1])))\n",
    "                # check for coverage in allele as represented in fasta file\n",
    "                match = re.search(subregion[3].replace('-',''), allele_fasta)\n",
    "                allele_fasta_span_bp_accounting_set.update(range(match.span()[0],match.span()[1]))\n",
    "                \n",
    "            else:\n",
    "                allele_span_list.append(subregion[3])\n",
    "                reference_span_list.append(subregion[4])\n",
    "                alignment_midline_list.append(subregion[5])\n",
    "                reference_span_bp_accounting_set.update(range(int(subregion[1].split(':')[0]),int(subregion[1].split(':')[1])))\n",
    "                # check for coverage in allele as represented in fasta file\n",
    "                match = re.search(subregion[3].replace('-',''), allele_fasta)\n",
    "                allele_fasta_span_bp_accounting_set.update(range(match.span()[0],match.span()[1]))\n",
    "                #allele_span_list.append('-'*subregion[0])\n",
    "                #reference_span_list.append(allele_ref_sequence[0:subregion[0]])\n",
    "                #alignment_midline_list.append(' '*subregion[0])\n",
    "                #reference_span_bp_accounting_set.update(range(1,int(subregion[1].split(':')[1]))) \n",
    "        elif len(sorted(allele_reconstruction_temp_list)) > index > 0:\n",
    "            test_span = range(int(sorted(allele_reconstruction_temp_list)[index-1][1].split(':')[1]), int(subregion[1].split(':')[0]))\n",
    "            \n",
    "            if reference_span_bp_accounting_set.intersection(test_span):\n",
    "                allele_span_list.append(subregion[3])\n",
    "                reference_span_list.append(subregion[4])\n",
    "                alignment_midline_list.append(subregion[5])\n",
    "                reference_span_bp_accounting_set.update(range(int(subregion[1].split(':')[0]),int(subregion[1].split(':')[1])))\n",
    "                match = re.search(subregion[3].replace('-',''), allele_fasta)\n",
    "                allele_fasta_span_bp_accounting_set.update(range(match.span()[0],match.span()[1]))\n",
    "            else:\n",
    "                match = re.search(subregion[3].replace('-',''), allele_fasta)\n",
    "                allele_fasta_span_bp_accounting_set.update(range(match.span()[0],match.span()[1]))\n",
    "                bases_in_fasta_allele_not_accounted_for_in_alignment = sorted(set(range(sorted(allele_fasta_span_bp_accounting_set)[0],sorted(allele_fasta_span_bp_accounting_set)[-1]))-allele_fasta_span_bp_accounting_set)\n",
    "                if len(bases_in_fasta_allele_not_accounted_for_in_alignment) > 0:\n",
    "                    bases_to_add = allele_fasta[bases_in_fasta_allele_not_accounted_for_in_alignment[0]:bases_in_fasta_allele_not_accounted_for_in_alignment[-1]+1]\n",
    "                    allele_fasta_span_bp_accounting_set.update(range(bases_in_fasta_allele_not_accounted_for_in_alignment[0],bases_in_fasta_allele_not_accounted_for_in_alignment[1]))\n",
    "                else:\n",
    "                    bases_to_add = ''\n",
    "                allele_span_list.append(bases_to_add)\n",
    "                allele_span_list.append('-'*(int(subregion[0])-int(sorted(allele_reconstruction_temp_list)[index-1][1].split(':')[1])-1-len(bases_to_add)))\n",
    "                reference_span_list.append(allele_ref_sequence[int(sorted(allele_reconstruction_temp_list)[index-1][1].split(':')[1]):int(subregion[0])-1])\n",
    "                alignment_midline_list.append(' '*(int(subregion[0])-int(sorted(allele_reconstruction_temp_list)[index-1][1].split(':')[1])-1))\n",
    "                reference_span_bp_accounting_set.update(range(int(subregion[1].split(':')[0]),int(subregion[1].split(':')[1])))\n",
    "                allele_span_list.append(subregion[3])\n",
    "                reference_span_list.append(subregion[4])\n",
    "                alignment_midline_list.append(subregion[5])\n",
    "                reference_span_bp_accounting_set.update(range(int(sorted(allele_reconstruction_temp_list)[index-1][1].split(':')[1])-1,int(subregion[1].split(':')[0])))\n",
    "\n",
    "    \n",
    "    # missing region of allele sequence as it appears in fasta\n",
    "    bases_in_fasta_allele_not_accounted_for_in_alignment = sorted(set(range(sorted(allele_fasta_span_bp_accounting_set)[0],sorted(allele_fasta_span_bp_accounting_set)[-1]))-allele_fasta_span_bp_accounting_set)\n",
    "    if len(bases_in_fasta_allele_not_accounted_for_in_alignment) > 0:   \n",
    "        bases_to_add = allele_fasta[bases_in_fasta_allele_not_accounted_for_in_alignment[0]:bases_in_fasta_allele_not_accounted_for_in_alignment[-1]+1]\n",
    "    else:\n",
    "        bases_to_add = ''\n",
    "        \n",
    "    reconstructed_hsp_from = str(int(sorted(list(reference_span_bp_accounting_set))[0])+1)\n",
    "    reconstructed_hsp_to = str(int(sorted(list(reference_span_bp_accounting_set))[-1])+1)\n",
    "    reconstructed_hsp_qseq =  ''.join(allele_span_list).strip('-')\n",
    "    reconstructed_hsp_hseq = ''.join(reference_span_list).strip('-')\n",
    "    reconstructed_hsp_midline = ''.join(alignment_midline_list)\n",
    "    \n",
    "    allele_reconstruction_list.append('<Hsp_hit-from>'+str(reconstructed_hsp_from)+'</Hsp_hit-from>')\n",
    "    allele_reconstruction_list.append('<Hsp_hit-to>'+str(reconstructed_hsp_to)+'</Hsp_hit-to>')\n",
    "    allele_reconstruction_list.append('<Hsp_qseq>'+reconstructed_hsp_qseq+'</Hsp_qseq>')\n",
    "    allele_reconstruction_list.append('<Hsp_hseq>'+reconstructed_hsp_hseq+'</Hsp_hseq>')\n",
    "    allele_reconstruction_list.append('<Hsp_midline>'+reconstructed_hsp_midline+'</Hsp_midline>')\n",
    "    \n",
    "    reconstructed_alleles_with_multiple_hsps_list.append(allele_reconstruction_list)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignments_list4 = []\n",
    "for i in alignments_list3:\n",
    "    if i not in multiple_alignments_hsp_list:\n",
    "        alignments_list4.append(i)\n",
    "for i in reconstructed_alleles_with_multiple_hsps_list:\n",
    "        alignments_list4.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In script_metrics.txt, log samples and allele IDs identified as having (1) no hits in alignment database or (2) multiple hits in alignment database, as well as (3) samples and allele IDs having more than 1 high-scoring pair (hsp) that the script was unable to reconstruct toward an alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use print redirection to write to target file, in append mode (append to script_metrics.txt)\n",
    "\n",
    "filename = Path(str(output_path)+'/'+processdate+'_script_metrics.txt')\n",
    "with open(filename, 'a') as f:\n",
    "    print(\"\\nRecord of ranked alleles deprecated from analysis output:\", file = f)\n",
    "    print(\"\\n    No hits identified by BLASTN in alignment database: \", file = f)\n",
    "    if len(no_hits_list) == 0:\n",
    "        print(\"        None\", file = f)    \n",
    "    else:\n",
    "        for i in no_hits_list:\n",
    "            print(\"        \"+i, file = f)\n",
    "    print(\"\\n    Multiple hits identified by BLASTN in alignment database: \", file = f)\n",
    "    if len(multiple_alignments_hits_list) == 0:\n",
    "        print(\"        None\", file = f) \n",
    "    else:\n",
    "        for i in multiple_alignments_hits_list:\n",
    "            print(\"        \"+i[1].split('>')[1].split('<')[0], file = f)  \n",
    "    print(\"\\n    >1 high-scoring pair (hsp) identified by BLASTN, but hsp's could not be reconstructed into a hypothesized allele: \", file = f)\n",
    "    if len(alleles_with_multiple_hsps_that_cannot_be_reconstructed_list) == 0:\n",
    "        print(\"        None\", file = f) \n",
    "    else:\n",
    "        for i in alleles_with_multiple_hsps_that_cannot_be_reconstructed_list:\n",
    "            print(\"        \"+i[1].split('>')[1].split('<')[0], file = f)\n",
    "    print(\"\\nRecord of ranked alleles reconstructed from >1 high-scoring pair (hsp):\", file = f)\n",
    "    print(\"\\n    >1 high-scoring pair (hsp) identified by BLASTN, and hsp's were reconstructed into a hypothesized allele: \", file = f)\n",
    "    if len(alleles_with_multiple_hsps_that_can_be_reconstructed_list) == 0:\n",
    "        print(\"        None\", file = f) \n",
    "    else:\n",
    "        for i in alleles_with_multiple_hsps_that_can_be_reconstructed_list:\n",
    "            print(\"        \"+i[1].split('>')[1].split('<')[0], file = f)   \n",
    "    print(\"\\n\", file = f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Finalize list containing candidate alleles with single alignment hit in reference database.  \n",
    "Prepare **'alignmentoutput_dict'**, a dictionary that aggregates all sample-associated alleles as sublists within a single list (value) assigned to appropriate sample name ID (key)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Among lists containing alignment data in alignments_list4, determine which queries (reads) correspond to the same sample; where querydef = i[1].split(\">\")[1].split(\"_[\")[0], reads belonging to the same sample share identical querydef\n",
    "# Fasta deflines encode frequency metrics for reads, based on defline format:\n",
    "# sampleID_[reads/total reads]_percentile_% read abundance_% top 10 reads_% reads filtered for 1%_% reads filtered for 10%\n",
    "querydef_list = []\n",
    "for i in alignments_list3:\n",
    "    querydef = i[1].split(\">\")[1].split(\"_\")[0]\n",
    "    querydef_list.append(querydef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "querydef_uniq_list = []\n",
    "for i in querydef_list:\n",
    "    if i in querydef_uniq_list:\n",
    "        pass\n",
    "    else:\n",
    "        querydef_uniq_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Prepare dictionary relating sample IDs to their associated reads ('alleles')      \n",
    "alignmentoutput_dict = {}\n",
    "for i in querydef_uniq_list:\n",
    "    alignmentoutput_dict[\"{0}\".format(i)] = tuple(x for x in alignments_list4 if bool(re.search(i, x[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify sample IDs for which no valid candidate alleles were identified. These samples are not further analyzed, but their identities are reported in 'script_metrics.txt'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Identify & subset sample ID's that do not have output alleles (empty tuple values in dictionary)\n",
    "empty_sampleIDs_list = []\n",
    "for i in alignmentoutput_dict:\n",
    "    if bool(alignmentoutput_dict.get(i) == ()):\n",
    "        empty_sampleIDs_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Make a copy of alignmentoutput_dict, removing dictionary keys with empty tuple values\n",
    "alignmentoutput_dict2 = { k : v for k,v in alignmentoutput_dict.items() if v}\n",
    "# Alignmentoutput_dict2 is the key dictionary for alignment information\n",
    "\n",
    "# Log allele definitions time duration\n",
    "allele_definitionsDuration = str(datetime.now() - startTime_alleles).split(':')[0]+' hr|'+str(datetime.now() - startTime_alleles).split(':')[1]+' min|'+str(datetime.now() - startTime_alleles).split(':')[2].split('.')[0]+' sec|'+str(datetime.now() - startTime_alleles).split(':')[2].split('.')[1]+' microsec'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VI. Identify TFBS matches to motifs (FIMO) in reference and candidate allele sequences\n",
    "Data for sample-specific alleles were assembled in **alignmentoutput_dict**, a dictionary that collected alignment data for each sample's top 5 reads, with each read's frequency metrics maintained in the allele name (defline). The contents of this dictionary are now further parsed, along with TFBS data collected by FIMO in **fimo.tsv** files, to generate repositories for TFBS matches identified for reference and allele sequences (**dict_ref_TFBS**, **dict_allele_TFBS**). TFBS in allele sequences are then compared to TFBS in cognate reference sequences to assemble **dict_allele_TFBS_synopsis**, which logs TFBS **gained** and **lost** in each allele relative to reference sequence.\n",
    "\n",
    "--------\n",
    "The output of these analytics is reported in **'collated_TFBS.txt'** and **'collated_TFBS.xlsx'**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Start the clock on FIMO operations duration      \n",
    "startTime_fimo = datetime.now()\n",
    "\n",
    "# Reference sequence input\n",
    "ref_input = Path(fasta_ref)\n",
    "\n",
    "# Reference sequence(s): FIMO file output directory\n",
    "ref_TFBS_output = output_path / 'fimo_out_ref'\n",
    "\n",
    "# alleles: FIMO file output directory      \n",
    "allele_TFBS_output = output_path / 'fimo_out'\n",
    "\n",
    "# Reference sequence(s): FIMO command (usage: fimo --bfile <background file> <motif file> <sequence file>)       \n",
    "cmd_TFBS = str(fimo_path)+' --bfile '+str(markovbackground_output)+' --o '+str(ref_TFBS_output)+' --thresh 1e-4'+' '+str(fimo_motifs_path)+' '+str(ref_input)\n",
    "\n",
    "os.system(cmd_TFBS)\n",
    "\n",
    "# Alleles: FIMO command (usage: fimo --bfile <background file> <motif file> <sequence file>) \n",
    "cmd_TFBS = str(fimo_path)+' --bfile '+str(markovbackground_output)+' --o '+str(allele_TFBS_output)+' --thresh 1e-4'+' '+str(fimo_motifs_path)+' '+str(query_input)\n",
    "\n",
    "os.system(cmd_TFBS)\n",
    "\n",
    "# Log FIMO operations time duration\n",
    "fimoDuration = str(datetime.now() - startTime_fimo).split(':')[0]+' hr|'+str(datetime.now() - startTime_fimo).split(':')[1]+' min|'+str(datetime.now() - startTime_fimo).split(':')[2].split('.')[0]+' sec|'+str(datetime.now() - startTime_fimo).split(':')[2].split('.')[1]+' microsec' \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collate TFBSs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Start the clock on TFBS collation operations duration\n",
    "startTime_TFBScollation = datetime.now()\n",
    "\n",
    "# TFBS output files exist for both reference sequences and alleles (two separate files, in two separate directories: fimo_out & fimo_out_ref)  \n",
    "# Prepare dictionary of TFBSs ID'ed, for each reference sample \n",
    "with open(str(ref_TFBS_output)+'/fimo.tsv', 'r') as file:\n",
    "    ref_lines = file.readlines()\n",
    "    \n",
    "# Remove FIMO header lines, etc.\n",
    "ref_lines = ref_lines[1:]\n",
    "for line in ref_lines.copy():\n",
    "    if len(line.split('\\t')) < 10:\n",
    "        ref_lines.remove(line)\n",
    "        \n",
    "# Convert to set for faster processing\n",
    "ref_lines = set(ref_lines)\n",
    "\n",
    "with open(str(ref_input)) as file:\n",
    "    fasta_lines = file.readlines()\n",
    "fasta_names = fasta_lines[0::2]\n",
    "fasta_names = [i.strip('\\n').strip('>') for i in fasta_names]\n",
    "ref_set = set(fasta_names)\n",
    "\n",
    "dict_ref_TFBS = {}\n",
    "for ref in ref_set:\n",
    "    dict_ref_TFBS[ref] = [] \n",
    "    \n",
    "# Take 3rd field of all lines as search for presence of key in dictionary, and add line as string in value list of key (allele)\n",
    "for line in ref_lines:\n",
    "    if line.split('\\t')[2].strip() in dict_ref_TFBS:\n",
    "        dict_ref_TFBS[line.split('\\t')[2]].append(line.strip())\n",
    "        \n",
    "# Prepare allele dictionary; first, populate with 'all_sites'.  Then, run comparison to 'dict_TFBS_ref' to define sites that are lost vs. gained relative to reference sequence.\n",
    "# Prepare dictionary of TFBSs ID'ed, for each sample allele\n",
    "\n",
    "dict_allele_TFBS = {}\n",
    "for allele in alignmentoutput_dict2:\n",
    "    dict_allele_TFBS[allele] = {}\n",
    "\n",
    "for allele in alignmentoutput_dict2:\n",
    "    for x in range(0, len(alignmentoutput_dict2.get(allele))):\n",
    "        dict_allele_TFBS[allele].update({alignmentoutput_dict2.get(allele)[x][1].split(\">\")[1].split(\"<\")[0]:[]})\n",
    "        \n",
    "with open(str(allele_TFBS_output)+'/fimo.tsv', 'r') as file:\n",
    "    allele_lines = file.readlines() \n",
    "\n",
    "# Remove FIMO header lines, etc.\n",
    "allele_lines = allele_lines[1:]\n",
    "for line in allele_lines.copy():\n",
    "    if len(line.split('\\t')) < 10:\n",
    "        allele_lines.remove(line)\n",
    "        \n",
    "# Convert to set for faster processing\n",
    "allele_lines = set(allele_lines)\n",
    "\n",
    "# Populate each allele with its 'all_sites' information\n",
    "for line in allele_lines:\n",
    "    dict_allele_TFBS_sample_key = line.split('\\t')[2].strip().split('_')[0]\n",
    "    dict_allele_TFBS_allele_key = line.split('\\t')[2].strip()\n",
    "    if dict_allele_TFBS_sample_key in dict_allele_TFBS:\n",
    "        if dict_allele_TFBS.get(dict_allele_TFBS_sample_key).get(dict_allele_TFBS_allele_key) is not None:\n",
    "            dict_allele_TFBS.get(dict_allele_TFBS_sample_key).get(dict_allele_TFBS_allele_key).append(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare synopsis dictionary: *gained*, *lost*, and *all_sites* sublists for each allele (*gained* and *lost* sublists populated by comparison of allele's *all_sites* list to *all_sites* list of reference sequence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Prepare synopsis dictionary with alleles as keys, and list of 3 sublists: gained, lost, all_sites      \n",
    "# Run comparison of 'all_sites' information relative to reference allele information.\n",
    "dict_allele_TFBS_synopsis = {}\n",
    "for allele in alignmentoutput_dict2:\n",
    "    dict_allele_TFBS_synopsis[allele] = {}\n",
    "    \n",
    "for allele in alignmentoutput_dict2:\n",
    "    for x in range(0, len(alignmentoutput_dict2.get(allele))):\n",
    "        dict_allele_TFBS_synopsis[allele].update({alignmentoutput_dict2.get(allele)[x][1].split(\">\")[1].split(\"<\")[0]:{'gained':[],'lost':[],'all_sites':[], 'TFs':{}, 'allele_sequence':[\n",
    "            alignmentoutput_dict2.get(allele)[x][7]]+[alignmentoutput_dict2.get(allele)[x][8]]+[alignmentoutput_dict2.get(allele)[x][9]]}})\n",
    "        \n",
    "for sample in dict_allele_TFBS_synopsis:\n",
    "    for allele in dict_allele_TFBS_synopsis.get(sample):\n",
    "        for motif in dict_allele_TFBS.get(sample).get(allele):\n",
    "            dict_allele_TFBS_synopsis.get(sample).get(allele).get('all_sites').append(motif.split('\\t')[1]+' ('+motif.split('\\t')[0]+'),'+motif.split('\\t')[5]+','+motif.split('\\t')[9]+','+motif.split('\\t')[7]+','+motif.split('\\t')[3]+','+motif.split('\\t')[4])\n",
    "            if motif.split('\\t')[0]+' ('+motif.split('\\t')[1]+')' not in dict_allele_TFBS_synopsis.get(sample).get(allele).get('TFs'):\n",
    "                count = 1\n",
    "                dict_allele_TFBS_synopsis.get(sample).get(allele).get('TFs').update({motif.split('\\t')[0]+' ('+motif.split('\\t')[1]+')':count})\n",
    "            else:\n",
    "                count = dict_allele_TFBS_synopsis.get(sample).get(allele).get('TFs').get(motif.split('\\t')[0]+' ('+motif.split('\\t')[1]+')')+1\n",
    "                dict_allele_TFBS_synopsis.get(sample).get(allele).get('TFs').update({motif.split('\\t')[0]+' ('+motif.split('\\t')[1]+')':count})\n",
    "\n",
    "# Run comparisons:\n",
    "# Make ref_TFBS_synopsis dictionary\n",
    "dict_ref_TFBS_synopsis = {}\n",
    "for ref in dict_ref_TFBS:\n",
    "    dict_ref_TFBS_synopsis[ref] = {'all_sites':[], 'TFs':{}}\n",
    "    \n",
    "\n",
    "# Summarize TF counts in reference sequences      \n",
    "for ref in dict_ref_TFBS_synopsis:    \n",
    "    for motif in dict_ref_TFBS.get(ref):\n",
    "        if motif.split('\\t')[0]+' ('+motif.split('\\t')[1]+')' not in dict_ref_TFBS_synopsis.get(ref).get('TFs'):\n",
    "            count = 1\n",
    "            dict_ref_TFBS_synopsis.get(ref).get('TFs').update({motif.split('\\t')[1]+' ('+motif.split('\\t')[0]+')':count})\n",
    "        else:\n",
    "            count = dict_ref_TFBS_synopsis.get(ref).get('TFs').get(motif.split('\\t')[0]+' ('+motif.split('\\t')[1]+')')+1\n",
    "            dict_ref_TFBS_synopsis.get(ref).get('TFs').update({motif.split('\\t')[1]+' ('+motif.split('\\t')[0]+')':count})\n",
    "            \n",
    "# Catalog TFBSs in reference sequences, in format akin to 'all_sites' format in dict_allele_TFBS_synopsis          \n",
    "for ref in dict_ref_TFBS_synopsis:\n",
    "    for motif in dict_ref_TFBS.get(ref):\n",
    "        dict_ref_TFBS_synopsis.get(ref).get('all_sites').append(motif.split('\\t')[1]+' ('+motif.split('\\t')[0]+'),'+motif.split('\\t')[5]+','+motif.split('\\t')[9]+','+motif.split('\\t')[7]+','+motif.split('\\t')[3]+','+motif.split('\\t')[4])\n",
    "        \n",
    "# Run comparisons, populating into dict_allele_TFBS_synopsis\n",
    "ref_options = [ref for ref in dict_ref_TFBS]\n",
    "for sample in dict_allele_TFBS_synopsis:\n",
    "    # define reference sequence appropriate to sample\n",
    "    for ref in ref_options:\n",
    "        if re.search(ref, sample):\n",
    "            sample_ref = ref\n",
    "    for allele in dict_allele_TFBS_synopsis.get(sample):\n",
    "        # check only for motifs that overlap aligned region between allele and ref\n",
    "        for x in alignmentoutput_dict2.get(sample):\n",
    "            if x[1].split('>')[1].split('<')[0] == allele:\n",
    "                to_from_range = range(int(x[5].split('>')[1].split('<')[0]),int(x[6].split('>')[1].split('<')[0]))\n",
    "        dict_allele_TFBS_synopsis.get(sample).get(allele)['ref_coordinates_span'] = to_from_range\n",
    "        ref_spans_represented_in_allele_hsps_temp = []\n",
    "        # get hsp aligment spans relative to reference coordinates\n",
    "        for index, x in enumerate(alignments_list3):\n",
    "            if x[1].split('>')[1].split('<')[0] == allele:\n",
    "                for i in range(5, len(alignments_list3[index]), 5):\n",
    "                    ref_spans_represented_in_allele_hsps_temp.append(range(int(alignments_list3[index][i].split('>')[1].split('<')[0])+1, int(alignments_list3[index][i+1].split('>')[1].split('<')[0])))\n",
    "                    ref_spans_represented_in_allele_hsps = sorted(list(i) for i in ref_spans_represented_in_allele_hsps_temp)\n",
    "        dict_allele_TFBS_synopsis.get(sample).get(allele)['hsp_alignment_spans'] = ref_spans_represented_in_allele_hsps   \n",
    "        ref_TFBS_set_to_include_in_evaluation = []\n",
    "        for ref_motif in dict_ref_TFBS_synopsis.get(sample_ref).get('all_sites'):\n",
    "            ref_motif_range = range(int(ref_motif.split(',')[4]), int(ref_motif.split(',')[5]))\n",
    "            if set(to_from_range).intersection(ref_motif_range):\n",
    "                ref_TFBS_set_to_include_in_evaluation.append(ref_motif)  \n",
    "        for motif in dict_allele_TFBS_synopsis.get(sample).get(allele).get('all_sites'):\n",
    "            # limit ref range\n",
    "            if motif.split(',')[:4] in [i.split(',')[:4] for i in ref_TFBS_set_to_include_in_evaluation]:\n",
    "                pass\n",
    "            else:\n",
    "                dict_allele_TFBS_synopsis.get(sample).get(allele).get('gained').append(motif)\n",
    "        for motif in ref_TFBS_set_to_include_in_evaluation:\n",
    "            if motif.split(',')[:4] in [i.split(',')[:4] for i in dict_allele_TFBS_synopsis.get(sample).get(allele).get('all_sites')]:\n",
    "                pass\n",
    "            else:\n",
    "                dict_allele_TFBS_synopsis.get(sample).get(allele).get('lost').append(motif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add allele ranks to allele names\n",
    "dict_allele_TFBS_synopsis_allele_ranks = {}\n",
    "\n",
    "for sample in dict_allele_TFBS_synopsis:\n",
    "    index_frequency_list = []\n",
    "    for index, allele in enumerate(dict_allele_TFBS_synopsis.get(sample)):\n",
    "        index_frequency_list.append((float(allele.split('_')[6].split(':')[1]), allele.split('_')[6], allele, index))\n",
    "        index_frequency_list_sorted = sorted(index_frequency_list, reverse=True)\n",
    "    dict_allele_TFBS_synopsis_allele_ranks[sample] = index_frequency_list_sorted\n",
    "    \n",
    "for sample in dict_allele_TFBS_synopsis:\n",
    "    for index, allele in enumerate(dict_allele_TFBS_synopsis.get(sample)):\n",
    "        for index, ranked_allele in enumerate(dict_allele_TFBS_synopsis_allele_ranks.get(sample)):\n",
    "            if allele == ranked_allele[2]:\n",
    "                allele_rank = index+1\n",
    "        dict_allele_TFBS_synopsis.get(sample).get(allele).update({'allele_rank': allele_rank})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take stock of gained and lost TFBS that positionally overlap in reference vs. allele (assessment of whether TFBS 'gained' for given TFs may in fact be 'regained' TFBS, in alleles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin interpretive assessment of whether TFBS 'gained' for given TFs may in fact be 'regained' TFBS, in alleles where TFBS for the same TF has been lost\n",
    "# In other words, small local base changes that disrupt a TFBS for a given TF may nevertheless supply a distinct TFBS for the same TF,\n",
    "# amounting to, in principle, a 'reconstitution' or preservation of potential TFBS for TF\n",
    "# First, convert lost/gained TFBS for each allele (per sample) to dataframe, allele_TFBS_synopsis_df\n",
    "\n",
    "sample_list = [] \n",
    "allele_count_list = []\n",
    "allele_list = []\n",
    "allele_sequence_list = []\n",
    "reference_sequence_list = []\n",
    "alignment_midline_list = []\n",
    "TF_list = []\n",
    "strand_list = []\n",
    "gained_TFBS_sequence_list = []\n",
    "lost_TFBS_sequence_list = []\n",
    "p_val_list = []\n",
    "lostvsgained_list = []\n",
    "allele_start_coordinate_list = []\n",
    "allele_stop_coordinate_list = []\n",
    "ref_start_coordinate_list = []\n",
    "ref_stop_coordinate_list = []\n",
    "\n",
    "for sample in dict_allele_TFBS_synopsis:\n",
    "    allele_count = 0\n",
    "    for allele in dict_allele_TFBS_synopsis.get(sample):\n",
    "        allele_count = allele_count+1\n",
    "        for TF_class in dict_allele_TFBS_synopsis.get(sample).get(allele):\n",
    "            if TF_class == 'lost':\n",
    "                if len(dict_allele_TFBS_synopsis.get(sample).get(allele).get('lost')) == 0:\n",
    "                    sample_list.append(sample)\n",
    "                    allele_count_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_rank'))\n",
    "                    allele_list.append(allele)\n",
    "                    allele_sequence_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[0].split('>')[1].split('<')[0].strip())\n",
    "                    reference_sequence_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[1].split('>')[1].split('<')[0].strip())\n",
    "                    alignment_midline_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[2].split('>')[1].split('<')[0].strip())   \n",
    "                    TF_list.append('n/a')\n",
    "                    strand_list.append('n/a')\n",
    "                    gained_TFBS_sequence_list.append('n/a')\n",
    "                    lost_TFBS_sequence_list.append('n/a')\n",
    "                    p_val_list.append('n/a')\n",
    "                    allele_start_coordinate_list.append('n/a')\n",
    "                    allele_stop_coordinate_list.append('n/a')\n",
    "                    ref_start_coordinate_list.append('n/a')\n",
    "                    ref_stop_coordinate_list.append('n/a')\n",
    "                    lostvsgained_list.append(\"No TFBS lost\")\n",
    "                else:\n",
    "                    for TF in dict_allele_TFBS_synopsis.get(sample).get(allele).get('lost'):\n",
    "                        sample_list.append(sample)\n",
    "                        allele_count_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_rank'))\n",
    "                        allele_list.append(allele)\n",
    "                        allele_sequence_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[0].split('>')[1].split('<')[0].strip())\n",
    "                        reference_sequence_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[1].split('>')[1].split('<')[0].strip())\n",
    "                        alignment_midline_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[2].split('>')[1].split('<')[0].strip())   \n",
    "                        TF_list.append(TF.split(',')[0])\n",
    "                        strand_list.append(TF.split(',')[1])\n",
    "                        gained_TFBS_sequence_list.append('n/a')\n",
    "                        lost_TFBS_sequence_list.append(TF.split(',')[2])                            \n",
    "                        p_val_list.append(TF.split(',')[3])\n",
    "                        allele_start_coordinate_list.append('n/a')\n",
    "                        allele_stop_coordinate_list.append('n/a')\n",
    "                        ref_start_coordinate_list.append(TF.split(',')[4])\n",
    "                        ref_stop_coordinate_list.append(TF.split(',')[5])\n",
    "                        lostvsgained_list.append('lost')\n",
    "            elif TF_class == 'gained':\n",
    "                if len(dict_allele_TFBS_synopsis.get(sample).get(allele).get('gained')) == 0:\n",
    "                    sample_list.append(sample)\n",
    "                    allele_count_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_rank'))\n",
    "                    allele_list.append(allele)\n",
    "                    allele_sequence_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[0].split('>')[1].split('<')[0].strip())\n",
    "                    reference_sequence_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[1].split('>')[1].split('<')[0].strip())\n",
    "                    alignment_midline_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[2].split('>')[1].split('<')[0].strip())\n",
    "                    TF_list.append('n/a')\n",
    "                    strand_list.append('n/a')\n",
    "                    gained_TFBS_sequence_list.append('n/a')\n",
    "                    lost_TFBS_sequence_list.append('n/a')\n",
    "                    p_val_list.append('n/a')\n",
    "                    allele_start_coordinate_list.append('n/a')\n",
    "                    allele_stop_coordinate_list.append('n/a')\n",
    "                    ref_start_coordinate_list.append('n/a')\n",
    "                    ref_stop_coordinate_list.append('n/a')\n",
    "                    lostvsgained_list.append(\"No TFBS gained\")\n",
    "                else:\n",
    "                    for TF in dict_allele_TFBS_synopsis.get(sample).get(allele).get('gained'):\n",
    "                        sample_list.append(sample)\n",
    "                        allele_count_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_rank'))\n",
    "                        allele_list.append(allele)\n",
    "                        allele_sequence_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[0].split('>')[1].split('<')[0].strip())\n",
    "                        reference_sequence_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[1].split('>')[1].split('<')[0].strip())\n",
    "                        alignment_midline_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[2].split('>')[1].split('<')[0].strip())\n",
    "                        TF_list.append(TF.split(',')[0])\n",
    "                        strand_list.append(TF.split(',')[1])\n",
    "                        gained_TFBS_sequence_list.append(TF.split(',')[2])\n",
    "                        lost_TFBS_sequence_list.append('n/a')                            \n",
    "                        p_val_list.append(TF.split(',')[3])\n",
    "                        allele_start_coordinate_list.append(TF.split(',')[4])\n",
    "                        allele_stop_coordinate_list.append(TF.split(',')[5])\n",
    "                        ref_start_coordinate_list.append('n/a')\n",
    "                        ref_stop_coordinate_list.append('n/a')\n",
    "                        lostvsgained_list.append('gained')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin interpretive assessment of whether TFBS 'gained' for given TFs may in fact be 'regained' TFBS, in alleles where TFBS for the same TF has been lost\n",
    "# In other words, small local base changes that disrupt a TFBS for a given TF may nevertheless supply a distinct TFBS for the same TF,\n",
    "# amounting to, in principle, a 'reconstitution' or preservation of potential TFBS for TF\n",
    "# First, convert lost/gained TFBS for each allele (per sample) to dataframe, allele_TFBS_synopsis_df\n",
    "\n",
    "sample_list = [] \n",
    "allele_count_list = []\n",
    "allele_list = []\n",
    "allele_sequence_list = []\n",
    "reference_sequence_list = []\n",
    "alignment_midline_list = []\n",
    "TF_list = []\n",
    "strand_list = []\n",
    "gained_TFBS_sequence_list = []\n",
    "lost_TFBS_sequence_list = []\n",
    "p_val_list = []\n",
    "lostvsgained_list = []\n",
    "allele_start_coordinate_list = []\n",
    "allele_stop_coordinate_list = []\n",
    "ref_start_coordinate_list = []\n",
    "ref_stop_coordinate_list = []\n",
    "\n",
    "for sample in dict_allele_TFBS_synopsis:\n",
    "    allele_count = 0\n",
    "    for allele in dict_allele_TFBS_synopsis.get(sample):\n",
    "        allele_count = allele_count+1\n",
    "        for TF_class in dict_allele_TFBS_synopsis.get(sample).get(allele):\n",
    "            if TF_class == 'lost':\n",
    "                # if allele alignment is to a subset of a longer user-provided reference span, coordinates\n",
    "                # must be converted to allele span coordinates (because coordinates in the 'lost' category are derived\n",
    "                # from reference sequence coordinates in dict_allele_TFBS_synopsis\n",
    "                if len(dict_allele_TFBS_synopsis.get(sample).get(allele).get('lost')) == 0:\n",
    "                    sample_list.append(sample)\n",
    "                    allele_count_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_rank'))\n",
    "                    allele_list.append(allele)\n",
    "                    allele_sequence_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[0].split('>')[1].split('<')[0].strip())\n",
    "                    reference_sequence_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[1].split('>')[1].split('<')[0].strip())\n",
    "                    alignment_midline_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[2].split('>')[1].split('<')[0].strip())   \n",
    "                    TF_list.append('n/a')\n",
    "                    strand_list.append('n/a')\n",
    "                    gained_TFBS_sequence_list.append('n/a')\n",
    "                    lost_TFBS_sequence_list.append('n/a')\n",
    "                    p_val_list.append('n/a')\n",
    "                    allele_start_coordinate_list.append('n/a')\n",
    "                    allele_stop_coordinate_list.append('n/a')\n",
    "                    ref_start_coordinate_list.append('n/a')\n",
    "                    ref_stop_coordinate_list.append('n/a')\n",
    "                    lostvsgained_list.append(\"No TFBS lost\")\n",
    "                else:\n",
    "                    # retrieve allele's alignment span to reference sequence\n",
    "                    ref_span = [dict_allele_TFBS_synopsis.get(sample).get(allele).get('ref_coordinates_span')[0],dict_allele_TFBS_synopsis.get(sample).get(allele).get('ref_coordinates_span')[-1]]\n",
    "                    # retrieve allele's intact span\n",
    "                    allele_length = len(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[0].split('>')[1].split('<')[0].replace('-',''))\n",
    "                    # retrieve allele's alignment span(s) relative to reference sequence\n",
    "                    dict_allele_TFBS_synopsis.get(sample).get(allele).get('hsp_alignment_spans')\n",
    "                    # retrieve intervening span between allele alignment spans relative to reference sequence\n",
    "                    if len(dict_allele_TFBS_synopsis.get(sample).get(allele).get('hsp_alignment_spans')) < 2:\n",
    "                        span = int(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[0].count('-'))\n",
    "                    else:\n",
    "                        span = int(dict_allele_TFBS_synopsis.get(sample).get(allele).get('hsp_alignment_spans')[1][0])-int(dict_allele_TFBS_synopsis.get(sample).get(allele).get('hsp_alignment_spans')[0][-1])  \n",
    "                    for TF in dict_allele_TFBS_synopsis.get(sample).get(allele).get('lost'):\n",
    "                        sample_list.append(sample)\n",
    "                        allele_count_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_rank'))\n",
    "                        allele_list.append(allele)\n",
    "                        allele_sequence_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[0].split('>')[1].split('<')[0].strip())\n",
    "                        reference_sequence_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[1].split('>')[1].split('<')[0].strip())\n",
    "                        alignment_midline_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[2].split('>')[1].split('<')[0].strip())   \n",
    "                        TF_list.append(TF.split(',')[0])\n",
    "                        strand_list.append(TF.split(',')[1])\n",
    "                        gained_TFBS_sequence_list.append('n/a')\n",
    "                        lost_TFBS_sequence_list.append(TF.split(',')[2])                            \n",
    "                        p_val_list.append(TF.split(',')[3])\n",
    "                        allele_start_coordinate_list.append('n/a')\n",
    "                        allele_stop_coordinate_list.append('n/a')\n",
    "                        # make adjustments in recorded 'lost' TFBS coordinates, to reflect coordinates as defined in allele span rather than coordinates as defined in reference span\n",
    "                        if set(range(int(TF.split(',')[4]), int(TF.split(',')[5]))).intersection(range(int(dict_allele_TFBS_synopsis.get(sample).get(allele).get('hsp_alignment_spans')[0][0]),\n",
    "                                                                                      int(dict_allele_TFBS_synopsis.get(sample).get(allele).get('hsp_alignment_spans')[0][-1]+1))):\n",
    "                            ref_start_coordinate_list.append(int(TF.split(',')[4])-ref_span[0])\n",
    "                            ref_stop_coordinate_list.append(int(TF.split(',')[5])-ref_span[0])\n",
    "                        elif set(range(int(TF.split(',')[4]), int(TF.split(',')[5]))).intersection(range(int(dict_allele_TFBS_synopsis.get(sample).get(allele).get('hsp_alignment_spans')[0][1]+1),\n",
    "                                                                                      int(dict_allele_TFBS_synopsis.get(sample).get(allele).get('hsp_alignment_spans')[1][0]))):\n",
    "                            ref_start_coordinate_list.append(int(TF.split(',')[4])-ref_span[0])\n",
    "                            ref_stop_coordinate_list.append(int(TF.split(',')[5])-ref_span[0])\n",
    "                        elif set(range(int(TF.split(',')[4]), int(TF.split(',')[5]))).intersection(range(int(dict_allele_TFBS_synopsis.get(sample).get(allele).get('hsp_alignment_spans')[1][0]),\n",
    "                                                                                      int(dict_allele_TFBS_synopsis.get(sample).get(allele).get('hsp_alignment_spans')[1][-1]+1))):\n",
    "                            ref_start_coordinate_list.append(int(TF.split(',')[4])-ref_span[0])\n",
    "                            ref_stop_coordinate_list.append(int(TF.split(',')[5])-ref_span[0])                       \n",
    "                        lostvsgained_list.append('lost')\n",
    "            elif TF_class == 'gained':\n",
    "                if len(dict_allele_TFBS_synopsis.get(sample).get(allele).get('gained')) == 0:\n",
    "                    sample_list.append(sample)\n",
    "                    allele_count_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_rank'))\n",
    "                    allele_list.append(allele)\n",
    "                    allele_sequence_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[0].split('>')[1].split('<')[0].strip())\n",
    "                    reference_sequence_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[1].split('>')[1].split('<')[0].strip())\n",
    "                    alignment_midline_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[2].split('>')[1].split('<')[0].strip())\n",
    "                    TF_list.append('n/a')\n",
    "                    strand_list.append('n/a')\n",
    "                    gained_TFBS_sequence_list.append('n/a')\n",
    "                    lost_TFBS_sequence_list.append('n/a')\n",
    "                    p_val_list.append('n/a')\n",
    "                    allele_start_coordinate_list.append('n/a')\n",
    "                    allele_stop_coordinate_list.append('n/a')\n",
    "                    ref_start_coordinate_list.append('n/a')\n",
    "                    ref_stop_coordinate_list.append('n/a')\n",
    "                    lostvsgained_list.append(\"No TFBS gained\")\n",
    "                else:\n",
    "                    # retrieve allele's alignment span to reference sequence\n",
    "                    ref_span = [dict_allele_TFBS_synopsis.get(sample).get(allele).get('ref_coordinates_span')[0],dict_allele_TFBS_synopsis.get(sample).get(allele).get('ref_coordinates_span')[-1]]\n",
    "                    # retrieve allele's intact span\n",
    "                    allele_length = len(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[0].split('>')[1].split('<')[0].replace('-',''))\n",
    "                    # retrieve allele's alignment span(s) relative to reference sequence\n",
    "                    dict_allele_TFBS_synopsis.get(sample).get(allele).get('hsp_alignment_spans')\n",
    "                    # retrieve intervening span between allele alignment spans relative to reference sequence\n",
    "                    if len(dict_allele_TFBS_synopsis.get(sample).get(allele).get('hsp_alignment_spans')) < 2:\n",
    "                        span = int(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[0].count('-'))\n",
    "                    else:\n",
    "                        span = int(dict_allele_TFBS_synopsis.get(sample).get(allele).get('hsp_alignment_spans')[1][0])-int(dict_allele_TFBS_synopsis.get(sample).get(allele).get('hsp_alignment_spans')[0][-1])   \n",
    "                    for TF in dict_allele_TFBS_synopsis.get(sample).get(allele).get('gained'):\n",
    "                        sample_list.append(sample)\n",
    "                        allele_count_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_rank'))\n",
    "                        allele_list.append(allele)\n",
    "                        allele_sequence_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[0].split('>')[1].split('<')[0].strip())\n",
    "                        reference_sequence_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[1].split('>')[1].split('<')[0].strip())\n",
    "                        alignment_midline_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[2].split('>')[1].split('<')[0].strip())\n",
    "                        TF_list.append(TF.split(',')[0])\n",
    "                        strand_list.append(TF.split(',')[1])\n",
    "                        gained_TFBS_sequence_list.append(TF.split(',')[2])\n",
    "                        lost_TFBS_sequence_list.append('n/a')                            \n",
    "                        p_val_list.append(TF.split(',')[3])\n",
    "                        allele_start_coordinate_list.append(TF.split(',')[4])\n",
    "                        allele_stop_coordinate_list.append(TF.split(',')[5]) \n",
    "                        ref_start_coordinate_list.append('n/a')\n",
    "                        ref_stop_coordinate_list.append('n/a')\n",
    "                        lostvsgained_list.append('gained')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*allele_TFBS_synopsis_df*: dataframe synopsis of samples and alleles, with individual rows detailing TFBSs lost or gained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>allele rank</th>\n",
       "      <th>allele ID</th>\n",
       "      <th>alignment query\n",
       "(allele sequence)</th>\n",
       "      <th>alignment midline</th>\n",
       "      <th>alignment hit\n",
       "(reference)</th>\n",
       "      <th>TF</th>\n",
       "      <th>strand</th>\n",
       "      <th>Lost TFBS sequence (in reference at this position, lost in allele)\n",
       "*Note: this TFBS sequence is in the reference, 5'-3' on strand indicated in 'strand'</th>\n",
       "      <th>Lost TFBS start coordinate (in reference)</th>\n",
       "      <th>Lost TFBS end coordinate (in reference)</th>\n",
       "      <th>Gained TFBS sequence (not in reference at this position, novel to allele)\n",
       "*Note: this TFBS sequence is in the allele, 5'-3' on strand indicated in 'strand'</th>\n",
       "      <th>Gained TFBS start coordinate (in allele)</th>\n",
       "      <th>Gained TFBS end coordinate (in allele)</th>\n",
       "      <th>p-val</th>\n",
       "      <th>lost or gained in allele (relative to ref)?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Ar (MA0007.3)</td>\n",
       "      <td>+</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>3.26e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Ar (MA0007.3)</td>\n",
       "      <td>-</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.66e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>E2F7 (MA0758.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>TTTTCCCCCCTATT</td>\n",
       "      <td>135</td>\n",
       "      <td>148</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.09e-05</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>E2F7 (MA0758.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>TTTTCCCCCCAAAC</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>3.04e-06</td>\n",
       "      <td>gained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>E2F8 (MA0865.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>TTTCCCCCCTAT</td>\n",
       "      <td>136</td>\n",
       "      <td>147</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.41e-05</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>E2F8 (MA0865.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>TTTTCCCCCCAA</td>\n",
       "      <td>55</td>\n",
       "      <td>66</td>\n",
       "      <td>3.6e-05</td>\n",
       "      <td>gained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>E2F8 (MA0865.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>TTTCCCCCCAAA</td>\n",
       "      <td>54</td>\n",
       "      <td>65</td>\n",
       "      <td>9.78e-08</td>\n",
       "      <td>gained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>HIC2 (MA0738.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>GTGCCAGCC</td>\n",
       "      <td>86</td>\n",
       "      <td>94</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>5.37e-05</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Hic1 (MA0739.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>GTGCCAGCC</td>\n",
       "      <td>86</td>\n",
       "      <td>94</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>5.97e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>MEIS1 (MA0498.2)</td>\n",
       "      <td>+</td>\n",
       "      <td>CTGACAG</td>\n",
       "      <td>109</td>\n",
       "      <td>115</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>4.53e-05</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>MEIS2 (MA0774.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>CTGACAGC</td>\n",
       "      <td>109</td>\n",
       "      <td>116</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>6.8e-05</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Mafb (MA0117.2)</td>\n",
       "      <td>+</td>\n",
       "      <td>GATGTGCTGACA</td>\n",
       "      <td>103</td>\n",
       "      <td>114</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.25e-05</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C1 (MA0113.3)</td>\n",
       "      <td>+</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.95e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C1 (MA0113.3)</td>\n",
       "      <td>-</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.03e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C2 (MA0727.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>ATGAACTCGATGTGCTG</td>\n",
       "      <td>95</td>\n",
       "      <td>111</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>9.39e-05</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C2 (MA0727.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.62e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C2 (MA0727.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.67e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NRL (MA0842.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>GATGTGCTGAC</td>\n",
       "      <td>103</td>\n",
       "      <td>113</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.79e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>RARA::RXRA (MA0159.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>AGTTCATGTGCCAGCCA</td>\n",
       "      <td>85</td>\n",
       "      <td>101</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>8.03e-05</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>RXRA::VDR (MA0074.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>AGCACATCGAGTTCA</td>\n",
       "      <td>96</td>\n",
       "      <td>110</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>6.66e-05</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>SMAD2::SMAD3::SMAD4 (MA0513.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>GTGGCTGGCACAT</td>\n",
       "      <td>84</td>\n",
       "      <td>96</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>7.99e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Vdr (MA0693.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>CAGCACATCGAGTTCA</td>\n",
       "      <td>96</td>\n",
       "      <td>111</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>4.58e-05</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-1-C02_R1+R2_[8/144]_rank2_%totalreads:5.56...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTC</td>\n",
       "      <td>|||||||||||||||||||||||||||||</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTC</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>No TFBS lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-1-C02_R1+R2_[8/144]_rank2_%totalreads:5.56...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTC</td>\n",
       "      <td>|||||||||||||||||||||||||||||</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTC</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>No TFBS gained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>No TFBS lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>No TFBS gained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-2-A01_R1+R2_[140/435]_rank2_%totalreads:32...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Ar (MA0007.3)</td>\n",
       "      <td>+</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>3.26e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-2-A01_R1+R2_[140/435]_rank2_%totalreads:32...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Ar (MA0007.3)</td>\n",
       "      <td>+</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>CAGAACACCCTGTTTTG</td>\n",
       "      <td>66</td>\n",
       "      <td>82</td>\n",
       "      <td>7.45e-05</td>\n",
       "      <td>gained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-2-A01_R1+R2_[140/435]_rank2_%totalreads:32...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Ar (MA0007.3)</td>\n",
       "      <td>-</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.66e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-2-A01_R1+R2_[140/435]_rank2_%totalreads:32...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Ar (MA0007.3)</td>\n",
       "      <td>-</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>CAAAACAGGGTGTTCTG</td>\n",
       "      <td>66</td>\n",
       "      <td>82</td>\n",
       "      <td>5.9e-05</td>\n",
       "      <td>gained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-4-G10_R1+R2_[347/806]_rank1_%totalreads:43...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C2 (MA0727.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.67e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-4-G10_R1+R2_[347/806]_rank1_%totalreads:43...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C2 (MA0727.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>CATAACAGGGTGTTCTG</td>\n",
       "      <td>66</td>\n",
       "      <td>82</td>\n",
       "      <td>4.99e-05</td>\n",
       "      <td>gained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Ar (MA0007.3)</td>\n",
       "      <td>+</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>3.26e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Ar (MA0007.3)</td>\n",
       "      <td>-</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.66e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C1 (MA0113.3)</td>\n",
       "      <td>+</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.95e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C1 (MA0113.3)</td>\n",
       "      <td>-</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.03e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C2 (MA0727.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.62e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C2 (MA0727.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.67e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>No TFBS gained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>3</td>\n",
       "      <td>KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Ar (MA0007.3)</td>\n",
       "      <td>+</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>3.26e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>3</td>\n",
       "      <td>KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Ar (MA0007.3)</td>\n",
       "      <td>+</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>CAGAACACCCTGTTATG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>7.86e-05</td>\n",
       "      <td>gained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>3</td>\n",
       "      <td>KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Ar (MA0007.3)</td>\n",
       "      <td>-</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.66e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>3</td>\n",
       "      <td>KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Ar (MA0007.3)</td>\n",
       "      <td>-</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>CATAACAGGGTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>6.74e-05</td>\n",
       "      <td>gained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>3</td>\n",
       "      <td>KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C1 (MA0113.3)</td>\n",
       "      <td>+</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.95e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>3</td>\n",
       "      <td>KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C1 (MA0113.3)</td>\n",
       "      <td>+</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>CAGAACACCCTGTTATG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>7.71e-05</td>\n",
       "      <td>gained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>3</td>\n",
       "      <td>KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C1 (MA0113.3)</td>\n",
       "      <td>-</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.03e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>3</td>\n",
       "      <td>KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C1 (MA0113.3)</td>\n",
       "      <td>-</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>CATAACAGGGTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>5.74e-05</td>\n",
       "      <td>gained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>3</td>\n",
       "      <td>KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C2 (MA0727.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.62e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>3</td>\n",
       "      <td>KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C2 (MA0727.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.67e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>3</td>\n",
       "      <td>KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C2 (MA0727.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>CATAACAGGGTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>4.99e-05</td>\n",
       "      <td>gained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>3</td>\n",
       "      <td>KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>SOX9 (MA0077.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>CTATTGTTC</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>1.53e-05</td>\n",
       "      <td>gained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>3</td>\n",
       "      <td>KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Sox6 (MA0515.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>CTATTGTTCT</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>gained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Ar (MA0007.3)</td>\n",
       "      <td>+</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>3.26e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Ar (MA0007.3)</td>\n",
       "      <td>-</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.66e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C1 (MA0113.3)</td>\n",
       "      <td>+</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.95e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C1 (MA0113.3)</td>\n",
       "      <td>-</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.03e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C2 (MA0727.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.62e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C2 (MA0727.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.67e-06</td>\n",
       "      <td>lost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>SOX9 (MA0077.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>CTATTGTTC</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>1.53e-05</td>\n",
       "      <td>gained</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Sox6 (MA0515.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>CTATTGTTCT</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>gained</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sample  allele rank  \\\n",
       "21   KE4-1-C02            1   \n",
       "20   KE4-1-C02            1   \n",
       "5    KE4-1-C02            1   \n",
       "4    KE4-1-C02            1   \n",
       "23   KE4-1-C02            1   \n",
       "2    KE4-1-C02            1   \n",
       "3    KE4-1-C02            1   \n",
       "8    KE4-1-C02            1   \n",
       "9    KE4-1-C02            1   \n",
       "15   KE4-1-C02            1   \n",
       "10   KE4-1-C02            1   \n",
       "7    KE4-1-C02            1   \n",
       "19   KE4-1-C02            1   \n",
       "11   KE4-1-C02            1   \n",
       "13   KE4-1-C02            1   \n",
       "18   KE4-1-C02            1   \n",
       "22   KE4-1-C02            1   \n",
       "12   KE4-1-C02            1   \n",
       "17   KE4-1-C02            1   \n",
       "16   KE4-1-C02            1   \n",
       "6    KE4-1-C02            1   \n",
       "14   KE4-1-C02            1   \n",
       "1    KE4-1-C02            2   \n",
       "0    KE4-1-C02            2   \n",
       "25   KE4-2-A01            1   \n",
       "24   KE4-2-A01            1   \n",
       "37   KE4-2-A01            2   \n",
       "26   KE4-2-A01            2   \n",
       "36   KE4-2-A01            2   \n",
       "30   KE4-2-A01            2   \n",
       "..         ...          ...   \n",
       "110  KE4-4-G10            1   \n",
       "104  KE4-4-G10            1   \n",
       "116  KE4-4-G10            2   \n",
       "115  KE4-4-G10            2   \n",
       "114  KE4-4-G10            2   \n",
       "112  KE4-4-G10            2   \n",
       "113  KE4-4-G10            2   \n",
       "117  KE4-4-G10            2   \n",
       "111  KE4-4-G10            2   \n",
       "129  KE4-4-G10            3   \n",
       "124  KE4-4-G10            3   \n",
       "128  KE4-4-G10            3   \n",
       "122  KE4-4-G10            3   \n",
       "127  KE4-4-G10            3   \n",
       "123  KE4-4-G10            3   \n",
       "125  KE4-4-G10            3   \n",
       "119  KE4-4-G10            3   \n",
       "126  KE4-4-G10            3   \n",
       "130  KE4-4-G10            3   \n",
       "120  KE4-4-G10            3   \n",
       "118  KE4-4-G10            3   \n",
       "121  KE4-4-G10            3   \n",
       "137  KE4-4-G10            4   \n",
       "136  KE4-4-G10            4   \n",
       "135  KE4-4-G10            4   \n",
       "133  KE4-4-G10            4   \n",
       "134  KE4-4-G10            4   \n",
       "138  KE4-4-G10            4   \n",
       "132  KE4-4-G10            4   \n",
       "131  KE4-4-G10            4   \n",
       "\n",
       "                                             allele ID  \\\n",
       "21   KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "20   KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "5    KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "4    KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "23   KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "2    KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "3    KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "8    KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "9    KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "15   KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "10   KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "7    KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "19   KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "11   KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "13   KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "18   KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "22   KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "12   KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "17   KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "16   KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "6    KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "14   KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "1    KE4-1-C02_R1+R2_[8/144]_rank2_%totalreads:5.56...   \n",
       "0    KE4-1-C02_R1+R2_[8/144]_rank2_%totalreads:5.56...   \n",
       "25   KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...   \n",
       "24   KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...   \n",
       "37   KE4-2-A01_R1+R2_[140/435]_rank2_%totalreads:32...   \n",
       "26   KE4-2-A01_R1+R2_[140/435]_rank2_%totalreads:32...   \n",
       "36   KE4-2-A01_R1+R2_[140/435]_rank2_%totalreads:32...   \n",
       "30   KE4-2-A01_R1+R2_[140/435]_rank2_%totalreads:32...   \n",
       "..                                                 ...   \n",
       "110  KE4-4-G10_R1+R2_[347/806]_rank1_%totalreads:43...   \n",
       "104  KE4-4-G10_R1+R2_[347/806]_rank1_%totalreads:43...   \n",
       "116  KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...   \n",
       "115  KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...   \n",
       "114  KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...   \n",
       "112  KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...   \n",
       "113  KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...   \n",
       "117  KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...   \n",
       "111  KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...   \n",
       "129  KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...   \n",
       "124  KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...   \n",
       "128  KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...   \n",
       "122  KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...   \n",
       "127  KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...   \n",
       "123  KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...   \n",
       "125  KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...   \n",
       "119  KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...   \n",
       "126  KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...   \n",
       "130  KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...   \n",
       "120  KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...   \n",
       "118  KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...   \n",
       "121  KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...   \n",
       "137  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...   \n",
       "136  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...   \n",
       "135  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...   \n",
       "133  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...   \n",
       "134  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...   \n",
       "138  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...   \n",
       "132  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...   \n",
       "131  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...   \n",
       "\n",
       "                    alignment query\\n(allele sequence)  \\\n",
       "21   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "20   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "5    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "4    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "23   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "2    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "3    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "8    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "9    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "15   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "10   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "7    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "19   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "11   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "13   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "18   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "22   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "12   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "17   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "16   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "6    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "14   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "1                        ACTTAAACTGGAGCTCTGACTTATTGTTC   \n",
       "0                        ACTTAAACTGGAGCTCTGACTTATTGTTC   \n",
       "25   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "24   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "37   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "26   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "36   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "30   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "..                                                 ...   \n",
       "110  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "104  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "116  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "115  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "114  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "112  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "113  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "117  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "111  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "129  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "124  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "128  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "122  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "127  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "123  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "125  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "119  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "126  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "130  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "120  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "118  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "121  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "137  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "136  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "135  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "133  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "134  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "138  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "132  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "131  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "\n",
       "                                     alignment midline  \\\n",
       "21   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "20   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "5    ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "4    ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "23   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "2    ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "3    ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "8    ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "9    ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "15   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "10   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "7    ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "19   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "11   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "13   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "18   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "22   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "12   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "17   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "16   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "6    ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "14   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "1                        |||||||||||||||||||||||||||||   \n",
       "0                        |||||||||||||||||||||||||||||   \n",
       "25   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "24   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "37   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "26   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "36   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "30   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "..                                                 ...   \n",
       "110  ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "104  ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "116  ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "115  ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "114  ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "112  ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "113  ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "117  ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "111  ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "129  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "124  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "128  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "122  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "127  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "123  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "125  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "119  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "126  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "130  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "120  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "118  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "121  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "137  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "136  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "135  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "133  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "134  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "138  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "132  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "131  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "\n",
       "                            alignment hit\\n(reference)  \\\n",
       "21   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "20   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "5    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "4    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "23   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "2    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "3    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "8    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "9    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "15   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "10   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "7    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "19   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "11   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "13   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "18   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "22   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "12   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "17   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "16   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "6    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "14   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "1                        ACTTAAACTGGAGCTCTGACTTATTGTTC   \n",
       "0                        ACTTAAACTGGAGCTCTGACTTATTGTTC   \n",
       "25   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "24   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "37   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "26   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "36   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "30   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "..                                                 ...   \n",
       "110  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "104  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "116  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "115  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "114  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "112  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "113  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "117  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "111  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "129  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "124  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "128  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "122  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "127  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "123  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "125  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "119  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "126  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "130  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "120  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "118  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "121  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "137  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "136  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "135  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "133  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "134  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "138  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "132  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "131  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "\n",
       "                                 TF strand  \\\n",
       "21                    Ar (MA0007.3)      +   \n",
       "20                    Ar (MA0007.3)      -   \n",
       "5                   E2F7 (MA0758.1)      -   \n",
       "4                   E2F7 (MA0758.1)      -   \n",
       "23                  E2F8 (MA0865.1)      -   \n",
       "2                   E2F8 (MA0865.1)      -   \n",
       "3                   E2F8 (MA0865.1)      -   \n",
       "8                   HIC2 (MA0738.1)      -   \n",
       "9                   Hic1 (MA0739.1)      -   \n",
       "15                 MEIS1 (MA0498.2)      +   \n",
       "10                 MEIS2 (MA0774.1)      +   \n",
       "7                   Mafb (MA0117.2)      +   \n",
       "19                 NR3C1 (MA0113.3)      +   \n",
       "11                 NR3C1 (MA0113.3)      -   \n",
       "13                 NR3C2 (MA0727.1)      +   \n",
       "18                 NR3C2 (MA0727.1)      +   \n",
       "22                 NR3C2 (MA0727.1)      -   \n",
       "12                   NRL (MA0842.1)      +   \n",
       "17            RARA::RXRA (MA0159.1)      -   \n",
       "16             RXRA::VDR (MA0074.1)      -   \n",
       "6    SMAD2::SMAD3::SMAD4 (MA0513.1)      +   \n",
       "14                   Vdr (MA0693.1)      -   \n",
       "1                               n/a    n/a   \n",
       "0                               n/a    n/a   \n",
       "25                              n/a    n/a   \n",
       "24                              n/a    n/a   \n",
       "37                    Ar (MA0007.3)      +   \n",
       "26                    Ar (MA0007.3)      +   \n",
       "36                    Ar (MA0007.3)      -   \n",
       "30                    Ar (MA0007.3)      -   \n",
       "..                              ...    ...   \n",
       "110                NR3C2 (MA0727.1)      -   \n",
       "104                NR3C2 (MA0727.1)      -   \n",
       "116                   Ar (MA0007.3)      +   \n",
       "115                   Ar (MA0007.3)      -   \n",
       "114                NR3C1 (MA0113.3)      +   \n",
       "112                NR3C1 (MA0113.3)      -   \n",
       "113                NR3C2 (MA0727.1)      +   \n",
       "117                NR3C2 (MA0727.1)      -   \n",
       "111                             n/a    n/a   \n",
       "129                   Ar (MA0007.3)      +   \n",
       "124                   Ar (MA0007.3)      +   \n",
       "128                   Ar (MA0007.3)      -   \n",
       "122                   Ar (MA0007.3)      -   \n",
       "127                NR3C1 (MA0113.3)      +   \n",
       "123                NR3C1 (MA0113.3)      +   \n",
       "125                NR3C1 (MA0113.3)      -   \n",
       "119                NR3C1 (MA0113.3)      -   \n",
       "126                NR3C2 (MA0727.1)      +   \n",
       "130                NR3C2 (MA0727.1)      -   \n",
       "120                NR3C2 (MA0727.1)      -   \n",
       "118                 SOX9 (MA0077.1)      +   \n",
       "121                 Sox6 (MA0515.1)      +   \n",
       "137                   Ar (MA0007.3)      +   \n",
       "136                   Ar (MA0007.3)      -   \n",
       "135                NR3C1 (MA0113.3)      +   \n",
       "133                NR3C1 (MA0113.3)      -   \n",
       "134                NR3C2 (MA0727.1)      +   \n",
       "138                NR3C2 (MA0727.1)      -   \n",
       "132                 SOX9 (MA0077.1)      +   \n",
       "131                 Sox6 (MA0515.1)      +   \n",
       "\n",
       "    Lost TFBS sequence (in reference at this position, lost in allele)\\n*Note: this TFBS sequence is in the reference, 5'-3' on strand indicated in 'strand'  \\\n",
       "21                                   CAGAACACCCTGTTCTG                                                                                                         \n",
       "20                                   CAGAACAGGGTGTTCTG                                                                                                         \n",
       "5                                       TTTTCCCCCCTATT                                                                                                         \n",
       "4                                                  n/a                                                                                                         \n",
       "23                                        TTTCCCCCCTAT                                                                                                         \n",
       "2                                                  n/a                                                                                                         \n",
       "3                                                  n/a                                                                                                         \n",
       "8                                            GTGCCAGCC                                                                                                         \n",
       "9                                            GTGCCAGCC                                                                                                         \n",
       "15                                             CTGACAG                                                                                                         \n",
       "10                                            CTGACAGC                                                                                                         \n",
       "7                                         GATGTGCTGACA                                                                                                         \n",
       "19                                   CAGAACACCCTGTTCTG                                                                                                         \n",
       "11                                   CAGAACAGGGTGTTCTG                                                                                                         \n",
       "13                                   ATGAACTCGATGTGCTG                                                                                                         \n",
       "18                                   CAGAACACCCTGTTCTG                                                                                                         \n",
       "22                                   CAGAACAGGGTGTTCTG                                                                                                         \n",
       "12                                         GATGTGCTGAC                                                                                                         \n",
       "17                                   AGTTCATGTGCCAGCCA                                                                                                         \n",
       "16                                     AGCACATCGAGTTCA                                                                                                         \n",
       "6                                        GTGGCTGGCACAT                                                                                                         \n",
       "14                                    CAGCACATCGAGTTCA                                                                                                         \n",
       "1                                                  n/a                                                                                                         \n",
       "0                                                  n/a                                                                                                         \n",
       "25                                                 n/a                                                                                                         \n",
       "24                                                 n/a                                                                                                         \n",
       "37                                   CAGAACACCCTGTTCTG                                                                                                         \n",
       "26                                                 n/a                                                                                                         \n",
       "36                                   CAGAACAGGGTGTTCTG                                                                                                         \n",
       "30                                                 n/a                                                                                                         \n",
       "..                                                 ...                                                                                                         \n",
       "110                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "104                                                n/a                                                                                                         \n",
       "116                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "115                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "114                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "112                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "113                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "117                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "111                                                n/a                                                                                                         \n",
       "129                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "124                                                n/a                                                                                                         \n",
       "128                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "122                                                n/a                                                                                                         \n",
       "127                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "123                                                n/a                                                                                                         \n",
       "125                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "119                                                n/a                                                                                                         \n",
       "126                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "130                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "120                                                n/a                                                                                                         \n",
       "118                                                n/a                                                                                                         \n",
       "121                                                n/a                                                                                                         \n",
       "137                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "136                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "135                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "133                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "134                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "138                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "132                                                n/a                                                                                                         \n",
       "131                                                n/a                                                                                                         \n",
       "\n",
       "    Lost TFBS start coordinate (in reference)  \\\n",
       "21                                         64   \n",
       "20                                         64   \n",
       "5                                         135   \n",
       "4                                         n/a   \n",
       "23                                        136   \n",
       "2                                         n/a   \n",
       "3                                         n/a   \n",
       "8                                          86   \n",
       "9                                          86   \n",
       "15                                        109   \n",
       "10                                        109   \n",
       "7                                         103   \n",
       "19                                         64   \n",
       "11                                         64   \n",
       "13                                         95   \n",
       "18                                         64   \n",
       "22                                         64   \n",
       "12                                        103   \n",
       "17                                         85   \n",
       "16                                         96   \n",
       "6                                          84   \n",
       "14                                         96   \n",
       "1                                         n/a   \n",
       "0                                         n/a   \n",
       "25                                        n/a   \n",
       "24                                        n/a   \n",
       "37                                         65   \n",
       "26                                        n/a   \n",
       "36                                         65   \n",
       "30                                        n/a   \n",
       "..                                        ...   \n",
       "110                                        65   \n",
       "104                                       n/a   \n",
       "116                                        65   \n",
       "115                                        65   \n",
       "114                                        65   \n",
       "112                                        65   \n",
       "113                                        65   \n",
       "117                                        65   \n",
       "111                                       n/a   \n",
       "129                                        65   \n",
       "124                                       n/a   \n",
       "128                                        65   \n",
       "122                                       n/a   \n",
       "127                                        65   \n",
       "123                                       n/a   \n",
       "125                                        65   \n",
       "119                                       n/a   \n",
       "126                                        65   \n",
       "130                                        65   \n",
       "120                                       n/a   \n",
       "118                                       n/a   \n",
       "121                                       n/a   \n",
       "137                                        65   \n",
       "136                                        65   \n",
       "135                                        65   \n",
       "133                                        65   \n",
       "134                                        65   \n",
       "138                                        65   \n",
       "132                                       n/a   \n",
       "131                                       n/a   \n",
       "\n",
       "    Lost TFBS end coordinate (in reference)  \\\n",
       "21                                       80   \n",
       "20                                       80   \n",
       "5                                       148   \n",
       "4                                       n/a   \n",
       "23                                      147   \n",
       "2                                       n/a   \n",
       "3                                       n/a   \n",
       "8                                        94   \n",
       "9                                        94   \n",
       "15                                      115   \n",
       "10                                      116   \n",
       "7                                       114   \n",
       "19                                       80   \n",
       "11                                       80   \n",
       "13                                      111   \n",
       "18                                       80   \n",
       "22                                       80   \n",
       "12                                      113   \n",
       "17                                      101   \n",
       "16                                      110   \n",
       "6                                        96   \n",
       "14                                      111   \n",
       "1                                       n/a   \n",
       "0                                       n/a   \n",
       "25                                      n/a   \n",
       "24                                      n/a   \n",
       "37                                       81   \n",
       "26                                      n/a   \n",
       "36                                       81   \n",
       "30                                      n/a   \n",
       "..                                      ...   \n",
       "110                                      81   \n",
       "104                                     n/a   \n",
       "116                                      81   \n",
       "115                                      81   \n",
       "114                                      81   \n",
       "112                                      81   \n",
       "113                                      81   \n",
       "117                                      81   \n",
       "111                                     n/a   \n",
       "129                                      81   \n",
       "124                                     n/a   \n",
       "128                                      81   \n",
       "122                                     n/a   \n",
       "127                                      81   \n",
       "123                                     n/a   \n",
       "125                                      81   \n",
       "119                                     n/a   \n",
       "126                                      81   \n",
       "130                                      81   \n",
       "120                                     n/a   \n",
       "118                                     n/a   \n",
       "121                                     n/a   \n",
       "137                                      81   \n",
       "136                                      81   \n",
       "135                                      81   \n",
       "133                                      81   \n",
       "134                                      81   \n",
       "138                                      81   \n",
       "132                                     n/a   \n",
       "131                                     n/a   \n",
       "\n",
       "    Gained TFBS sequence (not in reference at this position, novel to allele)\\n*Note: this TFBS sequence is in the allele, 5'-3' on strand indicated in 'strand'  \\\n",
       "21                                                 n/a                                                                                                             \n",
       "20                                                 n/a                                                                                                             \n",
       "5                                                  n/a                                                                                                             \n",
       "4                                       TTTTCCCCCCAAAC                                                                                                             \n",
       "23                                                 n/a                                                                                                             \n",
       "2                                         TTTTCCCCCCAA                                                                                                             \n",
       "3                                         TTTCCCCCCAAA                                                                                                             \n",
       "8                                                  n/a                                                                                                             \n",
       "9                                                  n/a                                                                                                             \n",
       "15                                                 n/a                                                                                                             \n",
       "10                                                 n/a                                                                                                             \n",
       "7                                                  n/a                                                                                                             \n",
       "19                                                 n/a                                                                                                             \n",
       "11                                                 n/a                                                                                                             \n",
       "13                                                 n/a                                                                                                             \n",
       "18                                                 n/a                                                                                                             \n",
       "22                                                 n/a                                                                                                             \n",
       "12                                                 n/a                                                                                                             \n",
       "17                                                 n/a                                                                                                             \n",
       "16                                                 n/a                                                                                                             \n",
       "6                                                  n/a                                                                                                             \n",
       "14                                                 n/a                                                                                                             \n",
       "1                                                  n/a                                                                                                             \n",
       "0                                                  n/a                                                                                                             \n",
       "25                                                 n/a                                                                                                             \n",
       "24                                                 n/a                                                                                                             \n",
       "37                                                 n/a                                                                                                             \n",
       "26                                   CAGAACACCCTGTTTTG                                                                                                             \n",
       "36                                                 n/a                                                                                                             \n",
       "30                                   CAAAACAGGGTGTTCTG                                                                                                             \n",
       "..                                                 ...                                                                                                             \n",
       "110                                                n/a                                                                                                             \n",
       "104                                  CATAACAGGGTGTTCTG                                                                                                             \n",
       "116                                                n/a                                                                                                             \n",
       "115                                                n/a                                                                                                             \n",
       "114                                                n/a                                                                                                             \n",
       "112                                                n/a                                                                                                             \n",
       "113                                                n/a                                                                                                             \n",
       "117                                                n/a                                                                                                             \n",
       "111                                                n/a                                                                                                             \n",
       "129                                                n/a                                                                                                             \n",
       "124                                  CAGAACACCCTGTTATG                                                                                                             \n",
       "128                                                n/a                                                                                                             \n",
       "122                                  CATAACAGGGTGTTCTG                                                                                                             \n",
       "127                                                n/a                                                                                                             \n",
       "123                                  CAGAACACCCTGTTATG                                                                                                             \n",
       "125                                                n/a                                                                                                             \n",
       "119                                  CATAACAGGGTGTTCTG                                                                                                             \n",
       "126                                                n/a                                                                                                             \n",
       "130                                                n/a                                                                                                             \n",
       "120                                  CATAACAGGGTGTTCTG                                                                                                             \n",
       "118                                          CTATTGTTC                                                                                                             \n",
       "121                                         CTATTGTTCT                                                                                                             \n",
       "137                                                n/a                                                                                                             \n",
       "136                                                n/a                                                                                                             \n",
       "135                                                n/a                                                                                                             \n",
       "133                                                n/a                                                                                                             \n",
       "134                                                n/a                                                                                                             \n",
       "138                                                n/a                                                                                                             \n",
       "132                                          CTATTGTTC                                                                                                             \n",
       "131                                         CTATTGTTCT                                                                                                             \n",
       "\n",
       "    Gained TFBS start coordinate (in allele)  \\\n",
       "21                                       n/a   \n",
       "20                                       n/a   \n",
       "5                                        n/a   \n",
       "4                                         53   \n",
       "23                                       n/a   \n",
       "2                                         55   \n",
       "3                                         54   \n",
       "8                                        n/a   \n",
       "9                                        n/a   \n",
       "15                                       n/a   \n",
       "10                                       n/a   \n",
       "7                                        n/a   \n",
       "19                                       n/a   \n",
       "11                                       n/a   \n",
       "13                                       n/a   \n",
       "18                                       n/a   \n",
       "22                                       n/a   \n",
       "12                                       n/a   \n",
       "17                                       n/a   \n",
       "16                                       n/a   \n",
       "6                                        n/a   \n",
       "14                                       n/a   \n",
       "1                                        n/a   \n",
       "0                                        n/a   \n",
       "25                                       n/a   \n",
       "24                                       n/a   \n",
       "37                                       n/a   \n",
       "26                                        66   \n",
       "36                                       n/a   \n",
       "30                                        66   \n",
       "..                                       ...   \n",
       "110                                      n/a   \n",
       "104                                       66   \n",
       "116                                      n/a   \n",
       "115                                      n/a   \n",
       "114                                      n/a   \n",
       "112                                      n/a   \n",
       "113                                      n/a   \n",
       "117                                      n/a   \n",
       "111                                      n/a   \n",
       "129                                      n/a   \n",
       "124                                       65   \n",
       "128                                      n/a   \n",
       "122                                       65   \n",
       "127                                      n/a   \n",
       "123                                       65   \n",
       "125                                      n/a   \n",
       "119                                       65   \n",
       "126                                      n/a   \n",
       "130                                      n/a   \n",
       "120                                       65   \n",
       "118                                       20   \n",
       "121                                       20   \n",
       "137                                      n/a   \n",
       "136                                      n/a   \n",
       "135                                      n/a   \n",
       "133                                      n/a   \n",
       "134                                      n/a   \n",
       "138                                      n/a   \n",
       "132                                       20   \n",
       "131                                       20   \n",
       "\n",
       "    Gained TFBS end coordinate (in allele)     p-val  \\\n",
       "21                                     n/a  3.26e-06   \n",
       "20                                     n/a  1.66e-06   \n",
       "5                                      n/a  1.09e-05   \n",
       "4                                       66  3.04e-06   \n",
       "23                                     n/a  1.41e-05   \n",
       "2                                       66   3.6e-05   \n",
       "3                                       65  9.78e-08   \n",
       "8                                      n/a  5.37e-05   \n",
       "9                                      n/a  5.97e-06   \n",
       "15                                     n/a  4.53e-05   \n",
       "10                                     n/a   6.8e-05   \n",
       "7                                      n/a  1.25e-05   \n",
       "19                                     n/a  2.95e-06   \n",
       "11                                     n/a  2.03e-06   \n",
       "13                                     n/a  9.39e-05   \n",
       "18                                     n/a  2.62e-06   \n",
       "22                                     n/a  1.67e-06   \n",
       "12                                     n/a  2.79e-06   \n",
       "17                                     n/a  8.03e-05   \n",
       "16                                     n/a  6.66e-05   \n",
       "6                                      n/a  7.99e-06   \n",
       "14                                     n/a  4.58e-05   \n",
       "1                                      n/a       n/a   \n",
       "0                                      n/a       n/a   \n",
       "25                                     n/a       n/a   \n",
       "24                                     n/a       n/a   \n",
       "37                                     n/a  3.26e-06   \n",
       "26                                      82  7.45e-05   \n",
       "36                                     n/a  1.66e-06   \n",
       "30                                      82   5.9e-05   \n",
       "..                                     ...       ...   \n",
       "110                                    n/a  1.67e-06   \n",
       "104                                     82  4.99e-05   \n",
       "116                                    n/a  3.26e-06   \n",
       "115                                    n/a  1.66e-06   \n",
       "114                                    n/a  2.95e-06   \n",
       "112                                    n/a  2.03e-06   \n",
       "113                                    n/a  2.62e-06   \n",
       "117                                    n/a  1.67e-06   \n",
       "111                                    n/a       n/a   \n",
       "129                                    n/a  3.26e-06   \n",
       "124                                     81  7.86e-05   \n",
       "128                                    n/a  1.66e-06   \n",
       "122                                     81  6.74e-05   \n",
       "127                                    n/a  2.95e-06   \n",
       "123                                     81  7.71e-05   \n",
       "125                                    n/a  2.03e-06   \n",
       "119                                     81  5.74e-05   \n",
       "126                                    n/a  2.62e-06   \n",
       "130                                    n/a  1.67e-06   \n",
       "120                                     81  4.99e-05   \n",
       "118                                     28  1.53e-05   \n",
       "121                                     29     8e-05   \n",
       "137                                    n/a  3.26e-06   \n",
       "136                                    n/a  1.66e-06   \n",
       "135                                    n/a  2.95e-06   \n",
       "133                                    n/a  2.03e-06   \n",
       "134                                    n/a  2.62e-06   \n",
       "138                                    n/a  1.67e-06   \n",
       "132                                     28  1.53e-05   \n",
       "131                                     29     8e-05   \n",
       "\n",
       "    lost or gained in allele (relative to ref)?  \n",
       "21                                         lost  \n",
       "20                                         lost  \n",
       "5                                          lost  \n",
       "4                                        gained  \n",
       "23                                         lost  \n",
       "2                                        gained  \n",
       "3                                        gained  \n",
       "8                                          lost  \n",
       "9                                          lost  \n",
       "15                                         lost  \n",
       "10                                         lost  \n",
       "7                                          lost  \n",
       "19                                         lost  \n",
       "11                                         lost  \n",
       "13                                         lost  \n",
       "18                                         lost  \n",
       "22                                         lost  \n",
       "12                                         lost  \n",
       "17                                         lost  \n",
       "16                                         lost  \n",
       "6                                          lost  \n",
       "14                                         lost  \n",
       "1                                  No TFBS lost  \n",
       "0                                No TFBS gained  \n",
       "25                                 No TFBS lost  \n",
       "24                               No TFBS gained  \n",
       "37                                         lost  \n",
       "26                                       gained  \n",
       "36                                         lost  \n",
       "30                                       gained  \n",
       "..                                          ...  \n",
       "110                                        lost  \n",
       "104                                      gained  \n",
       "116                                        lost  \n",
       "115                                        lost  \n",
       "114                                        lost  \n",
       "112                                        lost  \n",
       "113                                        lost  \n",
       "117                                        lost  \n",
       "111                              No TFBS gained  \n",
       "129                                        lost  \n",
       "124                                      gained  \n",
       "128                                        lost  \n",
       "122                                      gained  \n",
       "127                                        lost  \n",
       "123                                      gained  \n",
       "125                                        lost  \n",
       "119                                      gained  \n",
       "126                                        lost  \n",
       "130                                        lost  \n",
       "120                                      gained  \n",
       "118                                      gained  \n",
       "121                                      gained  \n",
       "137                                        lost  \n",
       "136                                        lost  \n",
       "135                                        lost  \n",
       "133                                        lost  \n",
       "134                                        lost  \n",
       "138                                        lost  \n",
       "132                                      gained  \n",
       "131                                      gained  \n",
       "\n",
       "[139 rows x 16 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare dataframe synopsis of samples and alleles, with individual rows detailing TFBS lost or gained \n",
    "allele_TFBS_synopsis_df_columns = {\"sample\":sample_list, \"allele rank\":allele_count_list, \"allele ID\":allele_list, \"alignment query\\n(allele sequence)\":allele_sequence_list,\n",
    "                                   \"alignment midline\":alignment_midline_list, \"alignment hit\\n(reference)\":reference_sequence_list, \"TF\":TF_list,\n",
    "                                   \"strand\":strand_list, \n",
    "                                   \"Lost TFBS sequence (in reference at this position, lost in allele)\\n*Note: this TFBS sequence is in the reference, 5'-3' on strand indicated in 'strand'\":lost_TFBS_sequence_list,\n",
    "                                   \"Lost TFBS start coordinate (in reference)\":ref_start_coordinate_list,\n",
    "                                   \"Lost TFBS end coordinate (in reference)\":ref_stop_coordinate_list,\n",
    "                                   \"Gained TFBS sequence (not in reference at this position, novel to allele)\\n*Note: this TFBS sequence is in the allele, 5'-3' on strand indicated in 'strand'\":gained_TFBS_sequence_list, \n",
    "                                   \"Gained TFBS start coordinate (in allele)\":allele_start_coordinate_list,\n",
    "                                   \"Gained TFBS end coordinate (in allele)\":allele_stop_coordinate_list, \n",
    "                                   \"p-val\":p_val_list, \"lost or gained in allele (relative to ref)?\":lostvsgained_list}\n",
    "allele_TFBS_synopsis_df = pd.DataFrame(allele_TFBS_synopsis_df_columns)\n",
    "\n",
    "allele_TFBS_synopsis_df.sort_values(by=['sample','allele rank','TF',\"strand\",\"lost or gained in allele (relative to ref)?\"],ascending=[True, True, True, True, False])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add read counts and calculated frequencies to allele_TFBS_synopsis_df\n",
    "read_count_list = [i.split('_')[2].strip('[]').split('/')[0] for i in allele_TFBS_synopsis_df['allele ID'].to_list()]\n",
    "total_reads_list = [i.split('_')[2].strip('[]').split('/')[1] for i in allele_TFBS_synopsis_df['allele ID'].to_list()]\n",
    "pct_total_reads_list = [i.split('_')[4].split(':')[1] for i in allele_TFBS_synopsis_df['allele ID'].to_list()]\n",
    "pct_reads_filtered_for_1pct_list = [float(i.split('_')[7].split(':')[1]) if i.split('_')[7].split(':')[1] != 'None' else 0 for i in allele_TFBS_synopsis_df['allele ID'].to_list()]\n",
    "pct_reads_filtered_for_10pct_list = [float(i.split('_')[8].split(':')[1]) if i.split('_')[8].split(':')[1] != 'None' else 0 for i in allele_TFBS_synopsis_df['allele ID'].to_list()]\n",
    "\n",
    "# Add column with allele comment (comment if appropriate)\n",
    "# Note, pre-processing reads with a read cleaning utility such as cutadapt, trimmomatic, or fastp may remove such reads/\n",
    "# inferred alleles in advance, obviating need for this read length flag\n",
    "allele_TFBS_synopsis_df['comment'] = ['note: inferred allele length <=50 bp; read may be primer dimer; consult fasta file for this inferred allele, and/or consider pre-processing fastq file (filter reads) prior to running CollatedMotifs' if i <=50 else '' for i in [len(x) for x in allele_TFBS_synopsis_df['alignment query\\n(allele sequence)'].to_list()]]\n",
    "\n",
    "allele_TFBS_synopsis_df.insert(loc=3, column='reads', value=read_count_list)\n",
    "allele_TFBS_synopsis_df.insert(loc=4, column='total reads', value=total_reads_list)\n",
    "allele_TFBS_synopsis_df.insert(loc=5, column='% total reads', value=pct_total_reads_list)\n",
    "allele_TFBS_synopsis_df.insert(loc=6, column='% reads filtered for reads <1%', value=pct_reads_filtered_for_1pct_list)\n",
    "allele_TFBS_synopsis_df.insert(loc=7, column='% reads filtered for reads <10%', value=pct_reads_filtered_for_10pct_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assessment of whether TFBSs in *allele_TFBS_synopsis_df* may be positionally overlapping TFBS replacements/cognates ('regains')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May-June 2021, revisited July\n",
    "# assess whether allele_TFBS_synopsis_df lost/gained TFBS may be TFBS 'replacements'/cognates\n",
    "lost_TFBS_list = []\n",
    "gained_TFBS_list = []\n",
    "\n",
    "allele_TFBS_synopsis_df_coordinates_updated = pd.DataFrame(columns=allele_TFBS_synopsis_df.columns)\n",
    "span_between_aligning_blocks_allele_list = []\n",
    "\n",
    "# coordinates for 'lost' TFBS have already been adjusted to reflect allele alignment span relative to user-provided reference sequence span\n",
    "# coordinates for 'gained' TFBS (novel to an allele relative to reference sequence) need to be corrected for positions in allele that are beyond a deletion/insertion span\n",
    "# (and would therefore not enable comparison to cognate coordinate position in reference sequence unless coordinates are adjusted for missing span)\n",
    "for index, row in allele_TFBS_synopsis_df.sort_values(by=['sample','allele rank','TF',\"strand\",\"lost or gained in allele (relative to ref)?\"],ascending=[True, True, True, True, False]).iterrows():\n",
    "    if row['lost or gained in allele (relative to ref)?'] == \"lost\":\n",
    "        lost_TFBS_list.append(row['sample']+','+str(row['allele rank'])+','+row['TF']+','+row['strand']+','+\n",
    "                              str(row['Lost TFBS start coordinate (in reference)'])+','+str(row['Lost TFBS end coordinate (in reference)'])+\n",
    "                              ','+row['lost or gained in allele (relative to ref)?']+','\n",
    "                              +row[\"Lost TFBS sequence (in reference at this position, lost in allele)\\n*Note: this TFBS sequence is in the reference, 5'-3' on strand indicated in 'strand'\"]+\n",
    "                             ','+row['p-val'])\n",
    "        allele_TFBS_synopsis_df_coordinates_updated.loc[index] = row\n",
    "        if re.search('-', dict_allele_TFBS_synopsis.get(row['sample']).get(row['allele ID']).get('allele_sequence')[0]): \n",
    "            # position of longest non-corresponding span in allele, relative to reference (in alignment) (characteristic if deletion allele)\n",
    "            span_between_aligning_blocks_allele_temp = re.search(max(re.findall(r'-+', dict_allele_TFBS_synopsis.get(row['sample']).get(row['allele ID']).get('allele_sequence')[0].split('>')[1].split('<')[0])),dict_allele_TFBS_synopsis.get(row['sample']).get(row['allele ID']).get('allele_sequence')[0].split('>')[1].split('<')[0]).span()\n",
    "            span_between_aligning_blocks_allele = tuple(value+1 for value in span_between_aligning_blocks_allele_temp)\n",
    "            calculated_span_between_aligning_blocks_allele = span_between_aligning_blocks_allele[1]-span_between_aligning_blocks_allele[0]\n",
    "            # position of longest non-corresponding span in reference, relative to allele (in alignment) (characteristic of insertion allele)\n",
    "            # span_between_aligning_blocks_reference = re.search(max(re.findall(r'-+', dict_allele_TFBS_synopsis.get(row['sample']).get(row['allele ID']).get('allele_sequence')[1])),dict_allele_TFBS_synopsis.get(row['sample']).get(row['allele ID']).get('allele_sequence')[0]).span()\n",
    "            span_between_aligning_blocks_allele_list.append(span_between_aligning_blocks_allele)\n",
    "        else:\n",
    "            span_between_aligning_blocks_allele_list.append('n/a') \n",
    "    elif row['lost or gained in allele (relative to ref)?'] == \"gained\":\n",
    "        # retrieve allele's alignment span to reference sequence\n",
    "        ref_span = [dict_allele_TFBS_synopsis.get(row['sample']).get(row['allele ID']).get('ref_coordinates_span')[0],dict_allele_TFBS_synopsis.get(row['sample']).get(row['allele ID']).get('ref_coordinates_span')[-1]]\n",
    "        # retrieve allele's intact span\n",
    "        allele_length = len(dict_allele_TFBS_synopsis.get(row['sample']).get(row['allele ID']).get('allele_sequence')[0].split('>')[1].split('<')[0].replace('-',''))\n",
    "        # retrieve allele's alignment span(s) relative to reference sequence\n",
    "        dict_allele_TFBS_synopsis.get(row['sample']).get(row['allele ID']).get('hsp_alignment_spans')\n",
    "        # retrieve intervening span between allele alignment spans relative to reference sequence\n",
    "        # make adjustments in 'gained' TFBS coordinates, to reflect coordinates as defined in reference span rather than coordinates as defined in allele span\n",
    "        # scenario where there was not >1 hsp detected by BLASTN (alignment is unsplit by BLASTN)\n",
    "        if len(dict_allele_TFBS_synopsis.get(row['sample']).get(row['allele ID']).get('hsp_alignment_spans')) < 2:\n",
    "            # print(row['allele rank'], dict_allele_TFBS_synopsis.get(row['sample']).get(row['allele ID']).get('hsp_alignment_spans'))\n",
    "            # adjust allele coordinates relative to reference coordinates\n",
    "            hsp_spans_relative_to_reference_seq = dict_allele_TFBS_synopsis.get(row['sample']).get(row['allele ID']).get('hsp_alignment_spans')    \n",
    "            basal_number = int(hsp_spans_relative_to_reference_seq[0][0])\n",
    "            hsp_spans_relative_to_reference_seq_adjusted = []\n",
    "            for x in hsp_spans_relative_to_reference_seq:\n",
    "                hsp_spans_relative_to_reference_seq_adjusted.append([int(y)-basal_number for y in x])  \n",
    "            if re.search('-', dict_allele_TFBS_synopsis.get(row['sample']).get(row['allele ID']).get('allele_sequence')[0]): \n",
    "            # position of longest non-corresponding span in allele, relative to reference (in alignment) (characteristic if deletion allele)\n",
    "                span_between_aligning_blocks_allele_temp = re.search(max(re.findall(r'-+', dict_allele_TFBS_synopsis.get(row['sample']).get(row['allele ID']).get('allele_sequence')[0].split('>')[1].split('<')[0])),dict_allele_TFBS_synopsis.get(row['sample']).get(row['allele ID']).get('allele_sequence')[0].split('>')[1].split('<')[0]).span()\n",
    "                span_between_aligning_blocks_allele = tuple(value+1 for value in span_between_aligning_blocks_allele_temp)\n",
    "                calculated_span_between_aligning_blocks_allele = span_between_aligning_blocks_allele[1]-span_between_aligning_blocks_allele[0]\n",
    "            # position of longest non-corresponding span in reference, relative to allele (in alignment) (characteristic of insertion allele)\n",
    "                # span_between_aligning_blocks_reference = re.search(max(re.findall(r'-+', dict_allele_TFBS_synopsis.get(row['sample']).get(row['allele ID']).get('allele_sequence')[1])),dict_allele_TFBS_synopsis.get(row['sample']).get(row['allele ID']).get('allele_sequence')[0]).span()\n",
    "                # scenario if no coordinate adjustment is needed (TFBS end coordinate occurs before largest alignment gap:\n",
    "                if int(row['Gained TFBS end coordinate (in allele)']) in range(int(hsp_spans_relative_to_reference_seq_adjusted[0][0]),\n",
    "                                                                                      int(span_between_aligning_blocks_allele[0])):\n",
    "                    gained_TFBS_list.append(row['sample']+','+str(row['allele rank'])+','+row['TF']+','+row['strand']+','+\n",
    "                              str(row['Gained TFBS start coordinate (in allele)'])+','+\n",
    "                              str(row['Gained TFBS end coordinate (in allele)'])+','+row['lost or gained in allele (relative to ref)?']+','\n",
    "                              +row[\"Gained TFBS sequence (not in reference at this position, novel to allele)\\n*Note: this TFBS sequence is in the allele, 5'-3' on strand indicated in 'strand'\"]+\n",
    "                             ','+row['p-val'])\n",
    "                    allele_TFBS_synopsis_df_coordinates_updated.loc[index] = row\n",
    "                    span_between_aligning_blocks_allele_list.append(span_between_aligning_blocks_allele)\n",
    "                # scenario if coordinate adjustment is needed (TFBS end coordinate occurs between start of alignment gap and alignment end):\n",
    "                elif int(row['Gained TFBS end coordinate (in allele)']) in range(int(span_between_aligning_blocks_allele[0]), int(hsp_spans_relative_to_reference_seq_adjusted[0][-1])):\n",
    "                    gained_TFBS_list.append(row['sample']+','+str(row['allele rank'])+','+row['TF']+','+row['strand']+','+\n",
    "                              str(int(row['Gained TFBS start coordinate (in allele)'])+calculated_span_between_aligning_blocks_allele)+','+\n",
    "                              str(int(row['Gained TFBS end coordinate (in allele)'])+calculated_span_between_aligning_blocks_allele)+','+row['lost or gained in allele (relative to ref)?']+','\n",
    "                              +row[\"Gained TFBS sequence (not in reference at this position, novel to allele)\\n*Note: this TFBS sequence is in the allele, 5'-3' on strand indicated in 'strand'\"]+\n",
    "                             ','+row['p-val']) \n",
    "                    # add row with updated coordinates\n",
    "                    allele_TFBS_synopsis_df_coordinates_updated.loc[index] = {'sample':row['sample'],'allele rank':row['allele rank'], \n",
    "                                                                              'allele ID':row['allele ID'], 'reads':row['reads'], 'total reads':row['total reads'],\n",
    "                                                                              '% total reads':row['% total reads'], '% reads filtered for reads <1%':row['% reads filtered for reads <1%'],\n",
    "                                                                              '% reads filtered for reads <10%':row['% reads filtered for reads <10%'], 'alignment query\\n(allele sequence)':row['alignment query\\n(allele sequence)'],\n",
    "                                                                              'alignment midline':row['alignment midline'], 'alignment hit\\n(reference)':row['alignment hit\\n(reference)'], 'TF':row['TF'],\n",
    "                                                                              'strand':row['strand'], \"Lost TFBS sequence (in reference at this position, lost in allele)\\n*Note: this TFBS sequence is in the reference, 5'-3' on strand indicated in 'strand'\":row[\"Lost TFBS sequence (in reference at this position, lost in allele)\\n*Note: this TFBS sequence is in the reference, 5'-3' on strand indicated in 'strand'\"],\n",
    "                                                                              'Lost TFBS start coordinate (in reference)':row['Lost TFBS start coordinate (in reference)'], 'Lost TFBS end coordinate (in reference)':row['Lost TFBS end coordinate (in reference)'],\n",
    "                                                                              \"Gained TFBS sequence (not in reference at this position, novel to allele)\\n*Note: this TFBS sequence is in the allele, 5'-3' on strand indicated in 'strand'\":row[\"Gained TFBS sequence (not in reference at this position, novel to allele)\\n*Note: this TFBS sequence is in the allele, 5'-3' on strand indicated in 'strand'\"],\n",
    "                                                                              'Gained TFBS start coordinate (in allele)':int(row['Gained TFBS start coordinate (in allele)'])+calculated_span_between_aligning_blocks_allele,\n",
    "                                                                              'Gained TFBS end coordinate (in allele)':int(row['Gained TFBS end coordinate (in allele)'])+calculated_span_between_aligning_blocks_allele,\n",
    "                                                                              'p-val':row['p-val'], 'lost or gained in allele (relative to ref)?':row['lost or gained in allele (relative to ref)?'], 'comment':row['comment']}\n",
    "                    span_between_aligning_blocks_allele_list.append(span_between_aligning_blocks_allele)\n",
    "            else:\n",
    "                span_between_aligning_blocks_allele = 'n/a'\n",
    "                gained_TFBS_list.append(row['sample']+','+str(row['allele rank'])+','+row['TF']+','+row['strand']+','+\n",
    "                              str(int(row['Gained TFBS start coordinate (in allele)']))+','+\n",
    "                              str(int(row['Gained TFBS end coordinate (in allele)']))+','+row['lost or gained in allele (relative to ref)?']+','\n",
    "                              +row[\"Gained TFBS sequence (not in reference at this position, novel to allele)\\n*Note: this TFBS sequence is in the allele, 5'-3' on strand indicated in 'strand'\"]+\n",
    "                             ','+row['p-val'])\n",
    "                allele_TFBS_synopsis_df_coordinates_updated.loc[index] = row\n",
    "                span_between_aligning_blocks_allele_list.append(span_between_aligning_blocks_allele)\n",
    "        # scenario where there was >1 hsp detected by BLASTN (aligning segments were split by BLASTN and required reconstruction)\n",
    "        else:\n",
    "            span_between_aligning_blocks_allele_temp = re.search(max(re.findall(r'-+', dict_allele_TFBS_synopsis.get(row['sample']).get(row['allele ID']).get('allele_sequence')[0].split('>')[1].split('<')[0])),dict_allele_TFBS_synopsis.get(row['sample']).get(row['allele ID']).get('allele_sequence')[0].split('>')[1].split('<')[0]).span()\n",
    "            span_between_aligning_blocks_allele = tuple(value+1 for value in span_between_aligning_blocks_allele_temp)\n",
    "            calculated_span_between_aligning_blocks_allele = span_between_aligning_blocks_allele[1]-span_between_aligning_blocks_allele[0]\n",
    "            hsp_spans_relative_to_reference_seq = dict_allele_TFBS_synopsis.get(row['sample']).get(row['allele ID']).get('hsp_alignment_spans')    \n",
    "            basal_number = int(hsp_spans_relative_to_reference_seq[0][0])\n",
    "            hsp_spans_relative_to_reference_seq_adjusted = []\n",
    "            for x in hsp_spans_relative_to_reference_seq:\n",
    "                hsp_spans_relative_to_reference_seq_adjusted.append([int(y)-basal_number for y in x])  \n",
    "            # condition for coordinates within first alignment block/hsp (no coordinate adjustment needed)\n",
    "            if int(row['Gained TFBS end coordinate (in allele)']) in range(int(hsp_spans_relative_to_reference_seq_adjusted[0][0]),\n",
    "                                                                                      int(span_between_aligning_blocks_allele[0])):\n",
    "                gained_TFBS_list.append(row['sample']+','+str(row['allele rank'])+','+row['TF']+','+row['strand']+','+\n",
    "                              str(row['Gained TFBS start coordinate (in allele)'])+','+\n",
    "                              str(row['Gained TFBS end coordinate (in allele)'])+','+row['lost or gained in allele (relative to ref)?']+','\n",
    "                              +row[\"Gained TFBS sequence (not in reference at this position, novel to allele)\\n*Note: this TFBS sequence is in the allele, 5'-3' on strand indicated in 'strand'\"]+\n",
    "                             ','+row['p-val'])\n",
    "                allele_TFBS_synopsis_df_coordinates_updated.loc[index] = row\n",
    "                span_between_aligning_blocks_allele_list.append(span_between_aligning_blocks_allele)\n",
    "            # condition for coordinates within gap between alignments blocks/hsp's\n",
    "            elif int(row['Gained TFBS end coordinate (in allele)']) in range(int(hsp_spans_relative_to_reference_seq_adjusted[0][-1])+1,\n",
    "                                                                                      int(hsp_spans_relative_to_reference_seq_adjusted[1][0])):\n",
    "                gained_TFBS_list.append(row['sample']+','+str(row['allele rank'])+','+row['TF']+','+row['strand']+','+\n",
    "                              str(row['Gained TFBS start coordinate (in allele)'])+','+\n",
    "                              str(row['Gained TFBS end coordinate (in allele)'])+','+row['lost or gained in allele (relative to ref)?']+','\n",
    "                              +row[\"Gained TFBS sequence (not in reference at this position, novel to allele)\\n*Note: this TFBS sequence is in the allele, 5'-3' on strand indicated in 'strand'\"]+\n",
    "                             ','+row['p-val'])\n",
    "                allele_TFBS_synopsis_df_coordinates_updated.loc[index] = row\n",
    "                span_between_aligning_blocks_allele_list.append(span_between_aligning_blocks_allele)\n",
    "            # condition for coordinates beyond gap between alignments blocks/hsp's (coordinate adjustment needed)\n",
    "            elif int(row['Gained TFBS end coordinate (in allele)']) in range(int(hsp_spans_relative_to_reference_seq_adjusted[1][0]),\n",
    "                                                                                      int(hsp_spans_relative_to_reference_seq_adjusted[1][-1])):\n",
    "                gained_TFBS_list.append(row['sample']+','+str(row['allele rank'])+','+row['TF']+','+row['strand']+','+\n",
    "                              str(int(row['Gained TFBS start coordinate (in allele)'])+calculated_span_between_aligning_blocks_allele)+','+\n",
    "                              str(int(row['Gained TFBS end coordinate (in allele)'])+calculated_span_between_aligning_blocks_allele)+','+row['lost or gained in allele (relative to ref)?']+','\n",
    "                              +row[\"Gained TFBS sequence (not in reference at this position, novel to allele)\\n*Note: this TFBS sequence is in the allele, 5'-3' on strand indicated in 'strand'\"]+\n",
    "                             ','+row['p-val'])\n",
    "                # add row with updated coordinates\n",
    "                allele_TFBS_synopsis_df_coordinates_updated.loc[index] = {'sample':row['sample'],'allele rank':row['allele rank'], \n",
    "                                                                              'allele ID':row['allele ID'], 'reads':row['reads'], 'total reads':row['total reads'],\n",
    "                                                                              '% total reads':row['% total reads'], '% reads filtered for reads <1%':row['% reads filtered for reads <1%'],\n",
    "                                                                              '% reads filtered for reads <10%':row['% reads filtered for reads <10%'], 'alignment query\\n(allele sequence)':row['alignment query\\n(allele sequence)'],\n",
    "                                                                              'alignment midline':row['alignment midline'], 'alignment hit\\n(reference)':row['alignment hit\\n(reference)'], 'TF':row['TF'],\n",
    "                                                                              'strand':row['strand'], \"Lost TFBS sequence (in reference at this position, lost in allele)\\n*Note: this TFBS sequence is in the reference, 5'-3' on strand indicated in 'strand'\":row[\"Lost TFBS sequence (in reference at this position, lost in allele)\\n*Note: this TFBS sequence is in the reference, 5'-3' on strand indicated in 'strand'\"],\n",
    "                                                                              'Lost TFBS start coordinate (in reference)':row['Lost TFBS start coordinate (in reference)'], 'Lost TFBS end coordinate (in reference)':row['Lost TFBS end coordinate (in reference)'],\n",
    "                                                                              \"Gained TFBS sequence (not in reference at this position, novel to allele)\\n*Note: this TFBS sequence is in the allele, 5'-3' on strand indicated in 'strand'\":row[\"Gained TFBS sequence (not in reference at this position, novel to allele)\\n*Note: this TFBS sequence is in the allele, 5'-3' on strand indicated in 'strand'\"],\n",
    "                                                                              'Gained TFBS start coordinate (in allele)':int(row['Gained TFBS start coordinate (in allele)'])+calculated_span_between_aligning_blocks_allele,\n",
    "                                                                              'Gained TFBS end coordinate (in allele)':int(row['Gained TFBS end coordinate (in allele)'])+calculated_span_between_aligning_blocks_allele,\n",
    "                                                                              'p-val':row['p-val'], 'lost or gained in allele (relative to ref)?':row['lost or gained in allele (relative to ref)?'], 'comment':row['comment']}\n",
    "                span_between_aligning_blocks_allele_list.append(span_between_aligning_blocks_allele)\n",
    "            else:\n",
    "                gained_TFBS_list.append(row['sample']+','+str(row['allele rank'])+','+row['TF']+','+row['strand']+','+\n",
    "                              str(int(row['Gained TFBS start coordinate (in allele)'])+calculated_span_between_aligning_blocks_allele)+','+\n",
    "                              str(int(row['Gained TFBS end coordinate (in allele)'])+calculated_span_between_aligning_blocks_allele)+','+row['lost or gained in allele (relative to ref)?']+','\n",
    "                              +row[\"Gained TFBS sequence (not in reference at this position, novel to allele)\\n*Note: this TFBS sequence is in the allele, 5'-3' on strand indicated in 'strand'\"]+\n",
    "                             ','+row['p-val'])\n",
    "                # add row with updated coordinates\n",
    "                allele_TFBS_synopsis_df_coordinates_updated.loc[index] = {'sample':row['sample'],'allele rank':row['allele rank'], \n",
    "                                                                              'allele ID':row['allele ID'], 'reads':row['reads'], 'total reads':row['total reads'],\n",
    "                                                                              '% total reads':row['% total reads'], '% reads filtered for reads <1%':row['% reads filtered for reads <1%'],\n",
    "                                                                              '% reads filtered for reads <10%':row['% reads filtered for reads <10%'], 'alignment query\\n(allele sequence)':row['alignment query\\n(allele sequence)'],\n",
    "                                                                              'alignment midline':row['alignment midline'], 'alignment hit\\n(reference)':row['alignment hit\\n(reference)'], 'TF':row['TF'],\n",
    "                                                                              'strand':row['strand'], \"Lost TFBS sequence (in reference at this position, lost in allele)\\n*Note: this TFBS sequence is in the reference, 5'-3' on strand indicated in 'strand'\":row[\"Lost TFBS sequence (in reference at this position, lost in allele)\\n*Note: this TFBS sequence is in the reference, 5'-3' on strand indicated in 'strand'\"],\n",
    "                                                                              'Lost TFBS start coordinate (in reference)':row['Lost TFBS start coordinate (in reference)'], 'Lost TFBS end coordinate (in reference)':row['Lost TFBS end coordinate (in reference)'],\n",
    "                                                                              \"Gained TFBS sequence (not in reference at this position, novel to allele)\\n*Note: this TFBS sequence is in the allele, 5'-3' on strand indicated in 'strand'\":row[\"Gained TFBS sequence (not in reference at this position, novel to allele)\\n*Note: this TFBS sequence is in the allele, 5'-3' on strand indicated in 'strand'\"],\n",
    "                                                                              'Gained TFBS start coordinate (in allele)':int(row['Gained TFBS start coordinate (in allele)'])+calculated_span_between_aligning_blocks_allele,\n",
    "                                                                              'Gained TFBS end coordinate (in allele)':int(row['Gained TFBS end coordinate (in allele)'])+calculated_span_between_aligning_blocks_allele,\n",
    "                                                                              'p-val':row['p-val'], 'lost or gained in allele (relative to ref)?':row['lost or gained in allele (relative to ref)?'], 'comment':row['comment']}\n",
    "                span_between_aligning_blocks_allele_list.append(span_between_aligning_blocks_allele)\n",
    "\n",
    "allele_TFBS_synopsis_df_coordinates_updated['span between alignment blocks'] = span_between_aligning_blocks_allele_list\n",
    "                \n",
    "\n",
    "potential_matched_TFBS_pairs_list = []\n",
    "\n",
    "for i in lost_TFBS_list:\n",
    "    for x in gained_TFBS_list:\n",
    "        if x.split(',')[4] == 'n/a' or x.split(',')[5] == 'n/a':\n",
    "            pass\n",
    "        else:\n",
    "            if i.split(',')[:4] == x.split(',')[:4]:\n",
    "                lost_range = range(int(i.split(',')[4]), int(i.split(',')[5])+1)\n",
    "                gained_range = range(int(x.split(',')[4]), int(x.split(',')[5])+1)\n",
    "                if len(set(lost_range) & set(gained_range)) > 0:\n",
    "                    potential_matched_TFBS_pairs_list.append((i,x))\n",
    "                \n",
    "unpaired_TFBS_gains_list = list(set(gained_TFBS_list) - \n",
    "                                set([i[0] for i in potential_matched_TFBS_pairs_list]+[i[1] for i in potential_matched_TFBS_pairs_list]))\n",
    "unpaired_TFBS_losses_list = list(set(lost_TFBS_list) - \n",
    "                                set([i[0] for i in potential_matched_TFBS_pairs_list]+[i[1] for i in potential_matched_TFBS_pairs_list]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# July 2021\n",
    "# Reconstitute data for categories ('no TFBS predicted as lost or gained in allele', 'predicted TFBS loss (TFBS lost in allele)',\n",
    "# 'predicted TFBS gain (novel to allele)')\n",
    "sample_list = []\n",
    "allele_rank_list = []\n",
    "allele_list = []\n",
    "read_count_list = []\n",
    "total_reads_count_list = []\n",
    "pct_total_reads_list = []\n",
    "pct_reads_filtered_for_1pct_list = []\n",
    "pct_reads_filtered_for_10pct_list = []\n",
    "allele_sequence_list = []\n",
    "reference_sequence_list = []\n",
    "alignment_midline_list = []\n",
    "TF_list = []\n",
    "strand_list = []\n",
    "lost_TFBS_sequence_list = []\n",
    "gained_TFBS_sequence_list = []\n",
    "allele_start_coordinate_list = []\n",
    "allele_stop_coordinate_list = []\n",
    "ref_start_coordinate_list = []\n",
    "ref_stop_coordinate_list = []\n",
    "lost_TFBS_pval_list = []\n",
    "gained_TFBS_pval_list = []\n",
    "predicted_lost_gained_pair_list = []\n",
    "\n",
    "for index, row in allele_TFBS_synopsis_df_coordinates_updated.iterrows():\n",
    "    if row['lost or gained in allele (relative to ref)?'] == 'lost':\n",
    "        lost_test_phrase = ''.join(row['sample']+','+str(row['allele rank'])+','+row['TF']+','+row['strand']+','+\n",
    "                              str(row['Lost TFBS start coordinate (in reference)'])+','+str(row['Lost TFBS end coordinate (in reference)'])+\n",
    "                              ','+row['lost or gained in allele (relative to ref)?']+','\n",
    "                              +row[\"Lost TFBS sequence (in reference at this position, lost in allele)\\n*Note: this TFBS sequence is in the reference, 5'-3' on strand indicated in 'strand'\"]+\n",
    "                             ','+row['p-val'])\n",
    "        if lost_test_phrase in set([i[0] for i in potential_matched_TFBS_pairs_list]+[i[1] for i in potential_matched_TFBS_pairs_list]):\n",
    "            for match_pair in potential_matched_TFBS_pairs_list:\n",
    "                if lost_test_phrase in match_pair:\n",
    "                    sample_list.append(row['sample'])\n",
    "                    allele_rank_list.append(row['allele rank'])\n",
    "                    allele_list.append(row['allele ID'])\n",
    "                    read_count_list.append(row['reads'])\n",
    "                    total_reads_count_list.append(row['total reads'])\n",
    "                    pct_total_reads_list.append(row['% total reads'])\n",
    "                    pct_reads_filtered_for_1pct_list.append(row['% reads filtered for reads <1%'])\n",
    "                    pct_reads_filtered_for_10pct_list.append(row['% reads filtered for reads <10%'])\n",
    "                    allele_sequence_list.append(row['alignment query\\n(allele sequence)'])\n",
    "                    reference_sequence_list.append(row['alignment hit\\n(reference)'])\n",
    "                    alignment_midline_list.append(row['alignment midline'])\n",
    "                    TF_list.append(row['TF'])\n",
    "                    strand_list.append(row['strand'])\n",
    "                    lost_TFBS_sequence_list.append(match_pair[0].split(',')[7])\n",
    "                    ref_start_coordinate_list.append(match_pair[0].split(',')[4])\n",
    "                    ref_stop_coordinate_list.append(match_pair[0].split(',')[5])\n",
    "                    gained_TFBS_sequence_list.append(match_pair[1].split(',')[7])\n",
    "                    allele_start_coordinate_list.append(match_pair[1].split(',')[4])\n",
    "                    allele_stop_coordinate_list.append(match_pair[1].split(',')[5])\n",
    "                    lost_TFBS_pval_list.append(match_pair[0].split(',')[8])\n",
    "                    gained_TFBS_pval_list.append(match_pair[1].split(',')[8])\n",
    "                    predicted_lost_gained_pair_list.append('predicted lost-regained TFBS pair')\n",
    "                else:\n",
    "                    pass\n",
    "        elif lost_test_phrase in unpaired_TFBS_losses_list:\n",
    "            sample_list.append(row['sample'])\n",
    "            allele_rank_list.append(row['allele rank'])\n",
    "            allele_list.append(row['allele ID'])\n",
    "            read_count_list.append(row['reads'])\n",
    "            total_reads_count_list.append(row['total reads'])\n",
    "            pct_total_reads_list.append(row['% total reads'])\n",
    "            pct_reads_filtered_for_1pct_list.append(row['% reads filtered for reads <1%'])\n",
    "            pct_reads_filtered_for_10pct_list.append(row['% reads filtered for reads <10%'])\n",
    "            allele_sequence_list.append(row['alignment query\\n(allele sequence)'])\n",
    "            reference_sequence_list.append(row['alignment hit\\n(reference)'])\n",
    "            alignment_midline_list.append(row['alignment midline'])\n",
    "            TF_list.append(row['TF'])\n",
    "            strand_list.append(row['strand'])\n",
    "            lost_TFBS_sequence_list.append(lost_test_phrase.split(',')[7])\n",
    "            ref_start_coordinate_list.append(lost_test_phrase.split(',')[4])\n",
    "            ref_stop_coordinate_list.append(lost_test_phrase.split(',')[5])\n",
    "            gained_TFBS_sequence_list.append('n/a')\n",
    "            allele_start_coordinate_list.append('n/a')\n",
    "            allele_stop_coordinate_list.append('n/a')\n",
    "            lost_TFBS_pval_list.append(lost_test_phrase.split(',')[8])\n",
    "            gained_TFBS_pval_list.append('n/a (>1e-4 threshold)')\n",
    "            predicted_lost_gained_pair_list.append('predicted TFBS loss (TFBS lost in allele)')\n",
    "    elif row['lost or gained in allele (relative to ref)?'] == 'gained':    \n",
    "        gained_test_phrase = ''.join(row['sample']+','+str(row['allele rank'])+','+row['TF']+','+row['strand']+','+\n",
    "                              str(row['Gained TFBS start coordinate (in allele)'])+','+\n",
    "                              str(row['Gained TFBS end coordinate (in allele)'])+','+row['lost or gained in allele (relative to ref)?']+','\n",
    "                              +row[\"Gained TFBS sequence (not in reference at this position, novel to allele)\\n*Note: this TFBS sequence is in the allele, 5'-3' on strand indicated in 'strand'\"]+\n",
    "                             ','+row['p-val'])\n",
    "        if gained_test_phrase in unpaired_TFBS_gains_list:\n",
    "            sample_list.append(row['sample'])\n",
    "            allele_rank_list.append(row['allele rank'])\n",
    "            allele_list.append(row['allele ID'])\n",
    "            read_count_list.append(row['reads'])\n",
    "            total_reads_count_list.append(row['total reads'])\n",
    "            pct_total_reads_list.append(row['% total reads'])\n",
    "            pct_reads_filtered_for_1pct_list.append(row['% reads filtered for reads <1%'])\n",
    "            pct_reads_filtered_for_10pct_list.append(row['% reads filtered for reads <10%'])\n",
    "            allele_sequence_list.append(row['alignment query\\n(allele sequence)'])\n",
    "            reference_sequence_list.append(row['alignment hit\\n(reference)'])\n",
    "            alignment_midline_list.append(row['alignment midline'])\n",
    "            TF_list.append(row['TF'])\n",
    "            strand_list.append(row['strand'])\n",
    "            lost_TFBS_sequence_list.append('n/a')\n",
    "            ref_start_coordinate_list.append('n/a')\n",
    "            ref_stop_coordinate_list.append('n/a')\n",
    "            gained_TFBS_sequence_list.append(gained_test_phrase.split(',')[7])\n",
    "            allele_start_coordinate_list.append(gained_test_phrase.split(',')[4])\n",
    "            allele_stop_coordinate_list.append(gained_test_phrase.split(',')[5])\n",
    "            lost_TFBS_pval_list.append('n/a (>1e-4 threshold)')\n",
    "            gained_TFBS_pval_list.append(gained_test_phrase.split(',')[8])\n",
    "            predicted_lost_gained_pair_list.append('predicted TFBS gain (novel to allele)')\n",
    "    elif row['lost or gained in allele (relative to ref)?'] == 'No TFBS gained':\n",
    "        lost_test_phrase = ''.join(row['sample']+','+str(row['allele rank'])+','+row['TF']+','+row['strand']+','+\n",
    "                              str(row['Lost TFBS start coordinate (in reference)'])+','+str(row['Lost TFBS end coordinate (in reference)'])+\n",
    "                              ','+row['lost or gained in allele (relative to ref)?']+','\n",
    "                              +row[\"Lost TFBS sequence (in reference at this position, lost in allele)\\n*Note: this TFBS sequence is in the reference, 5'-3' on strand indicated in 'strand'\"]+\n",
    "                             ','+row['p-val'])\n",
    "        if lost_test_phrase in unpaired_TFBS_losses_list:\n",
    "            pass\n",
    "        else:\n",
    "            if row['allele ID'] in allele_list:\n",
    "                pass\n",
    "            else:\n",
    "                sample_list.append(row['sample'])\n",
    "                allele_rank_list.append(row['allele rank'])\n",
    "                allele_list.append(row['allele ID'])\n",
    "                read_count_list.append(row['reads'])\n",
    "                total_reads_count_list.append(row['total reads'])\n",
    "                pct_total_reads_list.append(row['% total reads'])\n",
    "                pct_reads_filtered_for_1pct_list.append(row['% reads filtered for reads <1%'])\n",
    "                pct_reads_filtered_for_10pct_list.append(row['% reads filtered for reads <10%'])\n",
    "                allele_sequence_list.append(row['alignment query\\n(allele sequence)'])\n",
    "                reference_sequence_list.append(row['alignment hit\\n(reference)'])\n",
    "                alignment_midline_list.append(row['alignment midline'])\n",
    "                TF_list.append(row['TF'])\n",
    "                strand_list.append(row['strand'])\n",
    "                lost_TFBS_sequence_list.append('n/a')\n",
    "                ref_start_coordinate_list.append('n/a')\n",
    "                ref_stop_coordinate_list.append('n/a')\n",
    "                gained_TFBS_sequence_list.append('n/a')\n",
    "                allele_start_coordinate_list.append('n/a')\n",
    "                allele_stop_coordinate_list.append('n/a')\n",
    "                lost_TFBS_pval_list.append('n/a')\n",
    "                gained_TFBS_pval_list.append('n/a')\n",
    "                predicted_lost_gained_pair_list.append('no TFBS predicted as lost or gained in allele')\n",
    "    elif row['lost or gained in allele (relative to ref)?'] == 'No TFBS lost':\n",
    "        gained_test_phrase = ''.join(row['sample']+','+str(row['allele rank'])+','+row['TF']+','+row['strand']+','+\n",
    "                              str(row['Gained TFBS start coordinate (in allele)'])+','+\n",
    "                              str(row['Gained TFBS end coordinate (in allele)'])+','+row['lost or gained in allele (relative to ref)?']+','\n",
    "                              +row[\"Gained TFBS sequence (not in reference at this position, novel to allele)\\n*Note: this TFBS sequence is in the allele, 5'-3' on strand indicated in 'strand'\"]+\n",
    "                             ','+row['p-val']) \n",
    "        if gained_test_phrase in unpaired_TFBS_gains_list:\n",
    "            if row['allele ID'] in allele_list:\n",
    "                pass\n",
    "            else:\n",
    "                sample_list.append(row['sample'])\n",
    "                allele_rank_list.append(row['allele rank'])\n",
    "                allele_list.append(row['allele ID'])\n",
    "                read_count_list.append(row['reads'])\n",
    "                total_reads_count_list.append(row['total reads'])\n",
    "                pct_total_reads_list.append(row['% total reads'])\n",
    "                pct_reads_filtered_for_1pct_list.append(row['% reads filtered for reads <1%'])\n",
    "                pct_reads_filtered_for_10pct_list.append(row['% reads filtered for reads <10%'])\n",
    "                allele_sequence_list.append(row['alignment query\\n(allele sequence)'])\n",
    "                reference_sequence_list.append(row['alignment hit\\n(reference)'])\n",
    "                alignment_midline_list.append(row['alignment midline'])\n",
    "                TF_list.append(row['TF'])\n",
    "                strand_list.append(row['strand'])\n",
    "                lost_TFBS_sequence_list.append('n/a')\n",
    "                ref_start_coordinate_list.append('n/a')\n",
    "                ref_stop_coordinate_list.append('n/a')\n",
    "                gained_TFBS_sequence_list.append('n/a')\n",
    "                allele_start_coordinate_list.append('n/a')\n",
    "                allele_stop_coordinate_list.append('n/a')\n",
    "                lost_TFBS_pval_list.append('n/a')\n",
    "                gained_TFBS_pval_list.append('n/a')\n",
    "                predicted_lost_gained_pair_list.append('no TFBS predicted as lost or gained in allele')\n",
    "                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*interpreted_TFBS_synopsis_df*: dataframe synopsis of TFBS interpretations as isolated 'lost' or 'gained' instances relative to reference sequence, vs. positionally overlapping 'lost-regained' pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>allele rank</th>\n",
       "      <th>allele ID</th>\n",
       "      <th>read count</th>\n",
       "      <th>total reads</th>\n",
       "      <th>% total reads</th>\n",
       "      <th>% reads filtered for reads &lt;1%</th>\n",
       "      <th>% reads filtered for reads &lt;10%</th>\n",
       "      <th>alignment query\n",
       "(allele sequence)</th>\n",
       "      <th>alignment midline</th>\n",
       "      <th>...</th>\n",
       "      <th>Lost TFBS sequence (in reference at this position, lost in allele)\n",
       "*Note: this TFBS sequence is in the reference, 5'-3' on strand indicated in 'strand'</th>\n",
       "      <th>Gained TFBS sequence (not in reference at this position, novel to allele)\n",
       "*Note: this TFBS sequence is in the allele, 5'-3' on strand indicated in 'strand'</th>\n",
       "      <th>Lost TFBS coordinate start (in reference)</th>\n",
       "      <th>Lost TFBS coordinate end (in reference)</th>\n",
       "      <th>Gained TFBS coordinate start (in allele)</th>\n",
       "      <th>Gained TFBS coordinate end (in allele)</th>\n",
       "      <th>Lost TFBS p-val (in reference)</th>\n",
       "      <th>Gained TBFS p-val (in allele)</th>\n",
       "      <th>interpretation</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>n/a</td>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>3.26e-06</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>n/a</td>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.66e-06</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>TTTTCCCCCCTATT</td>\n",
       "      <td>n/a</td>\n",
       "      <td>135</td>\n",
       "      <td>148</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.09e-05</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>n/a</td>\n",
       "      <td>TTTTCCCCCCAAAC</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>3.04e-06</td>\n",
       "      <td>predicted TFBS gain (novel to allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>TTTCCCCCCTAT</td>\n",
       "      <td>n/a</td>\n",
       "      <td>136</td>\n",
       "      <td>147</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.41e-05</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>n/a</td>\n",
       "      <td>TTTTCCCCCCAA</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>55</td>\n",
       "      <td>66</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>3.6e-05</td>\n",
       "      <td>predicted TFBS gain (novel to allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>n/a</td>\n",
       "      <td>TTTCCCCCCAAA</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>54</td>\n",
       "      <td>65</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>9.78e-08</td>\n",
       "      <td>predicted TFBS gain (novel to allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>GTGCCAGCC</td>\n",
       "      <td>n/a</td>\n",
       "      <td>86</td>\n",
       "      <td>94</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>5.37e-05</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>GTGCCAGCC</td>\n",
       "      <td>n/a</td>\n",
       "      <td>86</td>\n",
       "      <td>94</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>5.97e-06</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CTGACAG</td>\n",
       "      <td>n/a</td>\n",
       "      <td>109</td>\n",
       "      <td>115</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>4.53e-05</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CTGACAGC</td>\n",
       "      <td>n/a</td>\n",
       "      <td>109</td>\n",
       "      <td>116</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>6.8e-05</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>GATGTGCTGACA</td>\n",
       "      <td>n/a</td>\n",
       "      <td>103</td>\n",
       "      <td>114</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.25e-05</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>n/a</td>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.95e-06</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>n/a</td>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.03e-06</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>ATGAACTCGATGTGCTG</td>\n",
       "      <td>n/a</td>\n",
       "      <td>95</td>\n",
       "      <td>111</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>9.39e-05</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>n/a</td>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.62e-06</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>n/a</td>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.67e-06</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>GATGTGCTGAC</td>\n",
       "      <td>n/a</td>\n",
       "      <td>103</td>\n",
       "      <td>113</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.79e-06</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>AGTTCATGTGCCAGCCA</td>\n",
       "      <td>n/a</td>\n",
       "      <td>85</td>\n",
       "      <td>101</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>8.03e-05</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>AGCACATCGAGTTCA</td>\n",
       "      <td>n/a</td>\n",
       "      <td>96</td>\n",
       "      <td>110</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>6.66e-05</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>GTGGCTGGCACAT</td>\n",
       "      <td>n/a</td>\n",
       "      <td>84</td>\n",
       "      <td>96</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>7.99e-06</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGCACATCGAGTTCA</td>\n",
       "      <td>n/a</td>\n",
       "      <td>96</td>\n",
       "      <td>111</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>4.58e-05</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-2-A01_R1+R2_[140/435]_rank2_%totalreads:32...</td>\n",
       "      <td>140</td>\n",
       "      <td>435</td>\n",
       "      <td>32.18</td>\n",
       "      <td>38.25</td>\n",
       "      <td>41.79</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>CAGAACACCCTGTTTTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>69</td>\n",
       "      <td>85</td>\n",
       "      <td>3.26e-06</td>\n",
       "      <td>7.45e-05</td>\n",
       "      <td>predicted lost-regained TFBS pair</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-2-A01_R1+R2_[140/435]_rank2_%totalreads:32...</td>\n",
       "      <td>140</td>\n",
       "      <td>435</td>\n",
       "      <td>32.18</td>\n",
       "      <td>38.25</td>\n",
       "      <td>41.79</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>CAAAACAGGGTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>69</td>\n",
       "      <td>85</td>\n",
       "      <td>1.66e-06</td>\n",
       "      <td>5.9e-05</td>\n",
       "      <td>predicted lost-regained TFBS pair</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-2-A01_R1+R2_[140/435]_rank2_%totalreads:32...</td>\n",
       "      <td>140</td>\n",
       "      <td>435</td>\n",
       "      <td>32.18</td>\n",
       "      <td>38.25</td>\n",
       "      <td>41.79</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>CAGAACACCCTGTTTTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>69</td>\n",
       "      <td>85</td>\n",
       "      <td>2.95e-06</td>\n",
       "      <td>6.18e-05</td>\n",
       "      <td>predicted lost-regained TFBS pair</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-2-A01_R1+R2_[140/435]_rank2_%totalreads:32...</td>\n",
       "      <td>140</td>\n",
       "      <td>435</td>\n",
       "      <td>32.18</td>\n",
       "      <td>38.25</td>\n",
       "      <td>41.79</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>CAAAACAGGGTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>69</td>\n",
       "      <td>85</td>\n",
       "      <td>2.03e-06</td>\n",
       "      <td>5.61e-05</td>\n",
       "      <td>predicted lost-regained TFBS pair</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-2-A01_R1+R2_[140/435]_rank2_%totalreads:32...</td>\n",
       "      <td>140</td>\n",
       "      <td>435</td>\n",
       "      <td>32.18</td>\n",
       "      <td>38.25</td>\n",
       "      <td>41.79</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>CAGAACACCCTGTTTTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>69</td>\n",
       "      <td>85</td>\n",
       "      <td>2.62e-06</td>\n",
       "      <td>5.39e-05</td>\n",
       "      <td>predicted lost-regained TFBS pair</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-2-A01_R1+R2_[140/435]_rank2_%totalreads:32...</td>\n",
       "      <td>140</td>\n",
       "      <td>435</td>\n",
       "      <td>32.18</td>\n",
       "      <td>38.25</td>\n",
       "      <td>41.79</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>CAAAACAGGGTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>69</td>\n",
       "      <td>85</td>\n",
       "      <td>1.67e-06</td>\n",
       "      <td>5.08e-05</td>\n",
       "      <td>predicted lost-regained TFBS pair</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-2-A01_R1+R2_[140/435]_rank2_%totalreads:32...</td>\n",
       "      <td>140</td>\n",
       "      <td>435</td>\n",
       "      <td>32.18</td>\n",
       "      <td>38.25</td>\n",
       "      <td>41.79</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>n/a</td>\n",
       "      <td>TTTTGTGGCTG</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>81</td>\n",
       "      <td>91</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>8.94e-05</td>\n",
       "      <td>predicted TFBS gain (novel to allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-2-A01_R1+R2_[11/435]_rank4_%totalreads:2.5...</td>\n",
       "      <td>11</td>\n",
       "      <td>435</td>\n",
       "      <td>2.53</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTC</td>\n",
       "      <td>|||||||||||||||||||||||||||||||</td>\n",
       "      <td>...</td>\n",
       "      <td>n/a</td>\n",
       "      <td>TTTCCGAGAAC</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>6.9e-05</td>\n",
       "      <td>predicted TFBS gain (novel to allele)</td>\n",
       "      <td>note: inferred allele length &lt;=50 bp; read may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>KE4-4-G02</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G02_R1+R2_[11/996]_rank4_%totalreads:1.1...</td>\n",
       "      <td>11</td>\n",
       "      <td>996</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>n/a</td>\n",
       "      <td>CTATTGTTC</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>1.53e-05</td>\n",
       "      <td>predicted TFBS gain (novel to allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>KE4-4-G02</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G02_R1+R2_[11/996]_rank4_%totalreads:1.1...</td>\n",
       "      <td>11</td>\n",
       "      <td>996</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>n/a</td>\n",
       "      <td>CTATTGTTCT</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>predicted TFBS gain (novel to allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-4-G10_R1+R2_[347/806]_rank1_%totalreads:43...</td>\n",
       "      <td>347</td>\n",
       "      <td>806</td>\n",
       "      <td>43.05</td>\n",
       "      <td>51.64</td>\n",
       "      <td>52.50</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>CAGAACACCCTGTTATG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>70</td>\n",
       "      <td>86</td>\n",
       "      <td>3.26e-06</td>\n",
       "      <td>7.86e-05</td>\n",
       "      <td>predicted lost-regained TFBS pair</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-4-G10_R1+R2_[347/806]_rank1_%totalreads:43...</td>\n",
       "      <td>347</td>\n",
       "      <td>806</td>\n",
       "      <td>43.05</td>\n",
       "      <td>51.64</td>\n",
       "      <td>52.50</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>CATAACAGGGTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>70</td>\n",
       "      <td>86</td>\n",
       "      <td>1.66e-06</td>\n",
       "      <td>6.74e-05</td>\n",
       "      <td>predicted lost-regained TFBS pair</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-4-G10_R1+R2_[347/806]_rank1_%totalreads:43...</td>\n",
       "      <td>347</td>\n",
       "      <td>806</td>\n",
       "      <td>43.05</td>\n",
       "      <td>51.64</td>\n",
       "      <td>52.50</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>CAGAACACCCTGTTATG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>70</td>\n",
       "      <td>86</td>\n",
       "      <td>2.95e-06</td>\n",
       "      <td>7.71e-05</td>\n",
       "      <td>predicted lost-regained TFBS pair</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-4-G10_R1+R2_[347/806]_rank1_%totalreads:43...</td>\n",
       "      <td>347</td>\n",
       "      <td>806</td>\n",
       "      <td>43.05</td>\n",
       "      <td>51.64</td>\n",
       "      <td>52.50</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>CATAACAGGGTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>70</td>\n",
       "      <td>86</td>\n",
       "      <td>2.03e-06</td>\n",
       "      <td>5.74e-05</td>\n",
       "      <td>predicted lost-regained TFBS pair</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-4-G10_R1+R2_[347/806]_rank1_%totalreads:43...</td>\n",
       "      <td>347</td>\n",
       "      <td>806</td>\n",
       "      <td>43.05</td>\n",
       "      <td>51.64</td>\n",
       "      <td>52.50</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>n/a</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.62e-06</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-4-G10_R1+R2_[347/806]_rank1_%totalreads:43...</td>\n",
       "      <td>347</td>\n",
       "      <td>806</td>\n",
       "      <td>43.05</td>\n",
       "      <td>51.64</td>\n",
       "      <td>52.50</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>CATAACAGGGTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>70</td>\n",
       "      <td>86</td>\n",
       "      <td>1.67e-06</td>\n",
       "      <td>4.99e-05</td>\n",
       "      <td>predicted lost-regained TFBS pair</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...</td>\n",
       "      <td>314</td>\n",
       "      <td>806</td>\n",
       "      <td>38.96</td>\n",
       "      <td>46.73</td>\n",
       "      <td>47.50</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>n/a</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>3.26e-06</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...</td>\n",
       "      <td>314</td>\n",
       "      <td>806</td>\n",
       "      <td>38.96</td>\n",
       "      <td>46.73</td>\n",
       "      <td>47.50</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>n/a</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.66e-06</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...</td>\n",
       "      <td>314</td>\n",
       "      <td>806</td>\n",
       "      <td>38.96</td>\n",
       "      <td>46.73</td>\n",
       "      <td>47.50</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>n/a</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.95e-06</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...</td>\n",
       "      <td>314</td>\n",
       "      <td>806</td>\n",
       "      <td>38.96</td>\n",
       "      <td>46.73</td>\n",
       "      <td>47.50</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>n/a</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.03e-06</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...</td>\n",
       "      <td>314</td>\n",
       "      <td>806</td>\n",
       "      <td>38.96</td>\n",
       "      <td>46.73</td>\n",
       "      <td>47.50</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>n/a</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.62e-06</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...</td>\n",
       "      <td>314</td>\n",
       "      <td>806</td>\n",
       "      <td>38.96</td>\n",
       "      <td>46.73</td>\n",
       "      <td>47.50</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>n/a</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.67e-06</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>3</td>\n",
       "      <td>KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...</td>\n",
       "      <td>11</td>\n",
       "      <td>806</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>CAGAACACCCTGTTATG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>69</td>\n",
       "      <td>85</td>\n",
       "      <td>3.26e-06</td>\n",
       "      <td>7.86e-05</td>\n",
       "      <td>predicted lost-regained TFBS pair</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>3</td>\n",
       "      <td>KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...</td>\n",
       "      <td>11</td>\n",
       "      <td>806</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>CATAACAGGGTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>69</td>\n",
       "      <td>85</td>\n",
       "      <td>1.66e-06</td>\n",
       "      <td>6.74e-05</td>\n",
       "      <td>predicted lost-regained TFBS pair</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>3</td>\n",
       "      <td>KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...</td>\n",
       "      <td>11</td>\n",
       "      <td>806</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>CAGAACACCCTGTTATG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>69</td>\n",
       "      <td>85</td>\n",
       "      <td>2.95e-06</td>\n",
       "      <td>7.71e-05</td>\n",
       "      <td>predicted lost-regained TFBS pair</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>3</td>\n",
       "      <td>KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...</td>\n",
       "      <td>11</td>\n",
       "      <td>806</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>CATAACAGGGTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>69</td>\n",
       "      <td>85</td>\n",
       "      <td>2.03e-06</td>\n",
       "      <td>5.74e-05</td>\n",
       "      <td>predicted lost-regained TFBS pair</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>3</td>\n",
       "      <td>KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...</td>\n",
       "      <td>11</td>\n",
       "      <td>806</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>n/a</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.62e-06</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>3</td>\n",
       "      <td>KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...</td>\n",
       "      <td>11</td>\n",
       "      <td>806</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>CATAACAGGGTGTTCTG</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>69</td>\n",
       "      <td>85</td>\n",
       "      <td>1.67e-06</td>\n",
       "      <td>4.99e-05</td>\n",
       "      <td>predicted lost-regained TFBS pair</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>3</td>\n",
       "      <td>KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...</td>\n",
       "      <td>11</td>\n",
       "      <td>806</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>n/a</td>\n",
       "      <td>CTATTGTTC</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>1.53e-05</td>\n",
       "      <td>predicted TFBS gain (novel to allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>3</td>\n",
       "      <td>KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...</td>\n",
       "      <td>11</td>\n",
       "      <td>806</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>n/a</td>\n",
       "      <td>CTATTGTTCT</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>predicted TFBS gain (novel to allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>n/a</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>3.26e-06</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>n/a</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.66e-06</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>n/a</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.95e-06</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>n/a</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.03e-06</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>n/a</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>2.62e-06</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>n/a</td>\n",
       "      <td>65</td>\n",
       "      <td>81</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1.67e-06</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>predicted TFBS loss (TFBS lost in allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>n/a</td>\n",
       "      <td>CTATTGTTC</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>1.53e-05</td>\n",
       "      <td>predicted TFBS gain (novel to allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>...</td>\n",
       "      <td>n/a</td>\n",
       "      <td>CTATTGTTCT</td>\n",
       "      <td>n/a</td>\n",
       "      <td>n/a</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "      <td>n/a (&gt;1e-4 threshold)</td>\n",
       "      <td>8e-05</td>\n",
       "      <td>predicted TFBS gain (novel to allele)</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sample  allele rank                                          allele ID  \\\n",
       "0   KE4-1-C02            1  KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "1   KE4-1-C02            1  KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "2   KE4-1-C02            1  KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "3   KE4-1-C02            1  KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "4   KE4-1-C02            1  KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "5   KE4-1-C02            1  KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "6   KE4-1-C02            1  KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "7   KE4-1-C02            1  KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "8   KE4-1-C02            1  KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "9   KE4-1-C02            1  KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "10  KE4-1-C02            1  KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "11  KE4-1-C02            1  KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "12  KE4-1-C02            1  KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "13  KE4-1-C02            1  KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "14  KE4-1-C02            1  KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "15  KE4-1-C02            1  KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "16  KE4-1-C02            1  KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "17  KE4-1-C02            1  KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "18  KE4-1-C02            1  KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "19  KE4-1-C02            1  KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "20  KE4-1-C02            1  KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "21  KE4-1-C02            1  KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....   \n",
       "22  KE4-2-A01            2  KE4-2-A01_R1+R2_[140/435]_rank2_%totalreads:32...   \n",
       "23  KE4-2-A01            2  KE4-2-A01_R1+R2_[140/435]_rank2_%totalreads:32...   \n",
       "24  KE4-2-A01            2  KE4-2-A01_R1+R2_[140/435]_rank2_%totalreads:32...   \n",
       "25  KE4-2-A01            2  KE4-2-A01_R1+R2_[140/435]_rank2_%totalreads:32...   \n",
       "26  KE4-2-A01            2  KE4-2-A01_R1+R2_[140/435]_rank2_%totalreads:32...   \n",
       "27  KE4-2-A01            2  KE4-2-A01_R1+R2_[140/435]_rank2_%totalreads:32...   \n",
       "28  KE4-2-A01            2  KE4-2-A01_R1+R2_[140/435]_rank2_%totalreads:32...   \n",
       "29  KE4-2-A01            4  KE4-2-A01_R1+R2_[11/435]_rank4_%totalreads:2.5...   \n",
       "..        ...          ...                                                ...   \n",
       "66  KE4-4-G02            4  KE4-4-G02_R1+R2_[11/996]_rank4_%totalreads:1.1...   \n",
       "67  KE4-4-G02            4  KE4-4-G02_R1+R2_[11/996]_rank4_%totalreads:1.1...   \n",
       "68  KE4-4-G10            1  KE4-4-G10_R1+R2_[347/806]_rank1_%totalreads:43...   \n",
       "69  KE4-4-G10            1  KE4-4-G10_R1+R2_[347/806]_rank1_%totalreads:43...   \n",
       "70  KE4-4-G10            1  KE4-4-G10_R1+R2_[347/806]_rank1_%totalreads:43...   \n",
       "71  KE4-4-G10            1  KE4-4-G10_R1+R2_[347/806]_rank1_%totalreads:43...   \n",
       "72  KE4-4-G10            1  KE4-4-G10_R1+R2_[347/806]_rank1_%totalreads:43...   \n",
       "73  KE4-4-G10            1  KE4-4-G10_R1+R2_[347/806]_rank1_%totalreads:43...   \n",
       "74  KE4-4-G10            2  KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...   \n",
       "75  KE4-4-G10            2  KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...   \n",
       "76  KE4-4-G10            2  KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...   \n",
       "77  KE4-4-G10            2  KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...   \n",
       "78  KE4-4-G10            2  KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...   \n",
       "79  KE4-4-G10            2  KE4-4-G10_R1+R2_[314/806]_rank2_%totalreads:38...   \n",
       "80  KE4-4-G10            3  KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...   \n",
       "81  KE4-4-G10            3  KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...   \n",
       "82  KE4-4-G10            3  KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...   \n",
       "83  KE4-4-G10            3  KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...   \n",
       "84  KE4-4-G10            3  KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...   \n",
       "85  KE4-4-G10            3  KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...   \n",
       "86  KE4-4-G10            3  KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...   \n",
       "87  KE4-4-G10            3  KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...   \n",
       "88  KE4-4-G10            4  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...   \n",
       "89  KE4-4-G10            4  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...   \n",
       "90  KE4-4-G10            4  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...   \n",
       "91  KE4-4-G10            4  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...   \n",
       "92  KE4-4-G10            4  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...   \n",
       "93  KE4-4-G10            4  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...   \n",
       "94  KE4-4-G10            4  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...   \n",
       "95  KE4-4-G10            4  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...   \n",
       "\n",
       "   read count total reads % total reads  % reads filtered for reads <1%  \\\n",
       "0          82         144         56.94                           88.17   \n",
       "1          82         144         56.94                           88.17   \n",
       "2          82         144         56.94                           88.17   \n",
       "3          82         144         56.94                           88.17   \n",
       "4          82         144         56.94                           88.17   \n",
       "5          82         144         56.94                           88.17   \n",
       "6          82         144         56.94                           88.17   \n",
       "7          82         144         56.94                           88.17   \n",
       "8          82         144         56.94                           88.17   \n",
       "9          82         144         56.94                           88.17   \n",
       "10         82         144         56.94                           88.17   \n",
       "11         82         144         56.94                           88.17   \n",
       "12         82         144         56.94                           88.17   \n",
       "13         82         144         56.94                           88.17   \n",
       "14         82         144         56.94                           88.17   \n",
       "15         82         144         56.94                           88.17   \n",
       "16         82         144         56.94                           88.17   \n",
       "17         82         144         56.94                           88.17   \n",
       "18         82         144         56.94                           88.17   \n",
       "19         82         144         56.94                           88.17   \n",
       "20         82         144         56.94                           88.17   \n",
       "21         82         144         56.94                           88.17   \n",
       "22        140         435         32.18                           38.25   \n",
       "23        140         435         32.18                           38.25   \n",
       "24        140         435         32.18                           38.25   \n",
       "25        140         435         32.18                           38.25   \n",
       "26        140         435         32.18                           38.25   \n",
       "27        140         435         32.18                           38.25   \n",
       "28        140         435         32.18                           38.25   \n",
       "29         11         435          2.53                            3.01   \n",
       "..        ...         ...           ...                             ...   \n",
       "66         11         996           1.1                            1.32   \n",
       "67         11         996           1.1                            1.32   \n",
       "68        347         806         43.05                           51.64   \n",
       "69        347         806         43.05                           51.64   \n",
       "70        347         806         43.05                           51.64   \n",
       "71        347         806         43.05                           51.64   \n",
       "72        347         806         43.05                           51.64   \n",
       "73        347         806         43.05                           51.64   \n",
       "74        314         806         38.96                           46.73   \n",
       "75        314         806         38.96                           46.73   \n",
       "76        314         806         38.96                           46.73   \n",
       "77        314         806         38.96                           46.73   \n",
       "78        314         806         38.96                           46.73   \n",
       "79        314         806         38.96                           46.73   \n",
       "80         11         806          1.36                            1.64   \n",
       "81         11         806          1.36                            1.64   \n",
       "82         11         806          1.36                            1.64   \n",
       "83         11         806          1.36                            1.64   \n",
       "84         11         806          1.36                            1.64   \n",
       "85         11         806          1.36                            1.64   \n",
       "86         11         806          1.36                            1.64   \n",
       "87         11         806          1.36                            1.64   \n",
       "88          4         806           0.5                            0.00   \n",
       "89          4         806           0.5                            0.00   \n",
       "90          4         806           0.5                            0.00   \n",
       "91          4         806           0.5                            0.00   \n",
       "92          4         806           0.5                            0.00   \n",
       "93          4         806           0.5                            0.00   \n",
       "94          4         806           0.5                            0.00   \n",
       "95          4         806           0.5                            0.00   \n",
       "\n",
       "    % reads filtered for reads <10%  \\\n",
       "0                            100.00   \n",
       "1                            100.00   \n",
       "2                            100.00   \n",
       "3                            100.00   \n",
       "4                            100.00   \n",
       "5                            100.00   \n",
       "6                            100.00   \n",
       "7                            100.00   \n",
       "8                            100.00   \n",
       "9                            100.00   \n",
       "10                           100.00   \n",
       "11                           100.00   \n",
       "12                           100.00   \n",
       "13                           100.00   \n",
       "14                           100.00   \n",
       "15                           100.00   \n",
       "16                           100.00   \n",
       "17                           100.00   \n",
       "18                           100.00   \n",
       "19                           100.00   \n",
       "20                           100.00   \n",
       "21                           100.00   \n",
       "22                            41.79   \n",
       "23                            41.79   \n",
       "24                            41.79   \n",
       "25                            41.79   \n",
       "26                            41.79   \n",
       "27                            41.79   \n",
       "28                            41.79   \n",
       "29                             0.00   \n",
       "..                              ...   \n",
       "66                             0.00   \n",
       "67                             0.00   \n",
       "68                            52.50   \n",
       "69                            52.50   \n",
       "70                            52.50   \n",
       "71                            52.50   \n",
       "72                            52.50   \n",
       "73                            52.50   \n",
       "74                            47.50   \n",
       "75                            47.50   \n",
       "76                            47.50   \n",
       "77                            47.50   \n",
       "78                            47.50   \n",
       "79                            47.50   \n",
       "80                             0.00   \n",
       "81                             0.00   \n",
       "82                             0.00   \n",
       "83                             0.00   \n",
       "84                             0.00   \n",
       "85                             0.00   \n",
       "86                             0.00   \n",
       "87                             0.00   \n",
       "88                             0.00   \n",
       "89                             0.00   \n",
       "90                             0.00   \n",
       "91                             0.00   \n",
       "92                             0.00   \n",
       "93                             0.00   \n",
       "94                             0.00   \n",
       "95                             0.00   \n",
       "\n",
       "                   alignment query\\n(allele sequence)  \\\n",
       "0   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "1   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "2   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "3   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "4   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "5   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "6   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "7   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "8   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "9   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "10  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "11  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "12  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "13  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "14  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "15  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "16  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "17  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "18  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "19  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "20  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "21  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "22  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "23  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "24  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "25  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "26  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "27  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "28  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "29                    ACTTAAACTGGAGCTCTGACTTATTGTTCTC   \n",
       "..                                                ...   \n",
       "66  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "67  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "68  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "69  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "70  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "71  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "72  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "73  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "74  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "75  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "76  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "77  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "78  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "79  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "80  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "81  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "82  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "83  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "84  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "85  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "86  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "87  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "88  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "89  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "90  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "91  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "92  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "93  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "94  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "95  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "\n",
       "                                    alignment midline  ...  \\\n",
       "0   ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "1   ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "2   ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "3   ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "4   ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "5   ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "6   ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "7   ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "8   ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "9   ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "10  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "11  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "12  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "13  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "14  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "15  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "16  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "17  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "18  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "19  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "20  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "21  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "22  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "23  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "24  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "25  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "26  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "27  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "28  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "29                    |||||||||||||||||||||||||||||||  ...   \n",
       "..                                                ...  ...   \n",
       "66  |||||||||||||||||||| |||||||||||||||||||||||||...  ...   \n",
       "67  |||||||||||||||||||| |||||||||||||||||||||||||...  ...   \n",
       "68  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "69  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "70  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "71  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "72  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "73  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "74  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "75  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "76  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "77  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "78  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "79  ||||||||||||||||||||||||||||||||||||||||||||||...  ...   \n",
       "80  |||||||||||||||||||| |||||||||||||||||||||||||...  ...   \n",
       "81  |||||||||||||||||||| |||||||||||||||||||||||||...  ...   \n",
       "82  |||||||||||||||||||| |||||||||||||||||||||||||...  ...   \n",
       "83  |||||||||||||||||||| |||||||||||||||||||||||||...  ...   \n",
       "84  |||||||||||||||||||| |||||||||||||||||||||||||...  ...   \n",
       "85  |||||||||||||||||||| |||||||||||||||||||||||||...  ...   \n",
       "86  |||||||||||||||||||| |||||||||||||||||||||||||...  ...   \n",
       "87  |||||||||||||||||||| |||||||||||||||||||||||||...  ...   \n",
       "88  |||||||||||||||||||| |||||||||||||||||||||||||...  ...   \n",
       "89  |||||||||||||||||||| |||||||||||||||||||||||||...  ...   \n",
       "90  |||||||||||||||||||| |||||||||||||||||||||||||...  ...   \n",
       "91  |||||||||||||||||||| |||||||||||||||||||||||||...  ...   \n",
       "92  |||||||||||||||||||| |||||||||||||||||||||||||...  ...   \n",
       "93  |||||||||||||||||||| |||||||||||||||||||||||||...  ...   \n",
       "94  |||||||||||||||||||| |||||||||||||||||||||||||...  ...   \n",
       "95  |||||||||||||||||||| |||||||||||||||||||||||||...  ...   \n",
       "\n",
       "   Lost TFBS sequence (in reference at this position, lost in allele)\\n*Note: this TFBS sequence is in the reference, 5'-3' on strand indicated in 'strand'  \\\n",
       "0                                   CAGAACACCCTGTTCTG                                                                                                         \n",
       "1                                   CAGAACAGGGTGTTCTG                                                                                                         \n",
       "2                                      TTTTCCCCCCTATT                                                                                                         \n",
       "3                                                 n/a                                                                                                         \n",
       "4                                        TTTCCCCCCTAT                                                                                                         \n",
       "5                                                 n/a                                                                                                         \n",
       "6                                                 n/a                                                                                                         \n",
       "7                                           GTGCCAGCC                                                                                                         \n",
       "8                                           GTGCCAGCC                                                                                                         \n",
       "9                                             CTGACAG                                                                                                         \n",
       "10                                           CTGACAGC                                                                                                         \n",
       "11                                       GATGTGCTGACA                                                                                                         \n",
       "12                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "13                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "14                                  ATGAACTCGATGTGCTG                                                                                                         \n",
       "15                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "16                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "17                                        GATGTGCTGAC                                                                                                         \n",
       "18                                  AGTTCATGTGCCAGCCA                                                                                                         \n",
       "19                                    AGCACATCGAGTTCA                                                                                                         \n",
       "20                                      GTGGCTGGCACAT                                                                                                         \n",
       "21                                   CAGCACATCGAGTTCA                                                                                                         \n",
       "22                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "23                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "24                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "25                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "26                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "27                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "28                                                n/a                                                                                                         \n",
       "29                                                n/a                                                                                                         \n",
       "..                                                ...                                                                                                         \n",
       "66                                                n/a                                                                                                         \n",
       "67                                                n/a                                                                                                         \n",
       "68                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "69                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "70                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "71                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "72                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "73                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "74                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "75                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "76                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "77                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "78                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "79                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "80                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "81                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "82                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "83                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "84                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "85                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "86                                                n/a                                                                                                         \n",
       "87                                                n/a                                                                                                         \n",
       "88                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "89                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "90                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "91                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "92                                  CAGAACACCCTGTTCTG                                                                                                         \n",
       "93                                  CAGAACAGGGTGTTCTG                                                                                                         \n",
       "94                                                n/a                                                                                                         \n",
       "95                                                n/a                                                                                                         \n",
       "\n",
       "   Gained TFBS sequence (not in reference at this position, novel to allele)\\n*Note: this TFBS sequence is in the allele, 5'-3' on strand indicated in 'strand'  \\\n",
       "0                                                 n/a                                                                                                             \n",
       "1                                                 n/a                                                                                                             \n",
       "2                                                 n/a                                                                                                             \n",
       "3                                      TTTTCCCCCCAAAC                                                                                                             \n",
       "4                                                 n/a                                                                                                             \n",
       "5                                        TTTTCCCCCCAA                                                                                                             \n",
       "6                                        TTTCCCCCCAAA                                                                                                             \n",
       "7                                                 n/a                                                                                                             \n",
       "8                                                 n/a                                                                                                             \n",
       "9                                                 n/a                                                                                                             \n",
       "10                                                n/a                                                                                                             \n",
       "11                                                n/a                                                                                                             \n",
       "12                                                n/a                                                                                                             \n",
       "13                                                n/a                                                                                                             \n",
       "14                                                n/a                                                                                                             \n",
       "15                                                n/a                                                                                                             \n",
       "16                                                n/a                                                                                                             \n",
       "17                                                n/a                                                                                                             \n",
       "18                                                n/a                                                                                                             \n",
       "19                                                n/a                                                                                                             \n",
       "20                                                n/a                                                                                                             \n",
       "21                                                n/a                                                                                                             \n",
       "22                                  CAGAACACCCTGTTTTG                                                                                                             \n",
       "23                                  CAAAACAGGGTGTTCTG                                                                                                             \n",
       "24                                  CAGAACACCCTGTTTTG                                                                                                             \n",
       "25                                  CAAAACAGGGTGTTCTG                                                                                                             \n",
       "26                                  CAGAACACCCTGTTTTG                                                                                                             \n",
       "27                                  CAAAACAGGGTGTTCTG                                                                                                             \n",
       "28                                        TTTTGTGGCTG                                                                                                             \n",
       "29                                        TTTCCGAGAAC                                                                                                             \n",
       "..                                                ...                                                                                                             \n",
       "66                                          CTATTGTTC                                                                                                             \n",
       "67                                         CTATTGTTCT                                                                                                             \n",
       "68                                  CAGAACACCCTGTTATG                                                                                                             \n",
       "69                                  CATAACAGGGTGTTCTG                                                                                                             \n",
       "70                                  CAGAACACCCTGTTATG                                                                                                             \n",
       "71                                  CATAACAGGGTGTTCTG                                                                                                             \n",
       "72                                                n/a                                                                                                             \n",
       "73                                  CATAACAGGGTGTTCTG                                                                                                             \n",
       "74                                                n/a                                                                                                             \n",
       "75                                                n/a                                                                                                             \n",
       "76                                                n/a                                                                                                             \n",
       "77                                                n/a                                                                                                             \n",
       "78                                                n/a                                                                                                             \n",
       "79                                                n/a                                                                                                             \n",
       "80                                  CAGAACACCCTGTTATG                                                                                                             \n",
       "81                                  CATAACAGGGTGTTCTG                                                                                                             \n",
       "82                                  CAGAACACCCTGTTATG                                                                                                             \n",
       "83                                  CATAACAGGGTGTTCTG                                                                                                             \n",
       "84                                                n/a                                                                                                             \n",
       "85                                  CATAACAGGGTGTTCTG                                                                                                             \n",
       "86                                          CTATTGTTC                                                                                                             \n",
       "87                                         CTATTGTTCT                                                                                                             \n",
       "88                                                n/a                                                                                                             \n",
       "89                                                n/a                                                                                                             \n",
       "90                                                n/a                                                                                                             \n",
       "91                                                n/a                                                                                                             \n",
       "92                                                n/a                                                                                                             \n",
       "93                                                n/a                                                                                                             \n",
       "94                                          CTATTGTTC                                                                                                             \n",
       "95                                         CTATTGTTCT                                                                                                             \n",
       "\n",
       "   Lost TFBS coordinate start (in reference)  \\\n",
       "0                                         64   \n",
       "1                                         64   \n",
       "2                                        135   \n",
       "3                                        n/a   \n",
       "4                                        136   \n",
       "5                                        n/a   \n",
       "6                                        n/a   \n",
       "7                                         86   \n",
       "8                                         86   \n",
       "9                                        109   \n",
       "10                                       109   \n",
       "11                                       103   \n",
       "12                                        64   \n",
       "13                                        64   \n",
       "14                                        95   \n",
       "15                                        64   \n",
       "16                                        64   \n",
       "17                                       103   \n",
       "18                                        85   \n",
       "19                                        96   \n",
       "20                                        84   \n",
       "21                                        96   \n",
       "22                                        65   \n",
       "23                                        65   \n",
       "24                                        65   \n",
       "25                                        65   \n",
       "26                                        65   \n",
       "27                                        65   \n",
       "28                                       n/a   \n",
       "29                                       n/a   \n",
       "..                                       ...   \n",
       "66                                       n/a   \n",
       "67                                       n/a   \n",
       "68                                        65   \n",
       "69                                        65   \n",
       "70                                        65   \n",
       "71                                        65   \n",
       "72                                        65   \n",
       "73                                        65   \n",
       "74                                        65   \n",
       "75                                        65   \n",
       "76                                        65   \n",
       "77                                        65   \n",
       "78                                        65   \n",
       "79                                        65   \n",
       "80                                        65   \n",
       "81                                        65   \n",
       "82                                        65   \n",
       "83                                        65   \n",
       "84                                        65   \n",
       "85                                        65   \n",
       "86                                       n/a   \n",
       "87                                       n/a   \n",
       "88                                        65   \n",
       "89                                        65   \n",
       "90                                        65   \n",
       "91                                        65   \n",
       "92                                        65   \n",
       "93                                        65   \n",
       "94                                       n/a   \n",
       "95                                       n/a   \n",
       "\n",
       "   Lost TFBS coordinate end (in reference)  \\\n",
       "0                                       80   \n",
       "1                                       80   \n",
       "2                                      148   \n",
       "3                                      n/a   \n",
       "4                                      147   \n",
       "5                                      n/a   \n",
       "6                                      n/a   \n",
       "7                                       94   \n",
       "8                                       94   \n",
       "9                                      115   \n",
       "10                                     116   \n",
       "11                                     114   \n",
       "12                                      80   \n",
       "13                                      80   \n",
       "14                                     111   \n",
       "15                                      80   \n",
       "16                                      80   \n",
       "17                                     113   \n",
       "18                                     101   \n",
       "19                                     110   \n",
       "20                                      96   \n",
       "21                                     111   \n",
       "22                                      81   \n",
       "23                                      81   \n",
       "24                                      81   \n",
       "25                                      81   \n",
       "26                                      81   \n",
       "27                                      81   \n",
       "28                                     n/a   \n",
       "29                                     n/a   \n",
       "..                                     ...   \n",
       "66                                     n/a   \n",
       "67                                     n/a   \n",
       "68                                      81   \n",
       "69                                      81   \n",
       "70                                      81   \n",
       "71                                      81   \n",
       "72                                      81   \n",
       "73                                      81   \n",
       "74                                      81   \n",
       "75                                      81   \n",
       "76                                      81   \n",
       "77                                      81   \n",
       "78                                      81   \n",
       "79                                      81   \n",
       "80                                      81   \n",
       "81                                      81   \n",
       "82                                      81   \n",
       "83                                      81   \n",
       "84                                      81   \n",
       "85                                      81   \n",
       "86                                     n/a   \n",
       "87                                     n/a   \n",
       "88                                      81   \n",
       "89                                      81   \n",
       "90                                      81   \n",
       "91                                      81   \n",
       "92                                      81   \n",
       "93                                      81   \n",
       "94                                     n/a   \n",
       "95                                     n/a   \n",
       "\n",
       "   Gained TFBS coordinate start (in allele)  \\\n",
       "0                                       n/a   \n",
       "1                                       n/a   \n",
       "2                                       n/a   \n",
       "3                                        53   \n",
       "4                                       n/a   \n",
       "5                                        55   \n",
       "6                                        54   \n",
       "7                                       n/a   \n",
       "8                                       n/a   \n",
       "9                                       n/a   \n",
       "10                                      n/a   \n",
       "11                                      n/a   \n",
       "12                                      n/a   \n",
       "13                                      n/a   \n",
       "14                                      n/a   \n",
       "15                                      n/a   \n",
       "16                                      n/a   \n",
       "17                                      n/a   \n",
       "18                                      n/a   \n",
       "19                                      n/a   \n",
       "20                                      n/a   \n",
       "21                                      n/a   \n",
       "22                                       69   \n",
       "23                                       69   \n",
       "24                                       69   \n",
       "25                                       69   \n",
       "26                                       69   \n",
       "27                                       69   \n",
       "28                                       81   \n",
       "29                                       26   \n",
       "..                                      ...   \n",
       "66                                       20   \n",
       "67                                       20   \n",
       "68                                       70   \n",
       "69                                       70   \n",
       "70                                       70   \n",
       "71                                       70   \n",
       "72                                      n/a   \n",
       "73                                       70   \n",
       "74                                      n/a   \n",
       "75                                      n/a   \n",
       "76                                      n/a   \n",
       "77                                      n/a   \n",
       "78                                      n/a   \n",
       "79                                      n/a   \n",
       "80                                       69   \n",
       "81                                       69   \n",
       "82                                       69   \n",
       "83                                       69   \n",
       "84                                      n/a   \n",
       "85                                       69   \n",
       "86                                       20   \n",
       "87                                       20   \n",
       "88                                      n/a   \n",
       "89                                      n/a   \n",
       "90                                      n/a   \n",
       "91                                      n/a   \n",
       "92                                      n/a   \n",
       "93                                      n/a   \n",
       "94                                       20   \n",
       "95                                       20   \n",
       "\n",
       "   Gained TFBS coordinate end (in allele) Lost TFBS p-val (in reference)  \\\n",
       "0                                     n/a                       3.26e-06   \n",
       "1                                     n/a                       1.66e-06   \n",
       "2                                     n/a                       1.09e-05   \n",
       "3                                      66          n/a (>1e-4 threshold)   \n",
       "4                                     n/a                       1.41e-05   \n",
       "5                                      66          n/a (>1e-4 threshold)   \n",
       "6                                      65          n/a (>1e-4 threshold)   \n",
       "7                                     n/a                       5.37e-05   \n",
       "8                                     n/a                       5.97e-06   \n",
       "9                                     n/a                       4.53e-05   \n",
       "10                                    n/a                        6.8e-05   \n",
       "11                                    n/a                       1.25e-05   \n",
       "12                                    n/a                       2.95e-06   \n",
       "13                                    n/a                       2.03e-06   \n",
       "14                                    n/a                       9.39e-05   \n",
       "15                                    n/a                       2.62e-06   \n",
       "16                                    n/a                       1.67e-06   \n",
       "17                                    n/a                       2.79e-06   \n",
       "18                                    n/a                       8.03e-05   \n",
       "19                                    n/a                       6.66e-05   \n",
       "20                                    n/a                       7.99e-06   \n",
       "21                                    n/a                       4.58e-05   \n",
       "22                                     85                       3.26e-06   \n",
       "23                                     85                       1.66e-06   \n",
       "24                                     85                       2.95e-06   \n",
       "25                                     85                       2.03e-06   \n",
       "26                                     85                       2.62e-06   \n",
       "27                                     85                       1.67e-06   \n",
       "28                                     91          n/a (>1e-4 threshold)   \n",
       "29                                     36          n/a (>1e-4 threshold)   \n",
       "..                                    ...                            ...   \n",
       "66                                     28          n/a (>1e-4 threshold)   \n",
       "67                                     29          n/a (>1e-4 threshold)   \n",
       "68                                     86                       3.26e-06   \n",
       "69                                     86                       1.66e-06   \n",
       "70                                     86                       2.95e-06   \n",
       "71                                     86                       2.03e-06   \n",
       "72                                    n/a                       2.62e-06   \n",
       "73                                     86                       1.67e-06   \n",
       "74                                    n/a                       3.26e-06   \n",
       "75                                    n/a                       1.66e-06   \n",
       "76                                    n/a                       2.95e-06   \n",
       "77                                    n/a                       2.03e-06   \n",
       "78                                    n/a                       2.62e-06   \n",
       "79                                    n/a                       1.67e-06   \n",
       "80                                     85                       3.26e-06   \n",
       "81                                     85                       1.66e-06   \n",
       "82                                     85                       2.95e-06   \n",
       "83                                     85                       2.03e-06   \n",
       "84                                    n/a                       2.62e-06   \n",
       "85                                     85                       1.67e-06   \n",
       "86                                     28          n/a (>1e-4 threshold)   \n",
       "87                                     29          n/a (>1e-4 threshold)   \n",
       "88                                    n/a                       3.26e-06   \n",
       "89                                    n/a                       1.66e-06   \n",
       "90                                    n/a                       2.95e-06   \n",
       "91                                    n/a                       2.03e-06   \n",
       "92                                    n/a                       2.62e-06   \n",
       "93                                    n/a                       1.67e-06   \n",
       "94                                     28          n/a (>1e-4 threshold)   \n",
       "95                                     29          n/a (>1e-4 threshold)   \n",
       "\n",
       "   Gained TBFS p-val (in allele)                             interpretation  \\\n",
       "0          n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "1          n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "2          n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "3                       3.04e-06      predicted TFBS gain (novel to allele)   \n",
       "4          n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "5                        3.6e-05      predicted TFBS gain (novel to allele)   \n",
       "6                       9.78e-08      predicted TFBS gain (novel to allele)   \n",
       "7          n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "8          n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "9          n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "10         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "11         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "12         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "13         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "14         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "15         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "16         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "17         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "18         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "19         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "20         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "21         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "22                      7.45e-05          predicted lost-regained TFBS pair   \n",
       "23                       5.9e-05          predicted lost-regained TFBS pair   \n",
       "24                      6.18e-05          predicted lost-regained TFBS pair   \n",
       "25                      5.61e-05          predicted lost-regained TFBS pair   \n",
       "26                      5.39e-05          predicted lost-regained TFBS pair   \n",
       "27                      5.08e-05          predicted lost-regained TFBS pair   \n",
       "28                      8.94e-05      predicted TFBS gain (novel to allele)   \n",
       "29                       6.9e-05      predicted TFBS gain (novel to allele)   \n",
       "..                           ...                                        ...   \n",
       "66                      1.53e-05      predicted TFBS gain (novel to allele)   \n",
       "67                         8e-05      predicted TFBS gain (novel to allele)   \n",
       "68                      7.86e-05          predicted lost-regained TFBS pair   \n",
       "69                      6.74e-05          predicted lost-regained TFBS pair   \n",
       "70                      7.71e-05          predicted lost-regained TFBS pair   \n",
       "71                      5.74e-05          predicted lost-regained TFBS pair   \n",
       "72         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "73                      4.99e-05          predicted lost-regained TFBS pair   \n",
       "74         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "75         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "76         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "77         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "78         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "79         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "80                      7.86e-05          predicted lost-regained TFBS pair   \n",
       "81                      6.74e-05          predicted lost-regained TFBS pair   \n",
       "82                      7.71e-05          predicted lost-regained TFBS pair   \n",
       "83                      5.74e-05          predicted lost-regained TFBS pair   \n",
       "84         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "85                      4.99e-05          predicted lost-regained TFBS pair   \n",
       "86                      1.53e-05      predicted TFBS gain (novel to allele)   \n",
       "87                         8e-05      predicted TFBS gain (novel to allele)   \n",
       "88         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "89         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "90         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "91         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "92         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "93         n/a (>1e-4 threshold)  predicted TFBS loss (TFBS lost in allele)   \n",
       "94                      1.53e-05      predicted TFBS gain (novel to allele)   \n",
       "95                         8e-05      predicted TFBS gain (novel to allele)   \n",
       "\n",
       "                                              comment  \n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                                      \n",
       "4                                                      \n",
       "5                                                      \n",
       "6                                                      \n",
       "7                                                      \n",
       "8                                                      \n",
       "9                                                      \n",
       "10                                                     \n",
       "11                                                     \n",
       "12                                                     \n",
       "13                                                     \n",
       "14                                                     \n",
       "15                                                     \n",
       "16                                                     \n",
       "17                                                     \n",
       "18                                                     \n",
       "19                                                     \n",
       "20                                                     \n",
       "21                                                     \n",
       "22                                                     \n",
       "23                                                     \n",
       "24                                                     \n",
       "25                                                     \n",
       "26                                                     \n",
       "27                                                     \n",
       "28                                                     \n",
       "29  note: inferred allele length <=50 bp; read may...  \n",
       "..                                                ...  \n",
       "66                                                     \n",
       "67                                                     \n",
       "68                                                     \n",
       "69                                                     \n",
       "70                                                     \n",
       "71                                                     \n",
       "72                                                     \n",
       "73                                                     \n",
       "74                                                     \n",
       "75                                                     \n",
       "76                                                     \n",
       "77                                                     \n",
       "78                                                     \n",
       "79                                                     \n",
       "80                                                     \n",
       "81                                                     \n",
       "82                                                     \n",
       "83                                                     \n",
       "84                                                     \n",
       "85                                                     \n",
       "86                                                     \n",
       "87                                                     \n",
       "88                                                     \n",
       "89                                                     \n",
       "90                                                     \n",
       "91                                                     \n",
       "92                                                     \n",
       "93                                                     \n",
       "94                                                     \n",
       "95                                                     \n",
       "\n",
       "[96 rows x 23 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare dataframe synopsis of samples and alleles, with individual rows mapping potential lost-regained TFBS pairs for in-common TFs\n",
    "interpreted_TFBS_synopsis_df_columns = {\"sample\":sample_list, \"allele rank\":allele_rank_list, \"allele ID\":allele_list, \n",
    "                                        'read count':read_count_list,\n",
    "                                        'total reads':total_reads_count_list,\n",
    "                                        '% total reads':pct_total_reads_list,\n",
    "                                        '% reads filtered for reads <1%':pct_reads_filtered_for_1pct_list,\n",
    "                                        '% reads filtered for reads <10%':pct_reads_filtered_for_10pct_list,\n",
    "                                        \"alignment query\\n(allele sequence)\":allele_sequence_list,\n",
    "                                        \"alignment midline\":alignment_midline_list, \"alignment hit\\n(reference)\":reference_sequence_list,\n",
    "                                        \"TF\":TF_list,\n",
    "                                        \"strand\":strand_list, \n",
    "                                        \"Lost TFBS sequence (in reference at this position, lost in allele)\\n*Note: this TFBS sequence is in the reference, 5'-3' on strand indicated in 'strand'\":lost_TFBS_sequence_list,\n",
    "                                        \"Gained TFBS sequence (not in reference at this position, novel to allele)\\n*Note: this TFBS sequence is in the allele, 5'-3' on strand indicated in 'strand'\":gained_TFBS_sequence_list, \n",
    "                                        \"Lost TFBS coordinate start (in reference)\":ref_start_coordinate_list,\n",
    "                                        \"Lost TFBS coordinate end (in reference)\":ref_stop_coordinate_list,\n",
    "                                        \"Gained TFBS coordinate start (in allele)\":allele_start_coordinate_list,\n",
    "                                        \"Gained TFBS coordinate end (in allele)\":allele_stop_coordinate_list,\n",
    "                                        \"Lost TFBS p-val (in reference)\":lost_TFBS_pval_list,\n",
    "                                        \"Gained TBFS p-val (in allele)\":gained_TFBS_pval_list,\n",
    "                                        \"interpretation\":predicted_lost_gained_pair_list}\n",
    "\n",
    "interpreted_TFBS_synopsis_df = pd.DataFrame(interpreted_TFBS_synopsis_df_columns)\n",
    "\n",
    "# Add column with allele comment (comment if appropriate)\n",
    "interpreted_TFBS_synopsis_df['comment'] = ['note: inferred allele length <=50 bp; read may be primer dimer; consult fasta file for this inferred allele, and/or consider pre-processing fastq file (filter reads) prior to running CollatedMotifs' if i <=50 else '' for i in [len(x) for x in interpreted_TFBS_synopsis_df['alignment query\\n(allele sequence)'].to_list()]]\n",
    "\n",
    "interpreted_TFBS_synopsis_df.sort_values(by=['sample','allele rank','TF',\"strand\",\"interpretation\"],ascending=[True, True, True, True, False])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "allele_rank_count_list = []\n",
    "sample_set = set(interpreted_TFBS_synopsis_df['sample'].to_list())\n",
    "\n",
    "for sample in sample_set:\n",
    "    allele_rank_list = []\n",
    "    for index, row in interpreted_TFBS_synopsis_df.iterrows():\n",
    "        if row['sample'] == sample:\n",
    "            if row['allele rank'] not in allele_rank_list:\n",
    "                allele_rank_list.append(row['allele rank'])\n",
    "    allele_rank_count_list.append((sample, sorted(allele_rank_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up interpreted_TFBS_synopsis_df; some sample alleles have been assigned rows that include the\n",
    "# label 'no TFBS predicted as lost or gained in allele', because of order of operations above,\n",
    "# but in fact have TFBS(s) predicted as lost or gained; find and remove these rows from interpreted_TFBS_synopsis_df\n",
    "# (in new dataframe called interpreted_TFBS_syopsis_df_updated)\n",
    "suspects = []\n",
    "for sample in allele_rank_count_list:\n",
    "    for allele_rank in sample[1]:\n",
    "        for index1, row in interpreted_TFBS_synopsis_df.iterrows():\n",
    "            if row['sample'] == sample[0] and row['allele rank'] == allele_rank and row['interpretation'] == 'no TFBS predicted as lost or gained in allele':\n",
    "                test_singularity = True\n",
    "                for index, row in interpreted_TFBS_synopsis_df.iterrows():\n",
    "                    if row['sample'] == sample[0] and row['allele rank'] == allele_rank and row['interpretation'] != 'no TFBS predicted as lost or gained in allele':\n",
    "                        test_singularity = False\n",
    "                if test_singularity == True:\n",
    "                    pass\n",
    "                elif test_singularity == False:\n",
    "                    suspects.append((sample[0], allele_rank, index1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_drop_list = [i[2] for i in suspects]\n",
    "interpreted_TFBS_synopsis_df_updated = interpreted_TFBS_synopsis_df.drop(index_drop_list)\n",
    "                     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF of interest**: if TF of interest was specified as input, the script will now query lost-gained outputs for the specific TF of interest, to interpret the following properties: **(1) lost without corresponding regain**, **(2) lost without corresponding regain *and* without positionally coinciding TFBS for new TF**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, query output for specific TF of interest, based on the following properties:\n",
    "# (1) lost without corresponding re-gain, (2) lost without corresponding re-gain and without positionally coinciding TFBS for new TF\n",
    "# TF of interest was provided by user at script outset (encoded by variable samples_list = set(interpreted_TFBS_synopsis_df['sample'].to_list())\n",
    "\n",
    "samples_list = set(interpreted_TFBS_synopsis_df['sample'].to_list())\n",
    "                   \n",
    "if TF_of_interest == '':\n",
    "    pass\n",
    "else:\n",
    "    interpretation_dict = {}\n",
    "    for sample in samples_list:\n",
    "        sample_interpretation_dict = {}\n",
    "        for index, row in interpreted_TFBS_synopsis_df_updated.sort_values(by=['sample','allele rank','TF',\"strand\",\"interpretation\"],ascending=[True, True, True, True, False]).iterrows():\n",
    "            if row['sample'] == sample:\n",
    "                if row['interpretation'] == \"no TFBS predicted as lost or gained in allele\":\n",
    "                    sample_interpretation_dict[row['allele rank']] = [row.to_list()]  \n",
    "                elif re.search(r'\\b'+TF_of_interest+r'\\b', row['TF']) and row['interpretation'] == 'predicted TFBS loss (TFBS lost in allele)':\n",
    "                    if row['allele rank'] not in sample_interpretation_dict:\n",
    "                        sample_interpretation_dict[row['allele rank']] = [row.to_list()]\n",
    "                    elif row['allele rank'] in sample_interpretation_dict:\n",
    "                        sample_interpretation_dict[row['allele rank']].append(row.to_list())\n",
    "                elif re.search(r'\\b'+TF_of_interest+r'\\b', row['TF']) and row['interpretation'] == 'predicted TFBS gain (novel to allele)':\n",
    "                    if row['allele rank'] not in sample_interpretation_dict:\n",
    "                        sample_interpretation_dict[row['allele rank']] = [row.to_list()]\n",
    "                    elif row['allele rank'] in sample_interpretation_dict:\n",
    "                        sample_interpretation_dict[row['allele rank']].append(row.to_list())\n",
    "                elif re.search(r'\\b'+TF_of_interest+r'\\b', row['TF']) and row['interpretation'] == 'predicted lost-regained TFBS pair':\n",
    "                    if row['allele rank'] not in sample_interpretation_dict:\n",
    "                        sample_interpretation_dict[row['allele rank']] = [row.to_list()]\n",
    "                    elif row['allele rank'] in sample_interpretation_dict:\n",
    "                        sample_interpretation_dict[row['allele rank']].append(row.to_list())         \n",
    "        interpretation_dict[sample] = sample_interpretation_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# July 2021\n",
    "# Now assess potential samples of particular interest based on 2 criteria above\n",
    "# Iterate through alleles to bin alleles for samples among the indicated lists below\n",
    "# (1) lost without corresponding gain, (2) lost without corresponding gain and without positionally coinciding TFBS for new TF\n",
    "# for (2), check for 'predicted TFBS gain (novel to allele)' that coincides with position of TFBS loss for TF of interest\n",
    "\n",
    "if TF_of_interest == '':\n",
    "    pass\n",
    "else:               \n",
    "    predicted_loss_of_target_TFBS_list = []\n",
    "    predicted_exclusive_loss_of_target_TFBS_list = []\n",
    "    predicted_loss_with_regain_of_different_TFBS_for_same_TF_list = []\n",
    "    predicted_loss_with_gain_of_different_TFBS_list = []\n",
    "\n",
    "    for sample in interpretation_dict:\n",
    "        for allele in interpretation_dict.get(sample):\n",
    "            for instance in interpretation_dict.get(sample).get(allele):\n",
    "                # loss with corresponding \"re-gain\" of 'replacement' TFBS for TF of interest\n",
    "                if instance[21] == 'predicted lost-regained TFBS pair':\n",
    "                    predicted_loss_with_regain_of_different_TFBS_for_same_TF_list.append(instance)\n",
    "                # loss without corresponding gain of 'replacement' TFBS for TF of interest\n",
    "                elif instance[21] == 'predicted TFBS loss (TFBS lost in allele)':\n",
    "                    predicted_loss_of_target_TFBS_list.append((sample,allele,instance))\n",
    "                    exclusive_loss_check = True\n",
    "                # further filter, for loss without corresponding gain of 'replacement' TFBS for TF of interest & no predicted positionally coinciding novel TFBS\n",
    "                    # consider two coordinate ranges to check (regarding losses):\n",
    "                    # first, check for allele's span between alignment blocks\n",
    "                    span_between_alignment_blocks = allele_TFBS_synopsis_df_coordinates_updated.loc[\n",
    "                        (allele_TFBS_synopsis_df_coordinates_updated['sample'] == sample) & \n",
    "                        (allele_TFBS_synopsis_df_coordinates_updated['allele rank'] == allele) &\n",
    "                        (allele_TFBS_synopsis_df_coordinates_updated['strand'] == instance[12]) &\n",
    "                        (allele_TFBS_synopsis_df_coordinates_updated['TF'].str.match(r'\\b'+TF_of_interest+r'\\b')) &\n",
    "                        (allele_TFBS_synopsis_df_coordinates_updated['Lost TFBS start coordinate (in reference)'] == int(instance[15])) &\n",
    "                        (allele_TFBS_synopsis_df_coordinates_updated['Lost TFBS end coordinate (in reference)'] == int(instance[16]))]['span between alignment blocks'].values[0]\n",
    "                    if span_between_alignment_blocks != 'n/a':\n",
    "                        for index, row in interpreted_TFBS_synopsis_df_updated.iterrows():\n",
    "                            if row['sample'] == sample and row['allele rank'] == allele and row['interpretation'] == 'predicted TFBS gain (novel to allele)':\n",
    "                                if set(range(int(row['Gained TFBS coordinate start (in allele)']),int(row['Gained TFBS coordinate end (in allele)']))).intersection(range(span_between_alignment_blocks[0],span_between_alignment_blocks[1])):\n",
    "                                    predicted_loss_with_gain_of_different_TFBS_list.append(((sample,allele,instance, row.to_list())))\n",
    "                                    exclusive_loss_check = False\n",
    "                    else:\n",
    "                        coordinate_range_to_check = range(int(interpreted_TFBS_synopsis_df_updated.loc[(interpreted_TFBS_synopsis_df_updated['sample'] == sample) &\n",
    "                                                 (interpreted_TFBS_synopsis_df_updated['allele rank'] == allele) &\n",
    "                                                  (interpreted_TFBS_synopsis_df_updated['strand'] == instance[12]) &\n",
    "                                                 (interpreted_TFBS_synopsis_df_updated['interpretation'] == 'predicted TFBS loss (TFBS lost in allele)') &\n",
    "                                                (interpreted_TFBS_synopsis_df_updated['TF'].str.match(r'\\b'+TF_of_interest+r'\\b'))]['Lost TFBS coordinate start (in reference)'].values[0]),\n",
    "                                                  int(interpreted_TFBS_synopsis_df_updated.loc[(interpreted_TFBS_synopsis_df_updated['sample'] == sample) &\n",
    "                                                 (interpreted_TFBS_synopsis_df_updated['allele rank'] == allele) &\n",
    "                                                  (interpreted_TFBS_synopsis_df_updated['strand'] == instance[12]) &\n",
    "                                                 (interpreted_TFBS_synopsis_df_updated['interpretation'] == 'predicted TFBS loss (TFBS lost in allele)') &\n",
    "                                                (interpreted_TFBS_synopsis_df_updated['TF'].str.match(r'\\b'+TF_of_interest+r'\\b'))]['Lost TFBS coordinate end (in reference)'].values[0]))\n",
    "                        for index, row in interpreted_TFBS_synopsis_df_updated.iterrows():\n",
    "                            if row['sample'] == sample and row['allele rank'] == allele and row['interpretation'] == 'predicted TFBS gain (novel to allele)':\n",
    "                                if set(coordinate_range_to_check).intersection(range(int(row['Gained TFBS coordinate start (in allele)']), \n",
    "                                                                             int(row['Gained TFBS coordinate end (in allele)']))):\n",
    "                                    predicted_loss_with_gain_of_different_TFBS_list.append(((sample,allele,instance, row.to_list())))\n",
    "                                    exclusive_loss_check = False\n",
    "                    if exclusive_loss_check == True:\n",
    "                        predicted_exclusive_loss_of_target_TFBS_list.append((sample,allele,instance))\n",
    "                                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF of interest**--*predicted_loss_of_TFBS_synopsis_df*: dataframe that catalogs sample alleles identified as having lost TFBS for TF of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare output to indicate **loss of TFBS for TF of interest**, without regain of different TFBS for same TF\n",
    "if TF_of_interest == '':\n",
    "    pass\n",
    "else:\n",
    "    sample_list = []\n",
    "    allele_rank_list = []\n",
    "    allele_list = []\n",
    "    read_count_list = []\n",
    "    total_reads_count_list = []\n",
    "    pct_total_reads_list = []\n",
    "    pct_reads_filtered_for_1pct_list = []\n",
    "    pct_reads_filtered_for_10pct_list = []\n",
    "    allele_sequence_list = []\n",
    "    reference_sequence_list = []\n",
    "    alignment_midline_list = []\n",
    "    TF_lost_list = []\n",
    "    TF_lost_strand_list = []\n",
    "    lost_TFBS_sequence_list = []\n",
    "    lost_TFBS_start_coordinate_list = []\n",
    "    lost_TFBS_end_coordinate_list = []\n",
    "    lost_TFBS_pval_list = []\n",
    "\n",
    "    for pair in predicted_loss_of_target_TFBS_list:\n",
    "        sample_list.append(pair[0])\n",
    "        allele_rank_list.append(pair[1])\n",
    "        allele_list.append(pair[2][2])\n",
    "        read_count_list.append(pair[2][2].split('_')[2].strip('[]').split('/')[0])\n",
    "        total_reads_count_list.append(pair[2][2].split('_')[2].strip('[]').split('/')[1])\n",
    "        pct_total_reads_list.append(pair[2][5])\n",
    "        pct_reads_filtered_for_1pct_list.append(pair[2][6])\n",
    "        pct_reads_filtered_for_10pct_list.append(pair[2][7])\n",
    "        allele_sequence_list.append(pair[2][8])\n",
    "        reference_sequence_list.append(pair[2][10])\n",
    "        alignment_midline_list.append(pair[2][9])\n",
    "        TF_lost_list.append(pair[2][11])\n",
    "        TF_lost_strand_list.append(pair[2][12])\n",
    "        lost_TFBS_sequence_list.append(pair[2][13])\n",
    "        lost_TFBS_start_coordinate_list.append(pair[2][15])\n",
    "        lost_TFBS_end_coordinate_list.append(pair[2][16])\n",
    "        lost_TFBS_pval_list.append(pair[2][19])\n",
    "        \n",
    "# create dataframe for predicted_loss_of_TFBS_synopsis\n",
    "if TF_of_interest == '':\n",
    "    pass\n",
    "else:\n",
    "    predicted_loss_of_TFBS_synopsis_df_columns = {\"sample\":sample_list, \"allele rank\":allele_rank_list, \"allele ID\":allele_list, \n",
    "                                        'read count':read_count_list,\n",
    "                                        'total reads':total_reads_count_list,\n",
    "                                        '% total reads':pct_total_reads_list,\n",
    "                                        '% reads filtered for reads <1%':pct_reads_filtered_for_1pct_list,\n",
    "                                        '% reads filtered for reads <10%':pct_reads_filtered_for_10pct_list,\n",
    "                                        \"alignment query\\n(allele sequence)\":allele_sequence_list,\n",
    "                                        \"alignment midline\":alignment_midline_list, \"alignment hit\\n(reference)\":reference_sequence_list,\n",
    "                                        \"TF lost\":TF_lost_list,                  \n",
    "                                        \"TF lost strand\":TF_lost_strand_list,                            \n",
    "                                        \"Lost TFBS sequence (in reference at this position, lost in allele)\\n*Note: this TFBS sequence is in the reference, 5'-3' on strand indicated in 'strand'\":lost_TFBS_sequence_list,\n",
    "                                        \"Lost TFBS coordinate start (in reference)\":lost_TFBS_start_coordinate_list,\n",
    "                                        \"Lost TFBS coordinate end (in reference)\":lost_TFBS_end_coordinate_list,\n",
    "                                        \"Lost TFBS p-val (in reference)\":lost_TFBS_pval_list}\n",
    "    predicted_loss_of_TFBS_synopsis_df = pd.DataFrame(predicted_loss_of_TFBS_synopsis_df_columns)\n",
    "\n",
    "    # Add column with allele comment (comment if appropriate)\n",
    "    predicted_loss_of_TFBS_synopsis_df['comment'] = ['note: inferred allele length <=50 bp; read may be primer dimer; consult fasta file for this inferred allele, and/or consider pre-processing fastq file (filter reads) prior to running CollatedMotifs' if i <=50 else '' for i in [len(x) for x in predicted_loss_of_TFBS_synopsis_df['alignment query\\n(allele sequence)'].to_list()]]\n",
    "\n",
    "    predicted_loss_of_TFBS_synopsis_df.sort_values(by=['sample','allele rank','TF lost',\"TF lost strand\",\"Lost TFBS coordinate start (in reference)\"],ascending=[True, True, True, True, True])\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF of interest**--*predicted_loss_with_regain_of_new_TFBS_for_same_TF_synopsis_df*: dataframe that catalogs sample alleles identified as having lost TFBS for TF of interest, but the genetic variant nevertheless regained a distinct TFBS for the same TF of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare output to indicate **loss of TFBS for TF of interest with regain of different TFBS for same TF**\n",
    "if TF_of_interest == '':\n",
    "    pass\n",
    "else:\n",
    "    sample_list = []\n",
    "    allele_rank_list = []\n",
    "    allele_list = []\n",
    "    read_count_list = []\n",
    "    total_reads_count_list = []\n",
    "    pct_total_reads_list = []\n",
    "    pct_reads_filtered_for_1pct_list = []\n",
    "    pct_reads_filtered_for_10pct_list = []\n",
    "    allele_sequence_list = []\n",
    "    reference_sequence_list = []\n",
    "    alignment_midline_list = []\n",
    "    TF_lost_list = []\n",
    "    TF_lost_strand_list = []\n",
    "    lost_TFBS_sequence_list = []\n",
    "    lost_TFBS_start_coordinate_list = []\n",
    "    lost_TFBS_end_coordinate_list = []\n",
    "    lost_TFBS_pval_list = []\n",
    "    TF_gained_list = []\n",
    "    TF_gained_strand_list = []\n",
    "    gained_TFBS_sequence_list = []\n",
    "    gained_TFBS_start_coordinate_list = []\n",
    "    gained_TFBS_end_coordinate_list = []\n",
    "    gained_TFBS_pval_list = []\n",
    "\n",
    "    for allele in predicted_loss_with_regain_of_different_TFBS_for_same_TF_list:\n",
    "        sample_list.append(allele[0])\n",
    "        allele_rank_list.append(allele[1])\n",
    "        allele_list.append(allele[2])\n",
    "        read_count_list.append(allele[2].split('_')[2].strip('[]').split('/')[0])\n",
    "        total_reads_count_list.append(allele[2].split('_')[2].strip('[]').split('/')[1])\n",
    "        pct_total_reads_list.append(allele[5])\n",
    "        pct_reads_filtered_for_1pct_list.append(allele[6])\n",
    "        pct_reads_filtered_for_10pct_list.append(allele[7])\n",
    "        allele_sequence_list.append(allele[8])\n",
    "        reference_sequence_list.append(allele[10])\n",
    "        alignment_midline_list.append(allele[9])\n",
    "        TF_lost_list.append(allele[11])\n",
    "        TF_lost_strand_list.append(allele[12])\n",
    "        lost_TFBS_sequence_list.append(allele[13])\n",
    "        lost_TFBS_start_coordinate_list.append(allele[15])\n",
    "        lost_TFBS_end_coordinate_list.append(allele[16])\n",
    "        lost_TFBS_pval_list.append(allele[19])\n",
    "        TF_gained_list.append(allele[11])\n",
    "        TF_gained_strand_list.append(allele[12])\n",
    "        gained_TFBS_sequence_list.append(allele[14])\n",
    "        gained_TFBS_start_coordinate_list.append(allele[17])\n",
    "        gained_TFBS_end_coordinate_list.append(allele[18])\n",
    "        gained_TFBS_pval_list.append(allele[20])\n",
    "        \n",
    "# create dataframe for predicted_loss_with_regain_of_new_TFBS_for_same_TF_synopsis\n",
    "if TF_of_interest == '':\n",
    "    pass\n",
    "else:\n",
    "    predicted_loss_with_regain_of_new_TFBS_for_same_TF_synopsis_df_columns = {\"sample\":sample_list, \"allele rank\":allele_rank_list, \"allele ID\":allele_list, \n",
    "                                        'read count':read_count_list,\n",
    "                                        'total reads':total_reads_count_list,\n",
    "                                        '% total reads':pct_total_reads_list,\n",
    "                                        '% reads filtered for reads <1%':pct_reads_filtered_for_1pct_list,\n",
    "                                        '% reads filtered for reads <10%':pct_reads_filtered_for_10pct_list,\n",
    "                                        \"alignment query\\n(allele sequence)\":allele_sequence_list,\n",
    "                                        \"alignment midline\":alignment_midline_list, \"alignment hit\\n(reference)\":reference_sequence_list,\n",
    "                                        \"TF lost\":TF_lost_list,\n",
    "                                        \"TF gained\":TF_gained_list,                    \n",
    "                                        \"TF lost strand\":TF_lost_strand_list,\n",
    "                                        \"TF gained strand\":TF_gained_strand_list,                        \n",
    "                                        \"Lost TFBS sequence (in reference at this position, lost in allele)\\n*Note: this TFBS sequence is in the reference, 5'-3' on strand indicated in 'strand'\":lost_TFBS_sequence_list,\n",
    "                                        \"Gained TFBS sequence (not in reference at this position, novel to allele)\\n*Note: this TFBS sequence is in the allele, 5'-3' on strand indicated in 'strand'\":gained_TFBS_sequence_list, \n",
    "                                        \"Lost TFBS coordinate start (in reference)\":lost_TFBS_start_coordinate_list,\n",
    "                                        \"Lost TFBS coordinate end (in reference)\":lost_TFBS_end_coordinate_list,\n",
    "                                        \"Gained TFBS coordinate start (in allele)\":gained_TFBS_start_coordinate_list,\n",
    "                                        \"Gained TFBS coordinate end (in allele)\":gained_TFBS_end_coordinate_list,\n",
    "                                        \"Lost TFBS p-val (in reference)\":lost_TFBS_pval_list,\n",
    "                                        \"Gained TBFS p-val (in allele)\":gained_TFBS_pval_list}\n",
    "\n",
    "    predicted_loss_with_regain_of_new_TFBS_for_same_TF_synopsis_df = pd.DataFrame(predicted_loss_with_regain_of_new_TFBS_for_same_TF_synopsis_df_columns)\n",
    "\n",
    "    # Add column with allele comment (comment if appropriate)\n",
    "    predicted_loss_with_regain_of_new_TFBS_for_same_TF_synopsis_df['comment'] = ['note: inferred allele length <=50 bp; read may be primer dimer; consult fasta file for this inferred allele, and/or consider pre-processing fastq file (filter reads) prior to running CollatedMotifs' if i <=50 else '' for i in [len(x) for x in predicted_loss_with_regain_of_new_TFBS_for_same_TF_synopsis_df['alignment query\\n(allele sequence)'].to_list()]]\n",
    "\n",
    "    predicted_loss_with_regain_of_new_TFBS_for_same_TF_synopsis_df.sort_values(by=['sample','allele rank','TF lost',\"TF lost strand\",\"Lost TFBS coordinate start (in reference)\"],ascending=[True, True, True, True, True])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF of interest**--*predicted_loss_with_gain_of_different_TFBS_synopsis_df*: dataframe that catalogs sample alleles identified as having lost TFBS for TF of interest, but the genetic variant gained a distinct TFBS for an entirely different TF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare output to indicate **loss of TFBS for TF of interest with gain of TFBS for novel TF**\n",
    "if TF_of_interest == '':\n",
    "    pass\n",
    "else:\n",
    "    sample_list = []\n",
    "    allele_rank_list = []\n",
    "    allele_list = []\n",
    "    read_count_list = []\n",
    "    total_reads_count_list = []\n",
    "    pct_total_reads_list = []\n",
    "    pct_reads_filtered_for_1pct_list = []\n",
    "    pct_reads_filtered_for_10pct_list = []\n",
    "    allele_sequence_list = []\n",
    "    reference_sequence_list = []\n",
    "    alignment_midline_list = []\n",
    "    TF_lost_list = []\n",
    "    TF_lost_strand_list = []\n",
    "    lost_TFBS_sequence_list = []\n",
    "    lost_TFBS_start_coordinate_list = []\n",
    "    lost_TFBS_end_coordinate_list = []\n",
    "    lost_TFBS_pval_list = []\n",
    "    TF_gained_list = []\n",
    "    TF_gained_strand_list = []\n",
    "    gained_TFBS_sequence_list = []\n",
    "    gained_TFBS_start_coordinate_list = []\n",
    "    gained_TFBS_end_coordinate_list = []\n",
    "    gained_TFBS_pval_list = []\n",
    "\n",
    "    for pair in predicted_loss_with_gain_of_different_TFBS_list:\n",
    "        sample_list.append(pair[0])\n",
    "        allele_rank_list.append(pair[1])\n",
    "        allele_list.append(pair[2][2])\n",
    "        read_count_list.append(pair[2][2].split('_')[2].strip('[]').split('/')[0])\n",
    "        total_reads_count_list.append(pair[2][2].split('_')[2].strip('[]').split('/')[1])\n",
    "        pct_total_reads_list.append(pair[2][5])\n",
    "        pct_reads_filtered_for_1pct_list.append(pair[2][6])\n",
    "        pct_reads_filtered_for_10pct_list.append(pair[2][7])\n",
    "        allele_sequence_list.append(pair[2][8])\n",
    "        reference_sequence_list.append(pair[2][10])\n",
    "        alignment_midline_list.append(pair[2][9])\n",
    "        TF_lost_list.append(pair[2][11])\n",
    "        TF_lost_strand_list.append(pair[2][12])\n",
    "        lost_TFBS_sequence_list.append(pair[2][13])\n",
    "        lost_TFBS_start_coordinate_list.append(pair[2][15])\n",
    "        lost_TFBS_end_coordinate_list.append(pair[2][16])\n",
    "        lost_TFBS_pval_list.append(pair[2][19])\n",
    "        TF_gained_list.append(pair[3][11])\n",
    "        TF_gained_strand_list.append(pair[3][12])\n",
    "        gained_TFBS_sequence_list.append(pair[3][14])\n",
    "        gained_TFBS_start_coordinate_list.append(pair[3][17])\n",
    "        gained_TFBS_end_coordinate_list.append(pair[3][18])\n",
    "        gained_TFBS_pval_list.append(pair[3][20])\n",
    "        \n",
    "# create dataframe for predicted_loss_with_gain_of_different_TFBS_synopsis\n",
    "if TF_of_interest == '':\n",
    "    pass\n",
    "else:\n",
    "    predicted_loss_with_gain_of_different_TFBS_synopsis_df_columns = {\"sample\":sample_list, \"allele rank\":allele_rank_list, \"allele ID\":allele_list, \n",
    "                                        'read count':read_count_list,\n",
    "                                        'total reads':total_reads_count_list,\n",
    "                                        '% total reads':pct_total_reads_list,\n",
    "                                        '% reads filtered for reads <1%':pct_reads_filtered_for_1pct_list,\n",
    "                                        '% reads filtered for reads <10%':pct_reads_filtered_for_10pct_list,\n",
    "                                        \"alignment query\\n(allele sequence)\":allele_sequence_list,\n",
    "                                        \"alignment midline\":alignment_midline_list, \"alignment hit\\n(reference)\":reference_sequence_list,\n",
    "                                        \"TF lost\":TF_lost_list,\n",
    "                                        \"TF gained\":TF_gained_list,                    \n",
    "                                        \"TF lost strand\":TF_lost_strand_list,\n",
    "                                        \"TF gained strand\":TF_gained_strand_list,                        \n",
    "                                        \"Lost TFBS sequence (in reference at this position, lost in allele)\\n*Note: this TFBS sequence is in the reference, 5'-3' on strand indicated in 'strand'\":lost_TFBS_sequence_list,\n",
    "                                        \"Gained TFBS sequence (not in reference at this position, novel to allele)\\n*Note: this TFBS sequence is in the allele, 5'-3' on strand indicated in 'strand'\":gained_TFBS_sequence_list, \n",
    "                                        \"Lost TFBS coordinate start (in reference)\":lost_TFBS_start_coordinate_list,\n",
    "                                        \"Lost TFBS coordinate end (in reference)\":lost_TFBS_end_coordinate_list,\n",
    "                                        \"Gained TFBS coordinate start (in allele)\":gained_TFBS_start_coordinate_list,\n",
    "                                        \"Gained TFBS coordinate end (in allele)\":gained_TFBS_end_coordinate_list,\n",
    "                                        \"Lost TFBS p-val (in reference)\":lost_TFBS_pval_list,\n",
    "                                        \"Gained TBFS p-val (in allele)\":gained_TFBS_pval_list}\n",
    "\n",
    "    predicted_loss_with_gain_of_different_TFBS_synopsis_df = pd.DataFrame(predicted_loss_with_gain_of_different_TFBS_synopsis_df_columns)\n",
    "\n",
    "    # Add column with allele comment (comment if appropriate)\n",
    "    predicted_loss_with_gain_of_different_TFBS_synopsis_df['comment'] = ['note: inferred allele length <=50 bp; read may be primer dimer; consult fasta file for this inferred allele, and/or consider pre-processing fastq file (filter reads) prior to running CollatedMotifs' if i <=50 else '' for i in [len(x) for x in predicted_loss_with_gain_of_different_TFBS_synopsis_df['alignment query\\n(allele sequence)'].to_list()]]\n",
    "\n",
    "    predicted_loss_with_gain_of_different_TFBS_synopsis_df.sort_values(by=['sample','allele rank','TF lost',\"TF lost strand\",\"Lost TFBS coordinate start (in reference)\"],ascending=[True, True, True, True, True])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF of interest**--*predicted_exclusive_loss_of_TFBS_synopsis_df*: dataframe that catalogs sample alleles identified as having exclusively lost TFBS for TF of interest (in other words, the genetic variant led to loss of TFBS for TF of interest, and FIMO did not identify a coinciding 'regained' TFBS for the TF of interest or a 'gained' TFBS for a different TF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare output to indicate **loss of TFBS for TF of interest with no predicted gain of TFBS for novel TF** (at pval threshold)\n",
    "if TF_of_interest == '':\n",
    "    pass\n",
    "else:\n",
    "    sample_list = []\n",
    "    allele_rank_list = []\n",
    "    allele_list = []\n",
    "    read_count_list = []\n",
    "    total_reads_count_list = []\n",
    "    pct_total_reads_list = []\n",
    "    pct_reads_filtered_for_1pct_list = []\n",
    "    pct_reads_filtered_for_10pct_list = []\n",
    "    allele_sequence_list = []\n",
    "    reference_sequence_list = []\n",
    "    alignment_midline_list = []\n",
    "    TF_lost_list = []\n",
    "    TF_lost_strand_list = []\n",
    "    lost_TFBS_sequence_list = []\n",
    "    lost_TFBS_start_coordinate_list = []\n",
    "    lost_TFBS_end_coordinate_list = []\n",
    "    lost_TFBS_pval_list = []\n",
    "    TF_gained_list = []\n",
    "    TF_gained_strand_list = []\n",
    "    gained_TFBS_sequence_list = []\n",
    "    gained_TFBS_start_coordinate_list = []\n",
    "    gained_TFBS_end_coordinate_list = []\n",
    "    gained_TFBS_pval_list = []\n",
    "\n",
    "    for pair in predicted_exclusive_loss_of_target_TFBS_list:\n",
    "        sample_list.append(pair[0])\n",
    "        allele_rank_list.append(pair[1])\n",
    "        allele_list.append(pair[2][2])\n",
    "        read_count_list.append(pair[2][2].split('_')[2].strip('[]').split('/')[0])\n",
    "        total_reads_count_list.append(pair[2][2].split('_')[2].strip('[]').split('/')[1])\n",
    "        pct_total_reads_list.append(pair[2][5])\n",
    "        pct_reads_filtered_for_1pct_list.append(pair[2][6])\n",
    "        pct_reads_filtered_for_10pct_list.append(pair[2][7])\n",
    "        allele_sequence_list.append(pair[2][8])\n",
    "        reference_sequence_list.append(pair[2][10])\n",
    "        alignment_midline_list.append(pair[2][9])\n",
    "        TF_lost_list.append(pair[2][11])\n",
    "        TF_lost_strand_list.append(pair[2][12])\n",
    "        lost_TFBS_sequence_list.append(pair[2][13])\n",
    "        lost_TFBS_start_coordinate_list.append(pair[2][15])\n",
    "        lost_TFBS_end_coordinate_list.append(pair[2][16])\n",
    "        lost_TFBS_pval_list.append(pair[2][19])\n",
    "        \n",
    "# create dataframe for predicted_exclusive_loss_of_TFBS_synopsis\n",
    "if TF_of_interest == '':\n",
    "    pass\n",
    "else:\n",
    "    predicted_exclusive_loss_of_TFBS_synopsis_df_columns = {\"sample\":sample_list, \"allele rank\":allele_rank_list, \"allele ID\":allele_list, \n",
    "                                        'read count':read_count_list,\n",
    "                                        'total reads':total_reads_count_list,\n",
    "                                        '% total reads':pct_total_reads_list,\n",
    "                                        '% reads filtered for reads <1%':pct_reads_filtered_for_1pct_list,\n",
    "                                        '% reads filtered for reads <10%':pct_reads_filtered_for_10pct_list,\n",
    "                                        \"alignment query\\n(allele sequence)\":allele_sequence_list,\n",
    "                                        \"alignment midline\":alignment_midline_list, \"alignment hit\\n(reference)\":reference_sequence_list,\n",
    "                                        \"TF lost\":TF_lost_list,                  \n",
    "                                        \"TF lost strand\":TF_lost_strand_list,                            \n",
    "                                        \"Lost TFBS sequence (in reference at this position, lost in allele)\\n*Note: this TFBS sequence is in the reference, 5'-3' on strand indicated in 'strand'\":lost_TFBS_sequence_list,\n",
    "                                        \"Lost TFBS coordinate start (in reference)\":lost_TFBS_start_coordinate_list,\n",
    "                                        \"Lost TFBS coordinate end (in reference)\":lost_TFBS_end_coordinate_list,\n",
    "                                        \"Lost TFBS p-val (in reference)\":lost_TFBS_pval_list}\n",
    "    predicted_exclusive_loss_of_TFBS_synopsis_df = pd.DataFrame(predicted_exclusive_loss_of_TFBS_synopsis_df_columns)\n",
    "\n",
    "    # Add column with allele comment (comment if appropriate)\n",
    "    predicted_exclusive_loss_of_TFBS_synopsis_df['comment'] = ['note: inferred allele length <=50 bp; read may be primer dimer; consult fasta file for this inferred allele, and/or consider pre-processing fastq file (filter reads) prior to running CollatedMotifs' if i <=50 else '' for i in [len(x) for x in predicted_exclusive_loss_of_TFBS_synopsis_df['alignment query\\n(allele sequence)'].to_list()]]\n",
    "\n",
    "    predicted_exclusive_loss_of_TFBS_synopsis_df.sort_values(by=['sample','allele rank','TF lost',\"TF lost strand\",\"Lost TFBS coordinate start (in reference)\"],ascending=[True, True, True, True, True])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF of interest**--*samples_predicted_to_have_lost_TFBS_synopsis_df*: dataframe that catalogs all ranked alleles for samples with at least one ranked allele identified as having lost TFBS for TF of interest; this dataframe becomes the basis for sample curation to facilitate identification of samples of potential experimental interest (for having lost TFBS for TF of interest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# July 2021\n",
    "# Take stock of samples with alleles having lost TFBS for TF of interest without regain/gain of TFBS for distinct TF\n",
    "# Re-populate remaining ranked alleles for these samples, to facilitate genotype inference\n",
    "if TF_of_interest == '':\n",
    "    pass\n",
    "else:\n",
    "    sample_list = []\n",
    "    allele_rank_list = []\n",
    "    allele_list = []\n",
    "    read_count_list = []\n",
    "    total_reads_list = []\n",
    "    total_reads_pct_list = []\n",
    "    total_reads_1pct_list = []\n",
    "    total_reads_10pct_list = []\n",
    "    allele_sequence_list = []\n",
    "    alignment_midline_list = []\n",
    "    reference_sequence_list = []\n",
    "    TF_list = []\n",
    "    TF_exlusively_lost_list = []\n",
    "    TF_lost_with_regain_of_TFBS_for_same_TF_list = []\n",
    "    TF_lost_with_gain_of_distinct_TF_list = []\n",
    "    reference_TFBS_unchanged_list = []\n",
    "    strand_list = []\n",
    "    TFBS_sequence_list = []\n",
    "    allele_start_coordinate_list = []\n",
    "    allele_stop_coordinate_list = []\n",
    "    p_val_list = []\n",
    "    comment_list = []\n",
    "\n",
    "    for sample in set(predicted_loss_of_TFBS_synopsis_df['sample'].to_list()).union(\n",
    "        set(predicted_loss_with_regain_of_new_TFBS_for_same_TF_synopsis_df['sample'].to_list())).union(\n",
    "        set(predicted_loss_with_gain_of_different_TFBS_synopsis_df['sample'].to_list())):\n",
    "        allele_lost_TFBS_list = []\n",
    "        allele_rank_lost_TFBS_list = []\n",
    "        allele_rank_other_list = []\n",
    "        \n",
    "        for index, row in predicted_exclusive_loss_of_TFBS_synopsis_df.iterrows():\n",
    "            if row['sample'] == sample:\n",
    "                sample_list.append(row['sample'])\n",
    "                allele_rank_list.append(row['allele rank'])\n",
    "                allele_rank_lost_TFBS_list.append(row['allele rank'])\n",
    "                allele_list.append(row['allele ID'])\n",
    "                read_count_list.append(row['read count'])\n",
    "                total_reads_list.append(row['total reads'])\n",
    "                total_reads_pct_list.append(row['% total reads'])\n",
    "                total_reads_1pct_list.append(row['% reads filtered for reads <1%']) \n",
    "                total_reads_10pct_list.append(row['% reads filtered for reads <10%'])\n",
    "                allele_sequence_list.append(row['alignment query\\n(allele sequence)'])\n",
    "                alignment_midline_list.append(row['alignment midline'])\n",
    "                reference_sequence_list.append(row['alignment hit\\n(reference)'])\n",
    "                TF_list.append(row['TF lost'])\n",
    "                TF_exlusively_lost_list.append('x')\n",
    "                TF_lost_with_regain_of_TFBS_for_same_TF_list.append('')\n",
    "                TF_lost_with_gain_of_distinct_TF_list.append('')\n",
    "                reference_TFBS_unchanged_list.append('')\n",
    "                strand_list.append(row['TF lost strand']) \n",
    "                TFBS_sequence_list.append(row[\"Lost TFBS sequence (in reference at this position, lost in allele)\\n*Note: this TFBS sequence is in the reference, 5'-3' on strand indicated in 'strand'\"])\n",
    "                allele_start_coordinate_list.append(row['Lost TFBS coordinate start (in reference)'])\n",
    "                allele_stop_coordinate_list.append(row['Lost TFBS coordinate end (in reference)'])\n",
    "                p_val_list.append(row['Lost TFBS p-val (in reference)'])\n",
    "                comment_list.append(row['comment']) \n",
    "                allele_rank_lost_TFBS_list.append(row['allele rank'])\n",
    "                allele_lost_TFBS_list.append(row['allele ID'])\n",
    "                \n",
    "        for index, row in predicted_loss_with_regain_of_new_TFBS_for_same_TF_synopsis_df.iterrows():\n",
    "             if row['sample'] == sample:\n",
    "                allele_rank_other_list.append(row['allele rank'])\n",
    "                allele_list.append(row['allele ID'])\n",
    "                allele_rank_list.append(row['allele rank'])\n",
    "                sample_list.append(row['sample'])\n",
    "                read_count_list.append(row['read count'])\n",
    "                total_reads_list.append(row['total reads'])\n",
    "                total_reads_pct_list.append(row['% total reads'])\n",
    "                total_reads_1pct_list.append(row['% reads filtered for reads <1%']) \n",
    "                total_reads_10pct_list.append(row['% reads filtered for reads <10%'])\n",
    "                allele_sequence_list.append(row['alignment query\\n(allele sequence)'])\n",
    "                alignment_midline_list.append(row['alignment midline'])\n",
    "                reference_sequence_list.append(row['alignment hit\\n(reference)'])\n",
    "                TF_list.append(row['TF lost'])\n",
    "                TF_exlusively_lost_list.append('')\n",
    "                TF_lost_with_regain_of_TFBS_for_same_TF_list.append('x')\n",
    "                TF_lost_with_gain_of_distinct_TF_list.append('')\n",
    "                reference_TFBS_unchanged_list.append('')\n",
    "                strand_list.append(row['TF lost strand']) \n",
    "                TFBS_sequence_list.append(row[\"Lost TFBS sequence (in reference at this position, lost in allele)\\n*Note: this TFBS sequence is in the reference, 5'-3' on strand indicated in 'strand'\"])\n",
    "                allele_start_coordinate_list.append(row['Lost TFBS coordinate start (in reference)'])\n",
    "                allele_stop_coordinate_list.append(row['Lost TFBS coordinate end (in reference)'])\n",
    "                p_val_list.append(row['Lost TFBS p-val (in reference)'])\n",
    "                comment_list.append(row['comment'])            \n",
    "                \n",
    "        for index, row in predicted_loss_with_gain_of_different_TFBS_synopsis_df.iterrows():\n",
    "            if row['sample'] == sample:\n",
    "                allele_rank_other_list.append(row['allele rank'])\n",
    "                allele_list.append(row['allele ID'])\n",
    "                allele_rank_list.append(row['allele rank'])\n",
    "                sample_list.append(row['sample'])\n",
    "                read_count_list.append(row['read count'])\n",
    "                total_reads_list.append(row['total reads'])\n",
    "                total_reads_pct_list.append(row['% total reads'])\n",
    "                total_reads_1pct_list.append(row['% reads filtered for reads <1%']) \n",
    "                total_reads_10pct_list.append(row['% reads filtered for reads <10%'])\n",
    "                allele_sequence_list.append(row['alignment query\\n(allele sequence)'])\n",
    "                alignment_midline_list.append(row['alignment midline'])\n",
    "                reference_sequence_list.append(row['alignment hit\\n(reference)'])\n",
    "                TF_list.append(row['TF lost'])\n",
    "                TF_exlusively_lost_list.append('')\n",
    "                TF_lost_with_regain_of_TFBS_for_same_TF_list.append('')\n",
    "                TF_lost_with_gain_of_distinct_TF_list.append('x')\n",
    "                reference_TFBS_unchanged_list.append('')\n",
    "                strand_list.append(row['TF lost strand']) \n",
    "                TFBS_sequence_list.append(row[\"Lost TFBS sequence (in reference at this position, lost in allele)\\n*Note: this TFBS sequence is in the reference, 5'-3' on strand indicated in 'strand'\"])\n",
    "                allele_start_coordinate_list.append(row['Lost TFBS coordinate start (in reference)'])\n",
    "                allele_stop_coordinate_list.append(row['Lost TFBS coordinate end (in reference)'])\n",
    "                p_val_list.append(row['Lost TFBS p-val (in reference)'])\n",
    "                comment_list.append(row['comment'])  \n",
    "                        \n",
    "        for index, row in allele_TFBS_synopsis_df.iterrows():\n",
    "            if row['sample'] == sample:\n",
    "                if row['allele rank'] not in allele_rank_lost_TFBS_list:\n",
    "                    if row['allele rank'] not in allele_rank_other_list:\n",
    "                        allele_rank_other_list.append(row['allele rank'])\n",
    "                        allele_list.append(row['allele ID'])\n",
    "                        allele_rank_list.append(row['allele rank'])\n",
    "                        sample_list.append(row['sample'])\n",
    "                        read_count_list.append(row['reads'])\n",
    "                        total_reads_list.append(row['total reads'])\n",
    "                        total_reads_pct_list.append(row['% total reads'])\n",
    "                        total_reads_1pct_list.append(row['% reads filtered for reads <1%']) \n",
    "                        total_reads_10pct_list.append(row['% reads filtered for reads <10%'])\n",
    "                        allele_sequence_list.append(row['alignment query\\n(allele sequence)'])\n",
    "                        alignment_midline_list.append(row['alignment midline'])\n",
    "                        reference_sequence_list.append(row['alignment hit\\n(reference)'])\n",
    "                        TF_list.append('n/a')\n",
    "                        TF_exlusively_lost_list.append('')\n",
    "                        TF_lost_with_regain_of_TFBS_for_same_TF_list.append('')\n",
    "                        TF_lost_with_gain_of_distinct_TF_list.append('')\n",
    "                        reference_TFBS_unchanged_list.append('x')\n",
    "                        strand_list.append('n/a') \n",
    "                        TFBS_sequence_list.append('n/a')\n",
    "                        allele_start_coordinate_list.append('n/a')\n",
    "                        allele_stop_coordinate_list.append('n/a')\n",
    "                        p_val_list.append('n/a')\n",
    "                        comment_list.append(row['comment'])\n",
    "    \n",
    "    samples_predicted_to_have_lost_TFBS_synopsis_df_columns = {\"sample\":sample_list, \"allele rank\":allele_rank_list, \"allele ID\":allele_list,\n",
    "                                \"read count\": read_count_list, \"total reads\": total_reads_list,\n",
    "                                \"% total reads\": total_reads_pct_list, \"% reads filtered for reads <1%\": total_reads_1pct_list,\n",
    "                                \"% reads filtered for reads <10%\": total_reads_10pct_list, \"alignment query\\n(allele sequence)\":allele_sequence_list,\n",
    "                                \"alignment midline\":alignment_midline_list, \"alignment hit\\n(reference)\":reference_sequence_list,\n",
    "                                \"TF lost (lost TFBS; no predicted regain of related for same TF, or gain of novel TFBS for distinct TF)\":TF_list,\n",
    "                                \"TFBS for TF exclusively lost\": TF_exlusively_lost_list,\n",
    "                                \"TFBS for TF lost with regain of different TFBS for same TF\": TF_lost_with_regain_of_TFBS_for_same_TF_list,\n",
    "                                \"TFBS for TF lost with gain of TFBS for different TF\": TF_lost_with_gain_of_distinct_TF_list,\n",
    "                                \"TFBS for TF unchanged relative to reference\": reference_TFBS_unchanged_list,\n",
    "                                \"TF lost strand\":strand_list, \n",
    "                                \"Lost TFBS sequence (in reference at this position, lost in allele)\\n*Note: this TFBS sequence is in the reference, 5'-3' on strand indicated in 'strand'\":TFBS_sequence_list,\n",
    "                                \"Lost TFBS coordinate start (in reference)\":allele_start_coordinate_list,\n",
    "                                \"Lost TFBS coordinate end (in reference)\":allele_stop_coordinate_list,\n",
    "                                \"Lost TFBS p-val (in reference)\":p_val_list, \"comment\":comment_list}\n",
    "\n",
    "    samples_predicted_to_have_lost_TFBS_synopsis_df = pd.DataFrame(samples_predicted_to_have_lost_TFBS_synopsis_df_columns)\n",
    "    \n",
    "    samples_predicted_to_have_lost_TFBS_synopsis_df.sort_values(by=['sample','allele rank','TF lost (lost TFBS; no predicted regain of related for same TF, or gain of novel TFBS for distinct TF)',\"TF lost strand\",\"Lost TFBS coordinate start (in reference)\"],ascending=[True, True, True, True, True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TF_of_interest == '':\n",
    "    pass\n",
    "else:\n",
    "    samples_predicted_to_have_lost_TFBS_synopsis_df.drop_duplicates(inplace=True)\n",
    "    samples_predicted_to_have_lost_TFBS_synopsis_df = samples_predicted_to_have_lost_TFBS_synopsis_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF of interest**--*samples_predicted_to_have_lost_TFBS_synopsis_df*: genotype inferences (assuming diploidy for simplicity), used as a basis for flagging samples as having lost TFBS for TF of interest in high-ranking (major) alleles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TF_of_interest == '':\n",
    "    pass\n",
    "else:\n",
    "    genotype_interpretation_dict = {}\n",
    "    for sample in set(samples_predicted_to_have_lost_TFBS_synopsis_df['sample'].to_list()):\n",
    "        allele_ranks_read_pct_list = []\n",
    "        for index, row in samples_predicted_to_have_lost_TFBS_synopsis_df.sort_values(by=['sample','allele rank']).iterrows():\n",
    "            if row['sample'] == sample:\n",
    "                allele_ranks_read_pct_list.append((row['allele rank'], row['% reads filtered for reads <10%'], row['TFBS for TF exclusively lost'], row['TFBS for TF lost with regain of different TFBS for same TF'],\n",
    "                                               row['TFBS for TF lost with gain of TFBS for different TF'], row['TFBS for TF unchanged relative to reference']))\n",
    "        for index, i in enumerate(sorted(set(allele_ranks_read_pct_list))):\n",
    "            if sample not in genotype_interpretation_dict:\n",
    "                if int(i[0]) == 1 and int(i[1]) > 90 and i[2] == 'x':\n",
    "                    genotype_interpretation_dict[sample] = 'predicted homozygous loss in high-ranking allele (no regain or gain)'\n",
    "                elif int(i[0]) == 1 and int(i[1]) > 90 and i[3] == 'x':\n",
    "                    genotype_interpretation_dict[sample] = 'predicted homozygous loss in high-ranking allele, with loss having regained a TFBS for TF'\n",
    "                elif int(i[0]) == 1 and int(i[1]) > 90 and i[4] == 'x':\n",
    "                    genotype_interpretation_dict[sample] = 'predicted homozygous loss in high-ranking allele, with loss having gained a novel TFBS for a distinct TF'\n",
    "                elif int(i[0]) == 1 and int(i[1]) > 90 and i[5] == 'x':\n",
    "                    genotype_interpretation_dict[sample] = 'predicted loss in inconsequential (low-ranking) allele rank(s)'\n",
    " \n",
    "                elif int(i[0]) == 1 and 35 < int(i[1]) < 90:\n",
    "                    if i[2] == 'x':\n",
    "                        if int(sorted(set(allele_ranks_read_pct_list))[index+1][0]) == 2 and 30 < int(sorted(set(allele_ranks_read_pct_list))[index+1][1]) < 90 and sorted(set(allele_ranks_read_pct_list))[index+1][2] == 'x':\n",
    "                            genotype_interpretation_dict[sample] = 'predicted biallelic loss among high-ranking alleles (no regain or gain)'\n",
    "                        elif int(sorted(set(allele_ranks_read_pct_list))[index+1][0]) == 2 and 30 < int(sorted(set(allele_ranks_read_pct_list))[index+1][1]) < 90 and sorted(set(allele_ranks_read_pct_list))[index+1][3] == 'x':\n",
    "                            genotype_interpretation_dict[sample] = 'predicted biallelic loss among high-ranking alleles, but 1 of the 2 losses has regained a TFBS for TF'\n",
    "                        elif int(sorted(set(allele_ranks_read_pct_list))[index+1][0]) == 2 and 30 < int(sorted(set(allele_ranks_read_pct_list))[index+1][1]) < 90 and sorted(set(allele_ranks_read_pct_list))[index+1][4] == 'x':\n",
    "                            genotype_interpretation_dict[sample] = 'predicted biallelic loss among high-ranking alleles, but 1 of the 2 losses has gained a novel TFBS for a distinct TF'\n",
    "                        elif int(sorted(set(allele_ranks_read_pct_list))[index+1][0]) == 2 and 30 < int(sorted(set(allele_ranks_read_pct_list))[index+1][1]) < 90 and sorted(set(allele_ranks_read_pct_list))[index+1][5] == 'x':\n",
    "                            genotype_interpretation_dict[sample] = 'predicted heterozygous loss among high-ranking alleles'\n",
    "                        else:\n",
    "                            genotype_interpretation_dict[sample] = 'predicted loss among high-ranking allele'\n",
    "                    elif i[3] == 'x':\n",
    "                        if int(sorted(set(allele_ranks_read_pct_list))[index+1][0]) == 2 and 30 < int(sorted(set(allele_ranks_read_pct_list))[index+1][1]) < 90 and sorted(set(allele_ranks_read_pct_list))[index+1][2] == 'x':\n",
    "                            genotype_interpretation_dict[sample] = 'predicted biallelic loss among high-ranking alleles, but 1 of the 2 losses has regained a TFBS for TF'\n",
    "                        elif int(sorted(set(allele_ranks_read_pct_list))[index+1][0]) == 2 and 30 < int(sorted(set(allele_ranks_read_pct_list))[index+1][1]) < 90 and sorted(set(allele_ranks_read_pct_list))[index+1][3] == 'x':\n",
    "                            genotype_interpretation_dict[sample] = 'predicted biallelic loss among high-ranking alleles, but both of the 2 losses have regained a TFBS for TF'\n",
    "                        elif int(sorted(set(allele_ranks_read_pct_list))[index+1][0]) == 2 and 30 < int(sorted(set(allele_ranks_read_pct_list))[index+1][1]) < 90 and sorted(set(allele_ranks_read_pct_list))[index+1][4] == 'x':\n",
    "                            genotype_interpretation_dict[sample] = 'predicted biallelic loss among high-ranking alleles, but 1 of the 2 losses has gained a novel TFBS for a distinct TF'\n",
    "                        elif int(sorted(set(allele_ranks_read_pct_list))[index+1][0]) == 2 and 30 < int(sorted(set(allele_ranks_read_pct_list))[index+1][1]) < 90 and sorted(set(allele_ranks_read_pct_list))[index+1][5] == 'x':\n",
    "                            genotype_interpretation_dict[sample] = 'predicted heterozygous loss among high-ranking alleles, with single loss having regained a TFBS for TF'\n",
    "                        else:\n",
    "                            genotype_interpretation_dict[sample] = 'predicted loss among high-ranking allele, with loss having regained a TFBS for TF'\n",
    "                    elif i[4] == 'x':\n",
    "                        if int(sorted(set(allele_ranks_read_pct_list))[index+1][0]) == 2 and 30 < int(sorted(set(allele_ranks_read_pct_list))[index+1][1]) < 90 and sorted(set(allele_ranks_read_pct_list))[index+1][2] == 'x':\n",
    "                            genotype_interpretation_dict[sample] = 'predicted biallelic loss among high-ranking alleles, but 1 of the 2 losses has gained a novel TFBS for a distinct TF'\n",
    "                        elif int(sorted(set(allele_ranks_read_pct_list))[index+1][0]) == 2 and 30 < int(sorted(set(allele_ranks_read_pct_list))[index+1][1]) < 90 and sorted(set(allele_ranks_read_pct_list))[index+1][3] == 'x':\n",
    "                            genotype_interpretation_dict[sample] = 'predicted biallelic loss among high-ranking alleles, but 1 of the 2 losses has regained a TFBS for TF and 1 has gained a novel TFBS for a distinct TF'\n",
    "                        elif int(sorted(set(allele_ranks_read_pct_list))[index+1][0]) == 2 and 30 < int(sorted(set(allele_ranks_read_pct_list))[index+1][1]) < 90 and sorted(set(allele_ranks_read_pct_list))[index+1][4] == 'x':\n",
    "                            genotype_interpretation_dict[sample] = 'predicted biallelic loss among high-ranking alleles, but both of the 2 losses have gained a novel TFBS for a distinct TF'\n",
    "                        elif int(sorted(set(allele_ranks_read_pct_list))[index+1][0]) == 2 and 30 < int(sorted(set(allele_ranks_read_pct_list))[index+1][1]) < 90 and sorted(set(allele_ranks_read_pct_list))[index+1][5] == 'x':\n",
    "                            genotype_interpretation_dict[sample] = 'predicted heterozygous loss among high-ranking alleles, with single loss having gained a novel TFBS for a distinct TF'\n",
    "                        else:\n",
    "                            genotype_interpretation_dict[sample] = 'predicted loss among high-ranking allele, with loss having gained a novel TFBS for a distinct TF'\n",
    "                    elif i[5] == 'x':\n",
    "                        if int(sorted(set(allele_ranks_read_pct_list))[index+1][0]) == 2 and 30 < int(sorted(set(allele_ranks_read_pct_list))[index+1][1]) < 90 and sorted(set(allele_ranks_read_pct_list))[index+1][2] == 'x':\n",
    "                            genotype_interpretation_dict[sample] = 'predicted heterozygous loss among high-ranking alleles'\n",
    "                        elif int(sorted(set(allele_ranks_read_pct_list))[index+1][0]) == 2 and 30 < int(sorted(set(allele_ranks_read_pct_list))[index+1][1]) < 90 and sorted(set(allele_ranks_read_pct_list))[index+1][3] == 'x':\n",
    "                            genotype_interpretation_dict[sample] = 'predicted heterozygous loss among high-ranking alleles, with single loss having regained a TFBS for TF'\n",
    "                        elif int(sorted(set(allele_ranks_read_pct_list))[index+1][0]) == 2 and 30 < int(sorted(set(allele_ranks_read_pct_list))[index+1][1]) < 90 and sorted(set(allele_ranks_read_pct_list))[index+1][4] == 'x':\n",
    "                            genotype_interpretation_dict[sample] = 'predicted heterozygous loss among high-ranking alleles, with single loss having gained a novel TFBS for a distinct TF'\n",
    "                        elif int(sorted(set(allele_ranks_read_pct_list))[index+1][0]) == 2 and 30 < int(sorted(set(allele_ranks_read_pct_list))[index+1][1]) < 90 and sorted(set(allele_ranks_read_pct_list))[index+1][5] == 'x':\n",
    "                             genotype_interpretation_dict[sample] = 'predicted loss in inconsequential (low-ranking) allele rank(s)'\n",
    "                        else:\n",
    "                             genotype_interpretation_dict[sample] = 'predicted loss in inconsequential (low-ranking) allele rank(s)'  \n",
    "                else:\n",
    "                    genotype_interpretation_dict[sample] = 'shrug?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TF_of_interest == '':\n",
    "    pass\n",
    "else:\n",
    "    genotype_inference_list = []\n",
    "    for index, row in samples_predicted_to_have_lost_TFBS_synopsis_df.iterrows():\n",
    "        genotype_inference_list.append(genotype_interpretation_dict.get(row['sample']))\n",
    "    \n",
    "    samples_predicted_to_have_lost_TFBS_synopsis_df['genotype inference'] = genotype_inference_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "cat_genotype_order = CategoricalDtype(\n",
    "    ['predicted loss among high-ranking allele',\n",
    "\n",
    "'predicted biallelic loss among high-ranking alleles (no regain or gain)',\n",
    "\n",
    " 'predicted loss among high-ranking allele, with loss having regained a TFBS for TF',\n",
    "\n",
    " 'predicted loss among high-ranking allele, with loss having gained a novel TFBS for a distinct TF',\n",
    "\n",
    " 'predicted biallelic loss among high-ranking alleles, but 1 of the 2 losses has regained a TFBS for TF',\n",
    "\n",
    " 'predicted biallelic loss among high-ranking alleles, but 1 of the 2 losses has gained a novel TFBS for a distinct TF',\n",
    "     \n",
    " 'predicted homozygous loss in high-ranking allele, with loss having regained a TFBS for TF',\n",
    "     \n",
    " 'predicted homozygous loss in high-ranking allele, with loss having gained a novel TFBS for a distinct TF',\n",
    "     \n",
    " 'predicted biallelic loss among high-ranking alleles, but both of the 2 losses have regained a TFBS for TF',\n",
    "\n",
    " 'predicted biallelic loss among high-ranking alleles, but 1 of the 2 losses has regained a TFBS for TF and 1 has gained a novel TFBS for a distinct TF',\n",
    "\n",
    " 'predicted biallelic loss among high-ranking alleles, but both of the 2 losses have gained a novel TFBS for a distinct TF',\n",
    "\n",
    " 'predicted heterozygous loss among high-ranking alleles',\n",
    "\n",
    " 'predicted heterozygous loss among high-ranking alleles, with single loss having regained a TFBS for TF',\n",
    "\n",
    " 'predicted heterozygous loss among high-ranking alleles, with single loss having gained a novel TFBS for a distinct TF',\n",
    "\n",
    " 'predicted loss in inconsequential (low-ranking) allele rank(s)'], \n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "if TF_of_interest == '':\n",
    "    pass\n",
    "else:\n",
    "    samples_predicted_to_have_lost_TFBS_synopsis_df['genotype inference'] = samples_predicted_to_have_lost_TFBS_synopsis_df['genotype inference'].astype(cat_genotype_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*all_TFBS_synopsis_df*: dataframe that catalogs all TFBSs detected for sample alleles (i.e., all FIMO outputs, not filtered for 'lost' or 'gained' status relative to reference sequence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, prepare output that summarizes all TFBS detected for given samples\n",
    "sample_list = []\n",
    "allele_rank_list = []\n",
    "allele_list = []\n",
    "allele_sequence_list = []\n",
    "reference_sequence_list = []\n",
    "alignment_midline_list = []\n",
    "TF_list = []\n",
    "strand_list = []\n",
    "TFBS_sequence_list = []\n",
    "p_val_list = []\n",
    "lostvsgained_list = []\n",
    "allele_start_coordinate_list = []\n",
    "allele_stop_coordinate_list = []\n",
    "ref_start_coordinate_list = []\n",
    "ref_stop_coordinate_list = []\n",
    "\n",
    "for sample in dict_allele_TFBS_synopsis:\n",
    "    allele_count = 0\n",
    "    for allele in dict_allele_TFBS_synopsis.get(sample):\n",
    "        allele_count = allele_count+1\n",
    "        for TFBS in dict_allele_TFBS_synopsis.get(sample).get(allele).get('all_sites'):\n",
    "            if len(dict_allele_TFBS_synopsis.get(sample).get(allele).get('all_sites')) == 0:\n",
    "                sample_list.append(sample)\n",
    "                allele_rank_list.append(allele_count)\n",
    "                allele_list.append(allele)\n",
    "                allele_sequence_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[0].split('>')[1].split('<')[0].strip())\n",
    "                reference_sequence_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[1].split('>')[1].split('<')[0].strip())\n",
    "                alignment_midline_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[2].split('>')[1].split('<')[0].strip())   \n",
    "                TF_list.append(TFBS.split(',')[0])\n",
    "                strand_list.append(TFBS.split(',')[1])                           \n",
    "                p_val_list.append(TFBS.split(',')[3])\n",
    "                allele_start_coordinate_list.append(TFBS.split(',')[4])\n",
    "                allele_stop_coordinate_list.append(TFBS.split(',')[5])\n",
    "                TFBS_sequence_list.append(TFBS.split(',')[2])\n",
    "            else:\n",
    "                sample_list.append(sample)\n",
    "                allele_rank_list.append(allele_count)\n",
    "                allele_list.append(allele)\n",
    "                allele_sequence_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[0].split('>')[1].split('<')[0].strip())\n",
    "                reference_sequence_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[1].split('>')[1].split('<')[0].strip())\n",
    "                alignment_midline_list.append(dict_allele_TFBS_synopsis.get(sample).get(allele).get('allele_sequence')[2].split('>')[1].split('<')[0].strip())   \n",
    "                TF_list.append(TFBS.split(',')[0])\n",
    "                strand_list.append(TFBS.split(',')[1])                           \n",
    "                p_val_list.append(TFBS.split(',')[3])\n",
    "                allele_start_coordinate_list.append(TFBS.split(',')[4])\n",
    "                allele_stop_coordinate_list.append(TFBS.split(',')[5])\n",
    "                TFBS_sequence_list.append(TFBS.split(',')[2])\n",
    "                \n",
    "all_TFBS_synopsis_df_columns = {\"sample\":sample_list, \"allele rank\":allele_rank_list, \"allele ID\":allele_list, \n",
    "                                \"alignment query\\n(allele sequence)\":allele_sequence_list,\n",
    "                                \"alignment midline\":alignment_midline_list, \"alignment hit\\n(reference)\":reference_sequence_list,\n",
    "                                \"TF\":TF_list,\n",
    "                                \"strand\":strand_list, \n",
    "                                \"TFBS sequence\":TFBS_sequence_list,\n",
    "                                \"TFBS coordinate start (in allele)\":allele_start_coordinate_list,\n",
    "                                \"TFBS coordinate end (in allele)\":allele_stop_coordinate_list,\n",
    "                                \"TFBS p-val\":p_val_list}\n",
    "\n",
    "all_TFBS_synopsis_df = pd.DataFrame(all_TFBS_synopsis_df_columns)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>allele rank</th>\n",
       "      <th>allele ID</th>\n",
       "      <th>reads</th>\n",
       "      <th>total reads</th>\n",
       "      <th>% total reads</th>\n",
       "      <th>% reads filtered for reads &lt;1%</th>\n",
       "      <th>% reads filtered for reads &lt;10%</th>\n",
       "      <th>alignment query\n",
       "(allele sequence)</th>\n",
       "      <th>alignment midline</th>\n",
       "      <th>alignment hit\n",
       "(reference)</th>\n",
       "      <th>TF</th>\n",
       "      <th>strand</th>\n",
       "      <th>TFBS sequence</th>\n",
       "      <th>TFBS coordinate start (in allele)</th>\n",
       "      <th>TFBS coordinate end (in allele)</th>\n",
       "      <th>TFBS p-val</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>E2F7 (MA0758.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>TTTTCCCCCCAAAC</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>3.04e-06</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>E2F8 (MA0865.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>TTTCCCCCCAAA</td>\n",
       "      <td>54</td>\n",
       "      <td>65</td>\n",
       "      <td>9.78e-08</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>E2F8 (MA0865.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>TTTTCCCCCCAA</td>\n",
       "      <td>55</td>\n",
       "      <td>66</td>\n",
       "      <td>3.6e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>EWSR1-FLI1 (MA0149.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>GGGGGGAAAAAAGGAAAG</td>\n",
       "      <td>57</td>\n",
       "      <td>74</td>\n",
       "      <td>9.59e-06</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>EWSR1-FLI1 (MA0149.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>GGAAAAAAGGAAAGAGAG</td>\n",
       "      <td>61</td>\n",
       "      <td>78</td>\n",
       "      <td>2.17e-06</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>IRF1 (MA0050.2)</td>\n",
       "      <td>-</td>\n",
       "      <td>ACTCTCTTTCCTTTTTTCCCC</td>\n",
       "      <td>59</td>\n",
       "      <td>79</td>\n",
       "      <td>6.96e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>IRF1 (MA0050.2)</td>\n",
       "      <td>-</td>\n",
       "      <td>CTGTGCACTCTCTTTCCTTTT</td>\n",
       "      <td>65</td>\n",
       "      <td>85</td>\n",
       "      <td>8.27e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>PRDM1 (MA0508.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>AAAAAAGGAAAGAGA</td>\n",
       "      <td>63</td>\n",
       "      <td>77</td>\n",
       "      <td>5.2e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>STAT1::STAT2 (MA0517.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>TCTCTTTCCTTTTTT</td>\n",
       "      <td>63</td>\n",
       "      <td>77</td>\n",
       "      <td>4.22e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>TFAP2A(var.2) (MA0810.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>TGCCCTAGAGCA</td>\n",
       "      <td>36</td>\n",
       "      <td>47</td>\n",
       "      <td>3.77e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>TFAP2B (MA0811.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>TGCCCTAGAGCA</td>\n",
       "      <td>36</td>\n",
       "      <td>47</td>\n",
       "      <td>3.97e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>TFAP2B (MA0811.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>TGCTCTAGGGCA</td>\n",
       "      <td>36</td>\n",
       "      <td>47</td>\n",
       "      <td>8.49e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>TFAP2C (MA0524.2)</td>\n",
       "      <td>+</td>\n",
       "      <td>TGCCCTAGAGCA</td>\n",
       "      <td>36</td>\n",
       "      <td>47</td>\n",
       "      <td>3.91e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>TFAP2C (MA0524.2)</td>\n",
       "      <td>-</td>\n",
       "      <td>TGCTCTAGGGCA</td>\n",
       "      <td>36</td>\n",
       "      <td>47</td>\n",
       "      <td>5.13e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KE4-1-C02</td>\n",
       "      <td>2</td>\n",
       "      <td>KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....</td>\n",
       "      <td>82</td>\n",
       "      <td>144</td>\n",
       "      <td>56.94</td>\n",
       "      <td>88.17</td>\n",
       "      <td>100.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>ZNF263 (MA0528.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>GGGGGAAAAAAGGAAAGAGAG</td>\n",
       "      <td>58</td>\n",
       "      <td>78</td>\n",
       "      <td>3.22e-06</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...</td>\n",
       "      <td>195</td>\n",
       "      <td>435</td>\n",
       "      <td>44.83</td>\n",
       "      <td>53.28</td>\n",
       "      <td>58.21</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Ar (MA0007.3)</td>\n",
       "      <td>+</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>66</td>\n",
       "      <td>82</td>\n",
       "      <td>3.26e-06</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...</td>\n",
       "      <td>195</td>\n",
       "      <td>435</td>\n",
       "      <td>44.83</td>\n",
       "      <td>53.28</td>\n",
       "      <td>58.21</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Ar (MA0007.3)</td>\n",
       "      <td>-</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>66</td>\n",
       "      <td>82</td>\n",
       "      <td>1.66e-06</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...</td>\n",
       "      <td>195</td>\n",
       "      <td>435</td>\n",
       "      <td>44.83</td>\n",
       "      <td>53.28</td>\n",
       "      <td>58.21</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>E2F7 (MA0758.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>TTTTCCCCCCTATT</td>\n",
       "      <td>137</td>\n",
       "      <td>150</td>\n",
       "      <td>1.09e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...</td>\n",
       "      <td>195</td>\n",
       "      <td>435</td>\n",
       "      <td>44.83</td>\n",
       "      <td>53.28</td>\n",
       "      <td>58.21</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>E2F8 (MA0865.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>TTTCCCCCCTAT</td>\n",
       "      <td>138</td>\n",
       "      <td>149</td>\n",
       "      <td>1.41e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...</td>\n",
       "      <td>195</td>\n",
       "      <td>435</td>\n",
       "      <td>44.83</td>\n",
       "      <td>53.28</td>\n",
       "      <td>58.21</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>EWSR1-FLI1 (MA0149.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>GGGGGGAAAAAAGGAAAG</td>\n",
       "      <td>141</td>\n",
       "      <td>158</td>\n",
       "      <td>9.59e-06</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...</td>\n",
       "      <td>195</td>\n",
       "      <td>435</td>\n",
       "      <td>44.83</td>\n",
       "      <td>53.28</td>\n",
       "      <td>58.21</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>EWSR1-FLI1 (MA0149.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>GGAAAAAAGGAAAGAGAG</td>\n",
       "      <td>145</td>\n",
       "      <td>162</td>\n",
       "      <td>2.17e-06</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...</td>\n",
       "      <td>195</td>\n",
       "      <td>435</td>\n",
       "      <td>44.83</td>\n",
       "      <td>53.28</td>\n",
       "      <td>58.21</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>HIC2 (MA0738.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>GTGCCAGCC</td>\n",
       "      <td>88</td>\n",
       "      <td>96</td>\n",
       "      <td>5.37e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...</td>\n",
       "      <td>195</td>\n",
       "      <td>435</td>\n",
       "      <td>44.83</td>\n",
       "      <td>53.28</td>\n",
       "      <td>58.21</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Hic1 (MA0739.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>GTGCCAGCC</td>\n",
       "      <td>88</td>\n",
       "      <td>96</td>\n",
       "      <td>5.97e-06</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...</td>\n",
       "      <td>195</td>\n",
       "      <td>435</td>\n",
       "      <td>44.83</td>\n",
       "      <td>53.28</td>\n",
       "      <td>58.21</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>IRF1 (MA0050.2)</td>\n",
       "      <td>-</td>\n",
       "      <td>ACTCTCTTTCCTTTTTTCCCC</td>\n",
       "      <td>143</td>\n",
       "      <td>163</td>\n",
       "      <td>6.96e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...</td>\n",
       "      <td>195</td>\n",
       "      <td>435</td>\n",
       "      <td>44.83</td>\n",
       "      <td>53.28</td>\n",
       "      <td>58.21</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>IRF1 (MA0050.2)</td>\n",
       "      <td>-</td>\n",
       "      <td>CTGTGCACTCTCTTTCCTTTT</td>\n",
       "      <td>149</td>\n",
       "      <td>169</td>\n",
       "      <td>8.27e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...</td>\n",
       "      <td>195</td>\n",
       "      <td>435</td>\n",
       "      <td>44.83</td>\n",
       "      <td>53.28</td>\n",
       "      <td>58.21</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>MEIS1 (MA0498.2)</td>\n",
       "      <td>+</td>\n",
       "      <td>CTGACAG</td>\n",
       "      <td>111</td>\n",
       "      <td>117</td>\n",
       "      <td>4.53e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...</td>\n",
       "      <td>195</td>\n",
       "      <td>435</td>\n",
       "      <td>44.83</td>\n",
       "      <td>53.28</td>\n",
       "      <td>58.21</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>MEIS2 (MA0774.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>CTGACAGC</td>\n",
       "      <td>111</td>\n",
       "      <td>118</td>\n",
       "      <td>6.8e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...</td>\n",
       "      <td>195</td>\n",
       "      <td>435</td>\n",
       "      <td>44.83</td>\n",
       "      <td>53.28</td>\n",
       "      <td>58.21</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Mafb (MA0117.2)</td>\n",
       "      <td>+</td>\n",
       "      <td>GATGTGCTGACA</td>\n",
       "      <td>105</td>\n",
       "      <td>116</td>\n",
       "      <td>1.25e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...</td>\n",
       "      <td>195</td>\n",
       "      <td>435</td>\n",
       "      <td>44.83</td>\n",
       "      <td>53.28</td>\n",
       "      <td>58.21</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C1 (MA0113.3)</td>\n",
       "      <td>+</td>\n",
       "      <td>CAGAACACCCTGTTCTG</td>\n",
       "      <td>66</td>\n",
       "      <td>82</td>\n",
       "      <td>2.95e-06</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>KE4-2-A01</td>\n",
       "      <td>1</td>\n",
       "      <td>KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...</td>\n",
       "      <td>195</td>\n",
       "      <td>435</td>\n",
       "      <td>44.83</td>\n",
       "      <td>53.28</td>\n",
       "      <td>58.21</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>||||||||||||||||||||||||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C1 (MA0113.3)</td>\n",
       "      <td>-</td>\n",
       "      <td>CAGAACAGGGTGTTCTG</td>\n",
       "      <td>66</td>\n",
       "      <td>82</td>\n",
       "      <td>2.03e-06</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>3</td>\n",
       "      <td>KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...</td>\n",
       "      <td>11</td>\n",
       "      <td>806</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>TFAP2C (MA0524.2)</td>\n",
       "      <td>-</td>\n",
       "      <td>TGCTCTAGGGCA</td>\n",
       "      <td>35</td>\n",
       "      <td>46</td>\n",
       "      <td>5.13e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>3</td>\n",
       "      <td>KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...</td>\n",
       "      <td>11</td>\n",
       "      <td>806</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Vdr (MA0693.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>CAGCACATCGAGTTCA</td>\n",
       "      <td>93</td>\n",
       "      <td>108</td>\n",
       "      <td>4.58e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>3</td>\n",
       "      <td>KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...</td>\n",
       "      <td>11</td>\n",
       "      <td>806</td>\n",
       "      <td>1.36</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>ZNF263 (MA0528.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>GGGGGAAAAAAGGAAAGAGAG</td>\n",
       "      <td>137</td>\n",
       "      <td>157</td>\n",
       "      <td>3.22e-06</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>E2F7 (MA0758.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>TTTTCCCCCCTATT</td>\n",
       "      <td>134</td>\n",
       "      <td>147</td>\n",
       "      <td>1.09e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>E2F8 (MA0865.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>TTTCCCCCCTAT</td>\n",
       "      <td>135</td>\n",
       "      <td>146</td>\n",
       "      <td>1.41e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>EWSR1-FLI1 (MA0149.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>GGGGGGAAAAAAGGAAAG</td>\n",
       "      <td>138</td>\n",
       "      <td>155</td>\n",
       "      <td>9.59e-06</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>EWSR1-FLI1 (MA0149.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>GGAAAAAAGGAAAGAGAG</td>\n",
       "      <td>142</td>\n",
       "      <td>159</td>\n",
       "      <td>2.17e-06</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>HIC2 (MA0738.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>GTGCCAGCC</td>\n",
       "      <td>85</td>\n",
       "      <td>93</td>\n",
       "      <td>5.37e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Hic1 (MA0739.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>GTGCCAGCC</td>\n",
       "      <td>85</td>\n",
       "      <td>93</td>\n",
       "      <td>5.97e-06</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>IRF1 (MA0050.2)</td>\n",
       "      <td>-</td>\n",
       "      <td>ACTCTCTTTCCTTTTTTCCCC</td>\n",
       "      <td>140</td>\n",
       "      <td>160</td>\n",
       "      <td>6.96e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>IRF1 (MA0050.2)</td>\n",
       "      <td>-</td>\n",
       "      <td>CTGTGCACTCTCTTTCCTTTT</td>\n",
       "      <td>146</td>\n",
       "      <td>166</td>\n",
       "      <td>8.27e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>MEIS1 (MA0498.2)</td>\n",
       "      <td>+</td>\n",
       "      <td>CTGACAG</td>\n",
       "      <td>108</td>\n",
       "      <td>114</td>\n",
       "      <td>4.53e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>MEIS2 (MA0774.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>CTGACAGC</td>\n",
       "      <td>108</td>\n",
       "      <td>115</td>\n",
       "      <td>6.8e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Mafb (MA0117.2)</td>\n",
       "      <td>+</td>\n",
       "      <td>GATGTGCTGACA</td>\n",
       "      <td>102</td>\n",
       "      <td>113</td>\n",
       "      <td>1.25e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NR3C2 (MA0727.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>ATGAACTCGATGTGCTG</td>\n",
       "      <td>94</td>\n",
       "      <td>110</td>\n",
       "      <td>9.39e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>NRL (MA0842.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>GATGTGCTGAC</td>\n",
       "      <td>102</td>\n",
       "      <td>112</td>\n",
       "      <td>2.79e-06</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>PRDM1 (MA0508.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>AAAAAAGGAAAGAGA</td>\n",
       "      <td>144</td>\n",
       "      <td>158</td>\n",
       "      <td>5.2e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>RARA::RXRA (MA0159.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>AGTTCATGTGCCAGCCA</td>\n",
       "      <td>84</td>\n",
       "      <td>100</td>\n",
       "      <td>8.03e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>RXRA::VDR (MA0074.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>AGCACATCGAGTTCA</td>\n",
       "      <td>95</td>\n",
       "      <td>109</td>\n",
       "      <td>6.66e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>SMAD2::SMAD3::SMAD4 (MA0513.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>GTGGCTGGCACAT</td>\n",
       "      <td>83</td>\n",
       "      <td>95</td>\n",
       "      <td>7.99e-06</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>SOX9 (MA0077.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>CTATTGTTC</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>1.53e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>STAT1::STAT2 (MA0517.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>TCTCTTTCCTTTTTT</td>\n",
       "      <td>144</td>\n",
       "      <td>158</td>\n",
       "      <td>4.22e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Sox6 (MA0515.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>CTATTGTTCT</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "      <td>8e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>TFAP2A(var.2) (MA0810.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>TGCCCTAGAGCA</td>\n",
       "      <td>35</td>\n",
       "      <td>46</td>\n",
       "      <td>3.77e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>TFAP2B (MA0811.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>TGCCCTAGAGCA</td>\n",
       "      <td>35</td>\n",
       "      <td>46</td>\n",
       "      <td>3.97e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>TFAP2B (MA0811.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>TGCTCTAGGGCA</td>\n",
       "      <td>35</td>\n",
       "      <td>46</td>\n",
       "      <td>8.49e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>TFAP2C (MA0524.2)</td>\n",
       "      <td>+</td>\n",
       "      <td>TGCCCTAGAGCA</td>\n",
       "      <td>35</td>\n",
       "      <td>46</td>\n",
       "      <td>3.91e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>TFAP2C (MA0524.2)</td>\n",
       "      <td>-</td>\n",
       "      <td>TGCTCTAGGGCA</td>\n",
       "      <td>35</td>\n",
       "      <td>46</td>\n",
       "      <td>5.13e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>Vdr (MA0693.1)</td>\n",
       "      <td>-</td>\n",
       "      <td>CAGCACATCGAGTTCA</td>\n",
       "      <td>95</td>\n",
       "      <td>110</td>\n",
       "      <td>4.58e-05</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>KE4-4-G10</td>\n",
       "      <td>4</td>\n",
       "      <td>KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...</td>\n",
       "      <td>4</td>\n",
       "      <td>806</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>|||||||||||||||||||| |||||||||||||||||||||||||...</td>\n",
       "      <td>ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...</td>\n",
       "      <td>ZNF263 (MA0528.1)</td>\n",
       "      <td>+</td>\n",
       "      <td>GGGGGAAAAAAGGAAAGAGAG</td>\n",
       "      <td>139</td>\n",
       "      <td>159</td>\n",
       "      <td>3.22e-06</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>373 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sample  allele rank  \\\n",
       "10   KE4-1-C02            2   \n",
       "9    KE4-1-C02            2   \n",
       "5    KE4-1-C02            2   \n",
       "0    KE4-1-C02            2   \n",
       "13   KE4-1-C02            2   \n",
       "6    KE4-1-C02            2   \n",
       "8    KE4-1-C02            2   \n",
       "3    KE4-1-C02            2   \n",
       "7    KE4-1-C02            2   \n",
       "1    KE4-1-C02            2   \n",
       "4    KE4-1-C02            2   \n",
       "11   KE4-1-C02            2   \n",
       "14   KE4-1-C02            2   \n",
       "2    KE4-1-C02            2   \n",
       "12   KE4-1-C02            2   \n",
       "45   KE4-2-A01            1   \n",
       "21   KE4-2-A01            1   \n",
       "16   KE4-2-A01            1   \n",
       "39   KE4-2-A01            1   \n",
       "26   KE4-2-A01            1   \n",
       "41   KE4-2-A01            1   \n",
       "31   KE4-2-A01            1   \n",
       "20   KE4-2-A01            1   \n",
       "33   KE4-2-A01            1   \n",
       "30   KE4-2-A01            1   \n",
       "32   KE4-2-A01            1   \n",
       "34   KE4-2-A01            1   \n",
       "42   KE4-2-A01            1   \n",
       "17   KE4-2-A01            1   \n",
       "24   KE4-2-A01            1   \n",
       "..         ...          ...   \n",
       "322  KE4-4-G10            3   \n",
       "317  KE4-4-G10            3   \n",
       "345  KE4-4-G10            3   \n",
       "354  KE4-4-G10            4   \n",
       "362  KE4-4-G10            4   \n",
       "358  KE4-4-G10            4   \n",
       "352  KE4-4-G10            4   \n",
       "359  KE4-4-G10            4   \n",
       "347  KE4-4-G10            4   \n",
       "351  KE4-4-G10            4   \n",
       "370  KE4-4-G10            4   \n",
       "356  KE4-4-G10            4   \n",
       "368  KE4-4-G10            4   \n",
       "346  KE4-4-G10            4   \n",
       "349  KE4-4-G10            4   \n",
       "363  KE4-4-G10            4   \n",
       "367  KE4-4-G10            4   \n",
       "353  KE4-4-G10            4   \n",
       "360  KE4-4-G10            4   \n",
       "348  KE4-4-G10            4   \n",
       "372  KE4-4-G10            4   \n",
       "355  KE4-4-G10            4   \n",
       "371  KE4-4-G10            4   \n",
       "350  KE4-4-G10            4   \n",
       "357  KE4-4-G10            4   \n",
       "361  KE4-4-G10            4   \n",
       "364  KE4-4-G10            4   \n",
       "369  KE4-4-G10            4   \n",
       "366  KE4-4-G10            4   \n",
       "365  KE4-4-G10            4   \n",
       "\n",
       "                                             allele ID reads total reads  \\\n",
       "10   KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....    82         144   \n",
       "9    KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....    82         144   \n",
       "5    KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....    82         144   \n",
       "0    KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....    82         144   \n",
       "13   KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....    82         144   \n",
       "6    KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....    82         144   \n",
       "8    KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....    82         144   \n",
       "3    KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....    82         144   \n",
       "7    KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....    82         144   \n",
       "1    KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....    82         144   \n",
       "4    KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....    82         144   \n",
       "11   KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....    82         144   \n",
       "14   KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....    82         144   \n",
       "2    KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....    82         144   \n",
       "12   KE4-1-C02_R1+R2_[82/144]_rank1_%totalreads:56....    82         144   \n",
       "45   KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...   195         435   \n",
       "21   KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...   195         435   \n",
       "16   KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...   195         435   \n",
       "39   KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...   195         435   \n",
       "26   KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...   195         435   \n",
       "41   KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...   195         435   \n",
       "31   KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...   195         435   \n",
       "20   KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...   195         435   \n",
       "33   KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...   195         435   \n",
       "30   KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...   195         435   \n",
       "32   KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...   195         435   \n",
       "34   KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...   195         435   \n",
       "42   KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...   195         435   \n",
       "17   KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...   195         435   \n",
       "24   KE4-2-A01_R1+R2_[195/435]_rank1_%totalreads:44...   195         435   \n",
       "..                                                 ...   ...         ...   \n",
       "322  KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...    11         806   \n",
       "317  KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...    11         806   \n",
       "345  KE4-4-G10_R1+R2_[11/806]_rank3_%totalreads:1.3...    11         806   \n",
       "354  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "362  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "358  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "352  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "359  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "347  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "351  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "370  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "356  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "368  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "346  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "349  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "363  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "367  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "353  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "360  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "348  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "372  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "355  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "371  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "350  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "357  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "361  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "364  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "369  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "366  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "365  KE4-4-G10_R1+R2_[4/806]_rank4_%totalreads:0.5_...     4         806   \n",
       "\n",
       "    % total reads  % reads filtered for reads <1%  \\\n",
       "10          56.94                           88.17   \n",
       "9           56.94                           88.17   \n",
       "5           56.94                           88.17   \n",
       "0           56.94                           88.17   \n",
       "13          56.94                           88.17   \n",
       "6           56.94                           88.17   \n",
       "8           56.94                           88.17   \n",
       "3           56.94                           88.17   \n",
       "7           56.94                           88.17   \n",
       "1           56.94                           88.17   \n",
       "4           56.94                           88.17   \n",
       "11          56.94                           88.17   \n",
       "14          56.94                           88.17   \n",
       "2           56.94                           88.17   \n",
       "12          56.94                           88.17   \n",
       "45          44.83                           53.28   \n",
       "21          44.83                           53.28   \n",
       "16          44.83                           53.28   \n",
       "39          44.83                           53.28   \n",
       "26          44.83                           53.28   \n",
       "41          44.83                           53.28   \n",
       "31          44.83                           53.28   \n",
       "20          44.83                           53.28   \n",
       "33          44.83                           53.28   \n",
       "30          44.83                           53.28   \n",
       "32          44.83                           53.28   \n",
       "34          44.83                           53.28   \n",
       "42          44.83                           53.28   \n",
       "17          44.83                           53.28   \n",
       "24          44.83                           53.28   \n",
       "..            ...                             ...   \n",
       "322          1.36                            1.64   \n",
       "317          1.36                            1.64   \n",
       "345          1.36                            1.64   \n",
       "354           0.5                            0.00   \n",
       "362           0.5                            0.00   \n",
       "358           0.5                            0.00   \n",
       "352           0.5                            0.00   \n",
       "359           0.5                            0.00   \n",
       "347           0.5                            0.00   \n",
       "351           0.5                            0.00   \n",
       "370           0.5                            0.00   \n",
       "356           0.5                            0.00   \n",
       "368           0.5                            0.00   \n",
       "346           0.5                            0.00   \n",
       "349           0.5                            0.00   \n",
       "363           0.5                            0.00   \n",
       "367           0.5                            0.00   \n",
       "353           0.5                            0.00   \n",
       "360           0.5                            0.00   \n",
       "348           0.5                            0.00   \n",
       "372           0.5                            0.00   \n",
       "355           0.5                            0.00   \n",
       "371           0.5                            0.00   \n",
       "350           0.5                            0.00   \n",
       "357           0.5                            0.00   \n",
       "361           0.5                            0.00   \n",
       "364           0.5                            0.00   \n",
       "369           0.5                            0.00   \n",
       "366           0.5                            0.00   \n",
       "365           0.5                            0.00   \n",
       "\n",
       "     % reads filtered for reads <10%  \\\n",
       "10                            100.00   \n",
       "9                             100.00   \n",
       "5                             100.00   \n",
       "0                             100.00   \n",
       "13                            100.00   \n",
       "6                             100.00   \n",
       "8                             100.00   \n",
       "3                             100.00   \n",
       "7                             100.00   \n",
       "1                             100.00   \n",
       "4                             100.00   \n",
       "11                            100.00   \n",
       "14                            100.00   \n",
       "2                             100.00   \n",
       "12                            100.00   \n",
       "45                             58.21   \n",
       "21                             58.21   \n",
       "16                             58.21   \n",
       "39                             58.21   \n",
       "26                             58.21   \n",
       "41                             58.21   \n",
       "31                             58.21   \n",
       "20                             58.21   \n",
       "33                             58.21   \n",
       "30                             58.21   \n",
       "32                             58.21   \n",
       "34                             58.21   \n",
       "42                             58.21   \n",
       "17                             58.21   \n",
       "24                             58.21   \n",
       "..                               ...   \n",
       "322                             0.00   \n",
       "317                             0.00   \n",
       "345                             0.00   \n",
       "354                             0.00   \n",
       "362                             0.00   \n",
       "358                             0.00   \n",
       "352                             0.00   \n",
       "359                             0.00   \n",
       "347                             0.00   \n",
       "351                             0.00   \n",
       "370                             0.00   \n",
       "356                             0.00   \n",
       "368                             0.00   \n",
       "346                             0.00   \n",
       "349                             0.00   \n",
       "363                             0.00   \n",
       "367                             0.00   \n",
       "353                             0.00   \n",
       "360                             0.00   \n",
       "348                             0.00   \n",
       "372                             0.00   \n",
       "355                             0.00   \n",
       "371                             0.00   \n",
       "350                             0.00   \n",
       "357                             0.00   \n",
       "361                             0.00   \n",
       "364                             0.00   \n",
       "369                             0.00   \n",
       "366                             0.00   \n",
       "365                             0.00   \n",
       "\n",
       "                    alignment query\\n(allele sequence)  \\\n",
       "10   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "9    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "5    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "0    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "13   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "6    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "8    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "3    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "7    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "1    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "4    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "11   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "14   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "2    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "12   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "45   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "21   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "16   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "39   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "26   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "41   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "31   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "20   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "33   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "30   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "32   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "34   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "42   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "17   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "24   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "..                                                 ...   \n",
       "322  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "317  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "345  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "354  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "362  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "358  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "352  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "359  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "347  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "351  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "370  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "356  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "368  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "346  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "349  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "363  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "367  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "353  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "360  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "348  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "372  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "355  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "371  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "350  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "357  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "361  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "364  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "369  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "366  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "365  ACTTAAACTGGAGCTCTGAC-TATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "\n",
       "                                     alignment midline  \\\n",
       "10   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "9    ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "5    ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "0    ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "13   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "6    ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "8    ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "3    ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "7    ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "1    ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "4    ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "11   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "14   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "2    ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "12   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "45   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "21   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "16   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "39   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "26   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "41   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "31   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "20   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "33   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "30   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "32   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "34   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "42   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "17   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "24   ||||||||||||||||||||||||||||||||||||||||||||||...   \n",
       "..                                                 ...   \n",
       "322  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "317  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "345  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "354  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "362  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "358  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "352  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "359  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "347  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "351  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "370  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "356  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "368  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "346  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "349  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "363  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "367  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "353  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "360  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "348  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "372  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "355  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "371  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "350  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "357  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "361  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "364  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "369  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "366  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "365  |||||||||||||||||||| |||||||||||||||||||||||||...   \n",
       "\n",
       "                            alignment hit\\n(reference)  \\\n",
       "10   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "9    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "5    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "0    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "13   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "6    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "8    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "3    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "7    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "1    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "4    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "11   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "14   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "2    ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "12   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "45   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "21   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "16   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "39   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "26   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "41   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "31   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "20   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "33   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "30   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "32   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "34   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "42   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "17   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "24   ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "..                                                 ...   \n",
       "322  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "317  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "345  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "354  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "362  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "358  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "352  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "359  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "347  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "351  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "370  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "356  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "368  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "346  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "349  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "363  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "367  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "353  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "360  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "348  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "372  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "355  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "371  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "350  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "357  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "361  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "364  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "369  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "366  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "365  ACTTAAACTGGAGCTCTGACTTATTGTTCTCTTACTGCCCTAGAGC...   \n",
       "\n",
       "                                 TF strand          TFBS sequence  \\\n",
       "10                  E2F7 (MA0758.1)      -         TTTTCCCCCCAAAC   \n",
       "9                   E2F8 (MA0865.1)      -           TTTCCCCCCAAA   \n",
       "5                   E2F8 (MA0865.1)      -           TTTTCCCCCCAA   \n",
       "0             EWSR1-FLI1 (MA0149.1)      +     GGGGGGAAAAAAGGAAAG   \n",
       "13            EWSR1-FLI1 (MA0149.1)      +     GGAAAAAAGGAAAGAGAG   \n",
       "6                   IRF1 (MA0050.2)      -  ACTCTCTTTCCTTTTTTCCCC   \n",
       "8                   IRF1 (MA0050.2)      -  CTGTGCACTCTCTTTCCTTTT   \n",
       "3                  PRDM1 (MA0508.1)      +        AAAAAAGGAAAGAGA   \n",
       "7           STAT1::STAT2 (MA0517.1)      -        TCTCTTTCCTTTTTT   \n",
       "1          TFAP2A(var.2) (MA0810.1)      +           TGCCCTAGAGCA   \n",
       "4                 TFAP2B (MA0811.1)      +           TGCCCTAGAGCA   \n",
       "11                TFAP2B (MA0811.1)      -           TGCTCTAGGGCA   \n",
       "14                TFAP2C (MA0524.2)      +           TGCCCTAGAGCA   \n",
       "2                 TFAP2C (MA0524.2)      -           TGCTCTAGGGCA   \n",
       "12                ZNF263 (MA0528.1)      +  GGGGGAAAAAAGGAAAGAGAG   \n",
       "45                    Ar (MA0007.3)      +      CAGAACACCCTGTTCTG   \n",
       "21                    Ar (MA0007.3)      -      CAGAACAGGGTGTTCTG   \n",
       "16                  E2F7 (MA0758.1)      -         TTTTCCCCCCTATT   \n",
       "39                  E2F8 (MA0865.1)      -           TTTCCCCCCTAT   \n",
       "26            EWSR1-FLI1 (MA0149.1)      +     GGGGGGAAAAAAGGAAAG   \n",
       "41            EWSR1-FLI1 (MA0149.1)      +     GGAAAAAAGGAAAGAGAG   \n",
       "31                  HIC2 (MA0738.1)      -              GTGCCAGCC   \n",
       "20                  Hic1 (MA0739.1)      -              GTGCCAGCC   \n",
       "33                  IRF1 (MA0050.2)      -  ACTCTCTTTCCTTTTTTCCCC   \n",
       "30                  IRF1 (MA0050.2)      -  CTGTGCACTCTCTTTCCTTTT   \n",
       "32                 MEIS1 (MA0498.2)      +                CTGACAG   \n",
       "34                 MEIS2 (MA0774.1)      +               CTGACAGC   \n",
       "42                  Mafb (MA0117.2)      +           GATGTGCTGACA   \n",
       "17                 NR3C1 (MA0113.3)      +      CAGAACACCCTGTTCTG   \n",
       "24                 NR3C1 (MA0113.3)      -      CAGAACAGGGTGTTCTG   \n",
       "..                              ...    ...                    ...   \n",
       "322               TFAP2C (MA0524.2)      -           TGCTCTAGGGCA   \n",
       "317                  Vdr (MA0693.1)      -       CAGCACATCGAGTTCA   \n",
       "345               ZNF263 (MA0528.1)      +  GGGGGAAAAAAGGAAAGAGAG   \n",
       "354                 E2F7 (MA0758.1)      -         TTTTCCCCCCTATT   \n",
       "362                 E2F8 (MA0865.1)      -           TTTCCCCCCTAT   \n",
       "358           EWSR1-FLI1 (MA0149.1)      +     GGGGGGAAAAAAGGAAAG   \n",
       "352           EWSR1-FLI1 (MA0149.1)      +     GGAAAAAAGGAAAGAGAG   \n",
       "359                 HIC2 (MA0738.1)      -              GTGCCAGCC   \n",
       "347                 Hic1 (MA0739.1)      -              GTGCCAGCC   \n",
       "351                 IRF1 (MA0050.2)      -  ACTCTCTTTCCTTTTTTCCCC   \n",
       "370                 IRF1 (MA0050.2)      -  CTGTGCACTCTCTTTCCTTTT   \n",
       "356                MEIS1 (MA0498.2)      +                CTGACAG   \n",
       "368                MEIS2 (MA0774.1)      +               CTGACAGC   \n",
       "346                 Mafb (MA0117.2)      +           GATGTGCTGACA   \n",
       "349                NR3C2 (MA0727.1)      +      ATGAACTCGATGTGCTG   \n",
       "363                  NRL (MA0842.1)      +            GATGTGCTGAC   \n",
       "367                PRDM1 (MA0508.1)      +        AAAAAAGGAAAGAGA   \n",
       "353           RARA::RXRA (MA0159.1)      -      AGTTCATGTGCCAGCCA   \n",
       "360            RXRA::VDR (MA0074.1)      -        AGCACATCGAGTTCA   \n",
       "348  SMAD2::SMAD3::SMAD4 (MA0513.1)      +          GTGGCTGGCACAT   \n",
       "372                 SOX9 (MA0077.1)      +              CTATTGTTC   \n",
       "355         STAT1::STAT2 (MA0517.1)      -        TCTCTTTCCTTTTTT   \n",
       "371                 Sox6 (MA0515.1)      +             CTATTGTTCT   \n",
       "350        TFAP2A(var.2) (MA0810.1)      +           TGCCCTAGAGCA   \n",
       "357               TFAP2B (MA0811.1)      +           TGCCCTAGAGCA   \n",
       "361               TFAP2B (MA0811.1)      -           TGCTCTAGGGCA   \n",
       "364               TFAP2C (MA0524.2)      +           TGCCCTAGAGCA   \n",
       "369               TFAP2C (MA0524.2)      -           TGCTCTAGGGCA   \n",
       "366                  Vdr (MA0693.1)      -       CAGCACATCGAGTTCA   \n",
       "365               ZNF263 (MA0528.1)      +  GGGGGAAAAAAGGAAAGAGAG   \n",
       "\n",
       "    TFBS coordinate start (in allele) TFBS coordinate end (in allele)  \\\n",
       "10                                 53                              66   \n",
       "9                                  54                              65   \n",
       "5                                  55                              66   \n",
       "0                                  57                              74   \n",
       "13                                 61                              78   \n",
       "6                                  59                              79   \n",
       "8                                  65                              85   \n",
       "3                                  63                              77   \n",
       "7                                  63                              77   \n",
       "1                                  36                              47   \n",
       "4                                  36                              47   \n",
       "11                                 36                              47   \n",
       "14                                 36                              47   \n",
       "2                                  36                              47   \n",
       "12                                 58                              78   \n",
       "45                                 66                              82   \n",
       "21                                 66                              82   \n",
       "16                                137                             150   \n",
       "39                                138                             149   \n",
       "26                                141                             158   \n",
       "41                                145                             162   \n",
       "31                                 88                              96   \n",
       "20                                 88                              96   \n",
       "33                                143                             163   \n",
       "30                                149                             169   \n",
       "32                                111                             117   \n",
       "34                                111                             118   \n",
       "42                                105                             116   \n",
       "17                                 66                              82   \n",
       "24                                 66                              82   \n",
       "..                                ...                             ...   \n",
       "322                                35                              46   \n",
       "317                                93                             108   \n",
       "345                               137                             157   \n",
       "354                               134                             147   \n",
       "362                               135                             146   \n",
       "358                               138                             155   \n",
       "352                               142                             159   \n",
       "359                                85                              93   \n",
       "347                                85                              93   \n",
       "351                               140                             160   \n",
       "370                               146                             166   \n",
       "356                               108                             114   \n",
       "368                               108                             115   \n",
       "346                               102                             113   \n",
       "349                                94                             110   \n",
       "363                               102                             112   \n",
       "367                               144                             158   \n",
       "353                                84                             100   \n",
       "360                                95                             109   \n",
       "348                                83                              95   \n",
       "372                                20                              28   \n",
       "355                               144                             158   \n",
       "371                                20                              29   \n",
       "350                                35                              46   \n",
       "357                                35                              46   \n",
       "361                                35                              46   \n",
       "364                                35                              46   \n",
       "369                                35                              46   \n",
       "366                                95                             110   \n",
       "365                               139                             159   \n",
       "\n",
       "    TFBS p-val comment  \n",
       "10    3.04e-06          \n",
       "9     9.78e-08          \n",
       "5      3.6e-05          \n",
       "0     9.59e-06          \n",
       "13    2.17e-06          \n",
       "6     6.96e-05          \n",
       "8     8.27e-05          \n",
       "3      5.2e-05          \n",
       "7     4.22e-05          \n",
       "1     3.77e-05          \n",
       "4     3.97e-05          \n",
       "11    8.49e-05          \n",
       "14    3.91e-05          \n",
       "2     5.13e-05          \n",
       "12    3.22e-06          \n",
       "45    3.26e-06          \n",
       "21    1.66e-06          \n",
       "16    1.09e-05          \n",
       "39    1.41e-05          \n",
       "26    9.59e-06          \n",
       "41    2.17e-06          \n",
       "31    5.37e-05          \n",
       "20    5.97e-06          \n",
       "33    6.96e-05          \n",
       "30    8.27e-05          \n",
       "32    4.53e-05          \n",
       "34     6.8e-05          \n",
       "42    1.25e-05          \n",
       "17    2.95e-06          \n",
       "24    2.03e-06          \n",
       "..         ...     ...  \n",
       "322   5.13e-05          \n",
       "317   4.58e-05          \n",
       "345   3.22e-06          \n",
       "354   1.09e-05          \n",
       "362   1.41e-05          \n",
       "358   9.59e-06          \n",
       "352   2.17e-06          \n",
       "359   5.37e-05          \n",
       "347   5.97e-06          \n",
       "351   6.96e-05          \n",
       "370   8.27e-05          \n",
       "356   4.53e-05          \n",
       "368    6.8e-05          \n",
       "346   1.25e-05          \n",
       "349   9.39e-05          \n",
       "363   2.79e-06          \n",
       "367    5.2e-05          \n",
       "353   8.03e-05          \n",
       "360   6.66e-05          \n",
       "348   7.99e-06          \n",
       "372   1.53e-05          \n",
       "355   4.22e-05          \n",
       "371      8e-05          \n",
       "350   3.77e-05          \n",
       "357   3.97e-05          \n",
       "361   8.49e-05          \n",
       "364   3.91e-05          \n",
       "369   5.13e-05          \n",
       "366   4.58e-05          \n",
       "365   3.22e-06          \n",
       "\n",
       "[373 rows x 18 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add read count data\n",
    "read_count_list = [i.split('_')[2].strip('[]').split('/')[0] for i in all_TFBS_synopsis_df['allele ID'].to_list()]\n",
    "total_reads_list = [i.split('_')[2].strip('[]').split('/')[1] for i in all_TFBS_synopsis_df['allele ID'].to_list()]\n",
    "pct_total_reads_list = [i.split('_')[4].split(':')[1] for i in all_TFBS_synopsis_df['allele ID'].to_list()]\n",
    "pct_reads_filtered_for_1pct_list = [float(i.split('_')[7].split(':')[1]) if i.split('_')[7].split(':')[1] != 'None' else 0 for i in all_TFBS_synopsis_df['allele ID'].to_list()]\n",
    "pct_reads_filtered_for_10pct_list = [float(i.split('_')[8].split(':')[1]) if i.split('_')[8].split(':')[1] != 'None' else 0 for i in all_TFBS_synopsis_df['allele ID'].to_list()]\n",
    "\n",
    "all_TFBS_synopsis_df.insert(loc=3, column='reads', value=read_count_list)\n",
    "all_TFBS_synopsis_df.insert(loc=4, column='total reads', value=total_reads_list)\n",
    "all_TFBS_synopsis_df.insert(loc=5, column='% total reads', value=pct_total_reads_list)\n",
    "all_TFBS_synopsis_df.insert(loc=6, column='% reads filtered for reads <1%', value=pct_reads_filtered_for_1pct_list)\n",
    "all_TFBS_synopsis_df.insert(loc=7, column='% reads filtered for reads <10%', value=pct_reads_filtered_for_10pct_list)\n",
    "\n",
    "# Add column with allele comment (comment if appropriate)\n",
    "all_TFBS_synopsis_df['comment'] = ['note: inferred allele length <=50 bp; read may be primer dimer; consult fasta file for this inferred allele, and/or consider pre-processing fastq file (filter reads) prior to running CollatedMotifs' if i <=50 else '' for i in [len(x) for x in all_TFBS_synopsis_df['alignment query\\n(allele sequence)'].to_list()]]\n",
    "\n",
    "all_TFBS_synopsis_df.sort_values(by=['sample','allele rank','TF',\"strand\",\"TFBS coordinate start (in allele)\"],ascending=[True, True, True, True, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VII. Process key output files  \n",
    "#### *Finalize reports of interpretations for TFBSs lost/regained/gained *  \n",
    "\n",
    "**Data availability:** The raw data underlying allele definitions and interpreted TFBS losses/gains relative to reference sequence are available to a user in a multi-worksheet Excel file, **collated_TFBS.xlsx**.\n",
    "\n",
    "**Lost/gained TFBSs mapped onto BLASTN alignments:** Positional overlays on sequence alignments are available for TFBSs lost or gained in ranked alleles relative to reference sequence, in **collated_TFBS.txt**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print dataframes to output file (Excel): **collated_motifs.xlsx**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "collatedTFBS_csv_output = Path(str(output_path)+ '/'+processdate+'_collated_TFBS.xlsx')\n",
    "\n",
    "with pd.ExcelWriter(collatedTFBS_csv_output) as writer:  \n",
    "    allele_TFBS_synopsis_df.sort_values(by=['sample','allele rank','TF',\"strand\",\"lost or gained in allele (relative to ref)?\"],ascending=[True, True, True, True, False]).to_excel(writer, sheet_name='1 TFBS, predicted lost, gained', index=False)\n",
    "    interpreted_TFBS_synopsis_df_updated.sort_values(by=['sample','allele rank','TF',\"strand\",\"interpretation\"],ascending=[True, True, True, True, False]).to_excel(writer, sheet_name='2 TFBS, lost-regained pairs', index=False)\n",
    "    if TF_of_interest == '':\n",
    "        all_TFBS_synopsis_df.sort_values(by=['sample','allele rank','TF',\"strand\",\"TFBS coordinate start (in allele)\"],ascending=[True, True, True, True, True]).to_excel(writer, sheet_name='3 All TFBS in alleles', index=False)\n",
    "    # TF_of_interest length is assessed to account for Excel maximum of 31 characters in tab names\n",
    "    elif len(TF_of_interest) <= 6:\n",
    "        predicted_loss_of_TFBS_synopsis_df.sort_values(by=['sample','allele rank','TF lost',\"TF lost strand\",\"Lost TFBS coordinate start (in reference)\"],ascending=[True, True, True, True, True]).to_excel(writer, sheet_name='3 '+TF_of_interest+', lost (all)', index=False)\n",
    "        predicted_exclusive_loss_of_TFBS_synopsis_df.sort_values(by=['sample','allele rank','TF lost',\"TF lost strand\",\"Lost TFBS coordinate start (in reference)\"],ascending=[True, True, True, True, True]).to_excel(writer, sheet_name='4 '+TF_of_interest+', lost (-gain,-regain)', index=False)\n",
    "        predicted_loss_with_regain_of_new_TFBS_for_same_TF_synopsis_df.sort_values(by=['sample','allele rank','TF lost',\"TF lost strand\",\"Lost TFBS coordinate start (in reference)\"],ascending=[True, True, True, True, True]).to_excel(writer, sheet_name='5 '+TF_of_interest+', lost (+regain)', index=False)\n",
    "        predicted_loss_with_gain_of_different_TFBS_synopsis_df.sort_values(by=['sample','allele rank','TF lost',\"TF lost strand\",\"Lost TFBS coordinate start (in reference)\"],ascending=[True, True, True, True, True]).to_excel(writer, sheet_name='6 '+TF_of_interest+', lost (+gain)', index=False)\n",
    "        samples_predicted_to_have_lost_TFBS_synopsis_df.sort_values(by=['genotype inference', 'sample','allele rank',\"TF lost strand\",\"Lost TFBS coordinate start (in reference)\"],ascending=[True, True, True, True, True]).to_excel(writer, sheet_name='7 '+TF_of_interest+', curated samples', index=False)\n",
    "        all_TFBS_synopsis_df.sort_values(by=['sample','allele rank','TF',\"strand\",\"TFBS coordinate start (in allele)\"],ascending=[True, True, True, True, True]).to_excel(writer, sheet_name='8 All TFBS in alleles', index=False)\n",
    "    else:\n",
    "        adjusted_TF_of_interest = TF_of_interest[:7]\n",
    "        predicted_loss_of_TFBS_synopsis_df.sort_values(by=['sample','allele rank','TF lost',\"TF lost strand\",\"Lost TFBS coordinate start (in reference)\"],ascending=[True, True, True, True, True]).to_excel(writer, sheet_name='3 '+adjusted_TF_of_interest+' lost (all)', index=False)\n",
    "        predicted_exclusive_loss_of_TFBS_synopsis_df.sort_values(by=['sample','allele rank','TF lost',\"TF lost strand\",\"Lost TFBS coordinate start (in reference)\"],ascending=[True, True, True, True, True]).to_excel(writer, sheet_name='4 '+adjusted_TF_of_interest+' lost (-gain,-regain)', index=False)\n",
    "        predicted_loss_with_regain_of_new_TFBS_for_same_TF_synopsis_df.sort_values(by=['sample','allele rank','TF lost',\"TF lost strand\",\"Lost TFBS coordinate start (in reference)\"],ascending=[True, True, True, True, True]).to_excel(writer, sheet_name='5 '+adjusted_TF_of_interest+' lost (+regain)', index=False)\n",
    "        predicted_loss_with_gain_of_different_TFBS_synopsis_df.sort_values(by=['sample','allele rank','TF lost',\"TF lost strand\",\"Lost TFBS coordinate start (in reference)\"],ascending=[True, True, True, True, True]).to_excel(writer, sheet_name='6 '+adjusted_TF_of_interest+' lost (+gain)', index=False)\n",
    "        samples_predicted_to_have_lost_TFBS_synopsis_df.sort_values(by=['genotype inference', 'sample','allele rank',\"TF lost strand\",\"Lost TFBS coordinate start (in reference)\"],ascending=[True, True, True, True, True]).to_excel(writer, sheet_name='7 '+adjusted_TF_of_interest+' curated samples', index=False)\n",
    "        all_TFBS_synopsis_df.sort_values(by=['sample','allele rank','TF',\"strand\",\"TFBS coordinate start (in allele)\"],ascending=[True, True, True, True, True]).to_excel(writer, sheet_name='8 All TFBS in alleles', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print alignments and associated lost/gained TFBS collations to output file: **collated_motifs.txt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Relate allele definition (alignments in alignmentoutput_dict2) to TFBS collation for each allele of each sample (with focus on lost and gained TFBS for each allele, relative to reference)\n",
    "collatedTFBS_output = Path(str(output_path)+ '/'+processdate+'_collated_TFBS.txt')\n",
    "with open(str(collatedTFBS_output), 'a+') as f:\n",
    "    print('CollatedMotifs.py: Summary of matches to TFBS motifs detected in sample sequence(s) relative to reference\\nDate: ' + (datetime.today().strftime(\"%m/%d/%Y\")) + '\\n\\n', file = f)\n",
    "    for i in sorted(dict_allele_TFBS_synopsis):\n",
    "        print((len(i)*'=')+'\\n'+i+'\\n'+(len(i)*'='), file = f)\n",
    "        for allele in sorted(dict_allele_TFBS_synopsis.get(i), key=lambda x: x.split('_')[3]):\n",
    "            for x in range(0, len(alignmentoutput_dict2.get(i))):\n",
    "                if alignmentoutput_dict2.get(i)[x][1].split('>')[1].split('<')[0] == allele:\n",
    "                    test = alignmentoutput_dict2.get(i)[x]\n",
    "            sum_gained_motifs = []\n",
    "            sum_lost_motifs = []\n",
    "            sum_motifs = []\n",
    "            sum_TFs = []\n",
    "            TFs_gt1 = []\n",
    "            lost_motifs_plus_strand = []\n",
    "            lost_motifs_minus_strand = []\n",
    "            total_lost_motifs = []\n",
    "            total_lost_motifs_list = []\n",
    "            gained_motifs_plus_strand = []\n",
    "            gained_motifs_minus_strand = []\n",
    "            total_gained_motifs = []\n",
    "            sum_motifs = str(len(dict_allele_TFBS_synopsis.get(i).get(allele).get('all_sites')))\n",
    "            #print(allele+' '+sum_motifs)\n",
    "            sum_TFs = str(len(dict_allele_TFBS_synopsis.get(i).get(allele).get('TFs')))\n",
    "            TFs_gt1 = str(len([TF for TF in dict_allele_TFBS_synopsis.get(i).get(allele).get('TFs') if dict_allele_TFBS_synopsis.get(i).get(allele).get('TFs').get(TF) > 1]))\n",
    "            sum_lost_motifs = str(len(dict_allele_TFBS_synopsis.get(i).get(allele).get('lost')))\n",
    "            sum_gained_motifs = str(len(dict_allele_TFBS_synopsis.get(i).get(allele).get('gained')))\n",
    "            # lost\n",
    "            lost_motifs_plus_strand = [motif.split(' ')[0] for motif in dict_allele_TFBS_synopsis.get(i).get(allele).get('lost') if motif.split(',')[1] == '+']\n",
    "            lost_motifs_minus_strand = [motif.split(' ')[0] for motif in dict_allele_TFBS_synopsis.get(i).get(allele).get('lost') if motif.split(',')[1] == '-']\n",
    "            total_lost_motifs = lost_motifs_plus_strand+lost_motifs_minus_strand\n",
    "            total_lost_motifs_dict = dict(Counter(total_lost_motifs))\n",
    "            total_lost_motifs_list = [i+':'+str(total_lost_motifs_dict.get(i)) for i in total_lost_motifs_dict]\n",
    "            total_lost_motifs_list = sorted(total_lost_motifs_list)\n",
    "            # gained\n",
    "            gained_motifs_plus_strand = [motif.split(' ')[0] for motif in dict_allele_TFBS_synopsis.get(i).get(allele).get('gained') if motif.split(',')[1] == '+']\n",
    "            gained_motifs_minus_strand = [motif.split(' ')[0] for motif in dict_allele_TFBS_synopsis.get(i).get(allele).get('gained') if motif.split(',')[1] == '-']\n",
    "            total_gained_motifs = gained_motifs_plus_strand+gained_motifs_minus_strand\n",
    "            total_gained_motifs_dict = dict(Counter(total_gained_motifs))\n",
    "            total_gained_motifs_list = [i+':'+str(total_gained_motifs_dict.get(i)) for i in total_gained_motifs_dict]\n",
    "            total_gained_motifs_list = sorted(total_gained_motifs_list)\n",
    "            print(3*' '+'Allele: '+allele.replace('_',' | ')+'\\n   Motifs: total distinct sites |'+sum_motifs+'|, total unique TFs |'+sum_TFs+'| (motifs for '+TFs_gt1+' TFs occur >1x)', file = f)\n",
    "            print(' Synopsis: relative to reference sequence--# lost sites |'+sum_lost_motifs+'|, # new sites |'+sum_gained_motifs+'|', file = f)\n",
    "            print('  Details: lost |'+str(total_lost_motifs_list).strip('[]').replace(\"'\",\"\")+'|', file = f)\n",
    "            print('            new |'+str(total_gained_motifs_list).strip('[]').replace(\"'\",\"\")+'|', file = f)\n",
    "            if len(dict_allele_TFBS_synopsis.get(i).get(allele).get('allele_sequence')[0].split('>')[1].split('<')[0]) <= 50:\n",
    "                print(5*' '+'Note: inferred allele length <=50 bp; read may be primer dimer;\\n'+11*' '+'consult fasta file for this inferred allele, and/or consider pre-processing fastq file (filter reads) prior to running CollatedMotifs', file = f)\n",
    "            # prepare complete visual mapping of new motifs above allele sequence\n",
    "            if int(sum_gained_motifs) > 0: \n",
    "                print('\\n'+11*' '+'NEW motifs:', file = f)\n",
    "                motif_plus_tracker = []\n",
    "                motif_minus_tracker = []\n",
    "                new_motif_plus_list = []\n",
    "                new_motif_minus_list = []\n",
    "                for motif in dict_allele_TFBS_synopsis.get(i).get(allele).get('gained'):\n",
    "                    if motif.split(',')[1] == '+':\n",
    "                        new_motif_plus_list.append(motif)\n",
    "                    elif motif.split(',')[1] == '-':\n",
    "                        new_motif_minus_list.append(motif)\n",
    "                for new_motif_plus in new_motif_plus_list:\n",
    "                    if len(motif_plus_tracker) == 0:\n",
    "                        print(11*' '+'plus(+) strand:', file = f)\n",
    "                        motif_plus_tracker.append('check')\n",
    "                    else:\n",
    "                        pass\n",
    "                    if re.search(new_motif_plus.split(',')[2],test[7].split('>')[1].split('<')[0]):\n",
    "                        match = re.search(new_motif_plus.split(',')[2],test[7].split('>')[1].split('<')[0])\n",
    "                        distance = match.span()[0]\n",
    "                        sequence = match.group()\n",
    "                        print((11+distance)*' '+sequence+' |-- '+new_motif_plus.split(',')[0]+' (pval '+new_motif_plus.split(',')[3]+')', file = f)\n",
    "                    elif re.search(new_motif_plus.split(',')[2],test[7].split('>')[1].split('<')[0].replace('-','')):\n",
    "                        match = re.search(new_motif_plus.split(',')[2],test[7].split('>')[1].split('<')[0].replace('-',''))\n",
    "                        distance = match.span()[0]\n",
    "                        sequence = match.group()\n",
    "                        print((11+distance)*' '+sequence+' |-- '+new_motif_plus.split(',')[0]+' (pval '+new_motif_plus.split(',')[3]+')'+' [note, approx. position]', file = f)\n",
    "                for new_motif_minus in new_motif_minus_list:\n",
    "                    if len(motif_minus_tracker) == 0:\n",
    "                        print(11*' '+'minus(-) strand:', file = f)\n",
    "                        motif_minus_tracker.append('check')\n",
    "                    else:\n",
    "                        pass\n",
    "                    seq_revcomp = ''.join(reversed(''.join(nt_dict.get(nt) for nt in test[7].split('>')[1].split('<')[0])))\n",
    "                    if re.search(new_motif_minus.split(',')[2],seq_revcomp):\n",
    "                        match = re.search(new_motif_minus.split(',')[2],seq_revcomp)\n",
    "                        distance = len(seq_revcomp)-match.span()[0]-len(new_motif_minus.split(',')[2])\n",
    "                        sequence = ''.join(reversed(match.group()))\n",
    "                        print((11*' '+distance*' '+sequence+' |-- '+new_motif_minus.split(',')[0]+' (pval '+new_motif_minus.split(',')[3]+')'), file = f)\n",
    "                    elif re.search(new_motif_minus.split(',')[2],seq_revcomp.replace('-','')):\n",
    "                        match = re.search(new_motif_minus.split(',')[2],seq_revcomp.replace('-',''))\n",
    "                        distance = len(seq_revcomp)-match.span()[0]-len(new_motif_minus.split(',')[2])\n",
    "                        sequence = ''.join(reversed(match.group()))\n",
    "                        print((11*' '+distance*' '+sequence+' |-- '+new_motif_minus.split(',')[0]+' (pval '+new_motif_minus.split(',')[3]+')'+' [note, approx. position]'), file = f)  \n",
    "            else:\n",
    "                pass\n",
    "            print('\\n'+4*' '+'query  '+test[7].split('>')[1].split('<')[0]+'\\n'+11*' '+test[9].split('>')[1].split('<')[0]+'\\n'+' reference '+test[8].split('>')[1].split('<')[0]+'\\n', file = f)\n",
    "            if int(sum_lost_motifs) > 0:\n",
    "                print(11*' '+'LOST motifs:', file = f)\n",
    "                motif_plus_tracker = []\n",
    "                motif_minus_tracker = []\n",
    "                lost_motif_plus_list = []\n",
    "                lost_motif_minus_list = []\n",
    "                for motif in dict_allele_TFBS_synopsis.get(i).get(allele).get('lost'):\n",
    "                    if motif.split(',')[1] == '+':\n",
    "                        lost_motif_plus_list.append(motif)\n",
    "                    elif motif.split(',')[1] == '-':\n",
    "                        lost_motif_minus_list.append(motif)\n",
    "                for lost_motif_plus in lost_motif_plus_list:\n",
    "                    if len(motif_plus_tracker) == 0:\n",
    "                        print(11*' '+'plus(+) strand:', file = f)\n",
    "                        motif_plus_tracker.append('check')\n",
    "                    else:\n",
    "                        pass\n",
    "                    if re.search(lost_motif_plus.split(',')[2],test[8].split('>')[1].split('<')[0]):\n",
    "                        match = re.search(lost_motif_plus.split(',')[2],test[8].split('>')[1].split('<')[0])\n",
    "                        distance = match.span()[0]\n",
    "                        sequence = match.group()\n",
    "                        print((11+distance)*' '+sequence+' |-- '+lost_motif_plus.split(',')[0]+' (pval '+lost_motif_plus.split(',')[3]+')', file = f)\n",
    "                    elif re.search(lost_motif_plus.split(',')[2],test[8].split('>')[1].split('<')[0].replace('-','')):\n",
    "                        match = re.search(lost_motif_plus.split(',')[2],test[8].split('>')[1].split('<')[0].replace('-',''))\n",
    "                        distance = len(test[8].split('>')[1].split('<')[0])-match.span()[0]-len(lost_motif_plus.split(',')[2])\n",
    "                        sequence = match.group()\n",
    "                        print((11*' '+distance*' '+sequence+' |-- '+lost_motif_plus.split(',')[0]+' (pval '+lost_motif_plus.split(',')[3]+')'+' [note, approx. position]'), file = f)  \n",
    "                for lost_motif_minus in lost_motif_minus_list:\n",
    "                    if len(motif_minus_tracker) == 0:\n",
    "                        print(11*' '+'minus(-) strand:', file = f)\n",
    "                        motif_minus_tracker.append('check')\n",
    "                    else:\n",
    "                        pass\n",
    "                    seq_revcomp = ''.join(reversed(''.join(nt_dict.get(nt) for nt in test[8].split('>')[1].split('<')[0])))\n",
    "                    if re.search(lost_motif_minus.split(',')[2],seq_revcomp):\n",
    "                        match = re.search(lost_motif_minus.split(',')[2],seq_revcomp)\n",
    "                        distance = len(seq_revcomp)-match.span()[0]-len(lost_motif_minus.split(',')[2])\n",
    "                        sequence = ''.join(reversed(match.group()))\n",
    "                        print((11*' '+distance*' '+sequence+' |-- '+lost_motif_minus.split(',')[0]+' (pval '+lost_motif_minus.split(',')[3]+')'), file = f)\n",
    "                    elif re.search(lost_motif_minus.split(',')[2],seq_revcomp.replace('-','')):\n",
    "                        match = re.search(lost_motif_minus.split(',')[2],seq_revcomp.replace('-',''))\n",
    "                        distance = len(seq_revcomp)-match.span()[0]-len(lost_motif_minus.split(',')[2])\n",
    "                        sequence = ''.join(reversed(match.group()))\n",
    "                        print((11*' '+distance*' '+sequence+' |-- '+lost_motif_minus.split(',')[0]+' (pval '+lost_motif_minus.split(',')[3]+')'+' [note, approx. position]'), file = f)  \n",
    "                print('', file = f)\n",
    "            else:\n",
    "                pass\n",
    "                print('\\n', file = f)\n",
    "            \n",
    "# Log TFBS collation operations time duration\n",
    "TFBScollationDuration = str(datetime.now() - startTime_TFBScollation).split(':')[0]+' hr|'+str(datetime.now() - startTime_TFBScollation).split(':')[1]+' min|'+str(datetime.now() - startTime_TFBScollation).split(':')[2].split('.')[0]+' sec|'+str(datetime.now() - startTime_TFBScollation).split(':')[2].split('.')[1]+' microsec'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIII. Process accessory file  \n",
    "#### *Finalize report of script operation metrics*   \n",
    "\n",
    "**Script metrics:** Along with operating system properties, user-specified variables, input fastq file properties recorded earlier, and TF positional frequency matrices provided to FIMO, metadata concerning output file sizes and script operation time durations are recorded in **script_metrics.txt**.  Samples and/or ranked alleles not present in final output files (due to multiple BLASTN hits or overlapping hsp's) are also noted here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Assess files in output directory\n",
    "file_set = [file for file in os.listdir(output_directory) if Path(file).suffix in ('.txt','.fa', '.xls', '.xlsx')] \n",
    "\n",
    "# Assign script end time\n",
    "endTime = datetime.now()\n",
    "endTimestr = str(endTime).split(' ')[1].split('.')[0]\n",
    "\n",
    "# Log entire script operations time duration\n",
    "processingDuration = str(datetime.now() - startTime).split(':')[0]+' hr|'+str(datetime.now() - startTime).split(':')[1]+' min|'+str(datetime.now() - startTime).split(':')[2].split('.')[0]+' sec|'+str(datetime.now() - startTime).split(':')[2].split('.')[1]+' microsec'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Prepare final report of file size metrics and time durations to **script_metrics.txt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Script has completed.  Please find output files at /Users/kirkehmsen/Documents/CollatedMotifsOutputGit_072721\n"
     ]
    }
   ],
   "source": [
    "filename = Path(str(output_path)+ '/'+processdate+'_script_metrics.txt')\n",
    "with open(filename, 'a') as f:\n",
    "    print(\"\"\"File output information:\n",
    "    Output directory: \"\"\" + str(output_directory) +\n",
    "'\\n    Total file #: ' + str(len(file_set)) +\n",
    "'\\n    Total file output sizes: '+path_size(str(output_directory)), file = f)\n",
    "    for file in file_set:\n",
    "        print('    '+file+': '+path_size(str(output_directory)+'/'+file), file = f)\n",
    "    print(\"\"\"\\n\\nScript operation times:\n",
    "    start time: \"\"\"+startTimestr+\n",
    "    '\\n    makeblastdb and fasta-get-markov processing time: '+makeblastdb_fastagetmarkov_operationsDuration+\n",
    "    '\\n    fasta processing time: '+readcountDuration+\n",
    "    '\\n    alignments processing time: '+alignmentsDuration+\n",
    "    '\\n    allele definitions processing time: '+allele_definitionsDuration+\n",
    "    '\\n    TFBS processing time (FIMO): '+fimoDuration+\n",
    "    '\\n    TFBS collation processing time: '+TFBScollationDuration+\n",
    "    '\\n    total processing time: '+processingDuration+\n",
    "    '\\n    end time: '+endTimestr, file = f)\n",
    "f.close()\n",
    "          \n",
    "# End of script operations\n",
    "print(\"\\nScript has completed.  Please find output files at \"+str(output_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "############################################################################# end"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
